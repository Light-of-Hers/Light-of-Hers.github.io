[{"title":"2023年你最喜欢的MLSys相关的工作是什么（回答）","url":"/2024/01/06/2023%E5%B9%B4%E4%BD%A0%E6%9C%80%E5%96%9C%E6%AC%A2%E7%9A%84MLSys%E7%9B%B8%E5%85%B3%E7%9A%84%E5%B7%A5%E4%BD%9C%E6%98%AF%E4%BB%80%E4%B9%88%EF%BC%88%E5%9B%9E%E7%AD%94%EF%BC%89/","content":"2023 年 mlsys 相关的研究中，最有代表性的主题无疑是 llm inference，涌现了不少优秀的工作。llm training 和之前的 transformer-based model training 主要是 scale 上有区别，基本的分布式训练方法大同小异，感觉前两年也大致卷完了。但 llm inference 除了 scale 上的区别使得内存压力和计算压力增大以外，其自回归解码的性质也使得推理优化变得更加有趣。感觉喜欢的工作挺多的，就都简单列一下吧。\n首先是 Continuous Batching，出处是 OSDI’22 的工作 Orca ，不过 “continuous batching” 这个名称还有大家比较熟悉的那个示意图出处好像是 2023 年的一个博客 How continuous batching enables 23x throughput in LLM inference while reducing p50 latency ，而且其大规模应用也在 2023 年，就勉强当作 2023 年的工作吧。主要贡献是通过细粒度的 batching 来改善了 llm serving 过程中硬件利用率问题。\n\n其次是 vLLM (SOSP’23 paper, code)，是 Ion Stoica 门下 LLMSYS 小组的工作（之前搞出了 vicuna 和 fast-chat 的组），主要贡献是提出了 paged-attention（类似操作系统中虚拟分页的内存管理机制，以及配套的针对不连续 sequence 的 attention kernel），缓解了 llm decode 阶段动态增长的 kv-cache 造成的内存碎片问题（huggingface 采用 concat 来增长 kv-cache，拷贝开销大，外部碎片多；faster-transformer 为每个 kv-cache 预分配固定内存，内部碎片大），由此也增大了 serving 过程的 batching 容量上限，大大提高了吞吐。\n然后是 Speculative Decoding (ICML’23 paper)，Google 的工作，借助一个更小的 draft model 来快速生成多个 token，由原始 model 来一次性验证这些 token，相当于变相突破了 llm decode 阶段每次只生成单个 token 的限制，以一些冗余计算为代价提高了硬件利用率，从而提升性能。CMU 的 Catalyst 组的贾志豪&amp;苗旭鹏的工作 SpecInfer (paper, code) 以 boost 方式训练ensemble draft model，推理时将多个 draft model 的输出组织成 token tree，用 tree attention 进行快速验证。还有 LLMSYS 组的 Lookahead Decoding (blog, code) 则是借助并行采样&amp;验证来加速 token 生成，性质上类似于即时”训练”一个 n-gram draft model 的 speculative decoding，同样也是用冗余计算来换取硬件效率，不过因为没借助预先训练的 draft model，上限会略低一些。\n最后是 Flash-Decoding (blog, code) 和 Flash-Decoding++ (paper)，前者是 Tri Dao 组的，相当于 Flash-Attention-v3，后者则出自清华汪玉组、上交戴国浩组、初创公司”无问芯穹”(Infinigence-AI)。两者解决的问题基本都是在 batch 不够大的情况下，decode 阶段 attention 的 query-seq-len=1 导致的并行性低下的问题，解决的共同思路都是想办法将 key-value-seq 维度给并行化。flash-decoding 将 flash-attention-v2 的思路和常见的 parallel reduction 结合。而 flash-decoding++ 的思路则更有趣，通过适当选取一个 unified max value（具体 analysis 参见 paper），将 softmax 所施加的 key-value-seq 维度上的 reduce 依赖部分破除，效率会比 flash-decoding 的 parallel reduction 更高。此外，Luis Ceze 门下的 FlashInfer (project, code) 也为 llm inference 提供了非常高效的 kernel 实现。\n上述的工作大多和 llm decode 阶段的特性有关。还有一些通过“压缩”模型来减少内存压力和计算压力的工作感觉也不错，比如几个借助动态稀疏性来推进 llm 本地化部署的工作：Tri Dao 组的 Deja Vu (ICML’23 paper, code)，上交 IPADS 的 PowerInfer (paper, code)，苹果的 LLM in a Flash (paper)；还有 llm low-bit 动态量化的 state-of-the-art，Luis Ceze 门下的工作 Atom (paper, code)。\n最后附上上述提到的部分工作关于各种系统要素的权衡：\n\n","tags":["ML-System","HPC","CUDA"]},{"title":"ASPLOS 2024有哪些值得关注的论文？（回答）","url":"/2024/05/06/ASPLOS%202024%E6%9C%89%E5%93%AA%E4%BA%9B%E5%80%BC%E5%BE%97%E5%85%B3%E6%B3%A8%E7%9A%84%E8%AE%BA%E6%96%87%EF%BC%9F%EF%BC%88%E5%9B%9E%E7%AD%94%EF%BC%89/","content":"按 Session 顺序讲讲北大的几篇工作吧。\n首先是 @Charlie @李秀红 的 Centauri: Enabling Efficient Scheduling for Communication-Computation Overlap in Large Model Training via Communication Partitioning，主要做分布式训练的 partition 和 scheduling 的抽象与优化，是这次 ASPLOS’24 的 best paper 之一（这次一共有 6 篇 best paper，平均一个 cycle 2 篇，基本涵盖了这次 ASPLOS 涉及的各个领域）。\n之后是刘譞哲组的徐大亮的 SoCFlow: Efficient and Scalable DNN Training on SoC-Clustered Edge Servers，主要做 SoC-Cluster 上的分布式训练（感觉就是 distributed on-device learning）。\n然后是我们组做的 MAGIS: Memory Optimization via Coordinated Graph Transformation and Scheduling for DNN，代码开源在 https://github.com/pku-liang/MAGIS，大家感兴趣可以关注一下。主要是通过图变换和图调度的协同来做 DNN 的内存优化。里面关于 dim graph 的抽象还有 fission tree 的构建挺有意思的，虽然 dim graph 主要是为了 fission transform 定义的完备性搞的，实际优化 DNN training 中主要起作用的还是 batch-dim（不过 sub-graph 会比较多样）。我签证被拒了，就由梁云老师还有子健帮忙代讲 talk 和 lightning talk，聪哥帮忙张贴 poster ……\n最后是孙广宇组李聪和周哲的两篇 ML PIM System 的工作 PIM-DL: Expanding the Applicability of Commodity DRAM-PIMs for Deep Learning via Algorithm-System Co-Optimization 和 SpecPIM: Accelerating Speculative Inference on PIM-Enabled System via Architecture-Dataflow Co-Exploration，前者搞了针对 DRAM-PIM 平台的 DL 框架，AE 代码开源在 https://github.com/leesou/PIM-DL-ASPLOS ，后者则设计了用来加速 LLM 投机推理的 PIM 架构以及配套的 DSE 框架。\n此外，本次会议个人最喜欢的还是 torch compiler PyTorch 2: Faster Machine Learning Through Dynamic Python Bytecode Transformation and Graph Compilation ，在易用性和性能上都达到了相当不错的效果，和 OpenAI Triton 一起竖起了目前工业级 ML Compiler 的标杆（而且 torch compiler 后端也可以接 triton，属于是强强联合了）。值得一提的是，torch compiler 后端接 triton 的话，最终会生成 python 代码，包含了被融合的算子对应的 triton 代码以及原函数的优化后的代码骨架；我们这次的工作 MAGIS 也有类似的做法，最后会生成调用了 pytorch api 的 python 函数，事实上也可以直接对接 torch compiler（不过在内存管理上会有些问题，之后会想办法改进一下）。\n","tags":["ML-System","ML-Compiler"]},{"title":"C++格式化字符串的一个极简实现","url":"/2020/01/07/C++%E6%A0%BC%E5%BC%8F%E5%8C%96%E5%AD%97%E7%AC%A6%E4%B8%B2%E7%9A%84%E4%B8%80%E4%B8%AA%E6%9E%81%E7%AE%80%E5%AE%9E%E7%8E%B0/","content":"写C++程序设计的大作业时，不方便引用外部的库，想传递一些格式化字符串写起来就很麻烦。一般来说使用sprintf或者std::ostringstream，但前者一般只支持C原生类型，而后者通常的写法略显繁琐（前者也比较繁琐）。于是便想到了下面的写法：\n#define format(__stream)\\    (dynamic_cast&lt;std::ostringstream &amp; &gt;(std::ostringstream() __stream).str())\n\n举个例子：\nnamespace crz {class bad_comparison : public std::logic_error {public:    explicit bad_comparison(        const std::type_info &amp;from,         const std::type_info &amp;to,         const char *opt) :     std::logic_error(format(&lt;&lt; from.name() &lt;&lt; \" \" &lt;&lt; opt &lt;&lt; \" \" &lt;&lt; to.name())) {}};}\n\n还可以用变参模板实现：\nnamespace crz {namespace detail {template&lt;typename ...Args, typename = typename std::enable_if&lt;sizeof...(Args) == 0&gt;::type&gt;inline std::ostream &amp;__va_output(std::ostream &amp;os, Args &amp;&amp;...args) {    return os;}template&lt;typename T, typename ...Args&gt;inline std::ostream &amp;__va_output(std::ostream &amp;os, T &amp;&amp;t, Args &amp;&amp;...args) {    os &lt;&lt; t;    return __va_output(os, std::forward&lt;Args&gt;(args)...);}}template&lt;typename ...Args&gt;inline std::string format(Args &amp;&amp;...args) {    std::ostringstream os;    detail::__va_output(os, std::forward&lt;Args&gt;(args)...);    return os.str();}}\n\n举个例子：\nnamespace crz {class bad_comparison : public std::logic_error {public:    explicit bad_comparison(        const std::type_info &amp;from,         const std::type_info &amp;to,         const char *opt) :     std::logic_error(format(from.name(), \" \", opt, \" \", to.name())) {}};}\n\n不过变参模板的实现显然没有之前用宏实现来得简洁。\n以上只是个人一时的脑洞，较大的项目还是用fmt等成熟的格式化库为好（或者等有生之年C++20的format落地后用标准库）。\n","tags":["Cpp"]},{"title":"C++中柯里化(curry)与偏应用(partial)的实现","url":"/2020/01/17/C++%E4%B8%AD%E6%9F%AF%E9%87%8C%E5%8C%96(curry)%E4%B8%8E%E5%81%8F%E5%BA%94%E7%94%A8(partial)%E7%9A%84%E5%AE%9E%E7%8E%B0/","content":"前言回家的时候在火车上草草看了下《JS函数式编程指南》，对Ramda库中curry和partial的实现略感兴趣，加之不久前，在完成C++期末大作业（实现一个类似python中的list的C++泛型容器）的过程中，深入学习了一下C++模板元编程的技术，因此便想用泛型编程技术实现C++中的curry和partial函数。\n对于柯里化和偏应用不太了解的，可以参考@罗宸的这个回答，在此不多赘述。\n\n基本思路curry的实现思路以int add(int a, int b) {return a + b;}为例，该函数柯里化后得到的函数对象c_add接收一个int参数a，返回一个函数对象，该对象保存之前传入的int参数a，接收一个int参数b，返回a + b的值。\n这样看来柯里化后的函数对象F必须都保存调用时传入的参数，并且能将当前保存的所有参数传递给调用后返回的函数对象。\n可以有两种实现思路：\n\n采用某种泛型数据结构（如std::tuple）保存积累至今的参数，并在传入最后一个参数的时候用某种方式一次性将所有参数传递给原函数（如std::apply）。这种方法比较容易想到。  \n\n还有一种方法参见何涛的这篇博客。其基本思想是保存之前的函数对象，传入最后一个参数后逐层传递参数（最高层N将最后一个参数传递给下一层N-1，N-1将得到的参数和自己保存的参数传递给下一层N-2），在最后一层调用柯里化之前的函数。实现上会更漂亮些，但性能上感觉不如前者。可以用下面的JS伪代码表现：\n\n\nconst curry = (f) =&gt; {  return (arg) =&gt; {      return curry(partial_first_arg(f, arg));  }}\n\npartial的实现思路偏应用的实现就比较直观，其实现思路也有两种：\n\n比较直观的方法：保存传入的参数，在被调用时连同传入的参数一起传给原函数。  \n\n也是何涛博客中提到的方法，基本思想可以用下面JS伪码表述：\n\n\nconst partial = (f, arg, ...args) =&gt; {  return partial(partial_first_arg(f, arg), ...args);}\n\n\n实现坑点关于curry/partial的C++实现，有不少先例，如何涛的一篇博客、@Khellendros的一篇文章、stackoverflow上的一个问题等，但多多少少有一些难以忽视的漏洞，包括但不限于：\n\n采用右值引用结合std::forward来转发函数参数，如Khellendros的curry实现：\n\nauto operator()(A &amp;&amp;... args) const {    auto cache2 = std::tuple_cat(_cache, std::forward_as_tuple(args...));    return CurriedFunction&lt;F, i - 1, decltype(cache2)&gt;(_fn, std::move(cache2));}\n\n这样会将所有传入的左值引用都保存为引用，而不是根据原函数的参数类型保存为值/引用，在许多情况下会导致悬垂引用问题。如下面的例子：\nint add(int a, int b) {    return a + b;}auto inc(int x) {    return Reimuda::curry&lt;2&gt;(add)(x);}int main() {    auto f1 = inc(1);    auto f2 = inc(2);    auto f3 = inc(3);    auto f4 = inc(4);    auto f5 = inc(5);    std::cout &lt;&lt; f1(1) &lt;&lt; std::endl;}\n\n会输出奇怪的数（反正不是2），因为inc中的curry(add)接收x后保存的是x的引用而不是值，之后对inc的调用会覆写原引用指向的栈上的位置。\n\n采用引用保存原函数。和前例一样也会出现悬垂引用问题。一般对于函数对象而言保存值是最好的，如果需要保存引用可以用std::ref显式包装。\n\n对于函数和保存的参数的可拷贝性缺乏考量。\n\n没有按原函数的参数类型要求严格地按值/引用保存传入的参数。这点是1.的延伸。\n\n\n……\n上述问题主要都是C++的内存管理模式导致的。和ML、Lisp等大多数带函数式编程特性的语言不同，C++没有GC，这就导致了实现curry&amp;partial的过程中，在涉及值/引用和拷贝/移动时需要更细致的考察（用Rust的话编译器会帮你考察……）。\n\n实现细节函数签名的萃取前面的部分说过，想要在C++中实现一个行为较为正确的curry&amp;partial，必须显式地解析参数类型，根据参数类型来决定保存传入的参数的值还是引用。因此需要一些TMP技巧来萃取函数对象的签名。这部分内容可以参见这篇文章，这里仅给出代码：\nnamespace __detail {template&lt;typename R, typename ...As&gt;struct __function_traits_base {    using function_type = std::function&lt;R(As...)&gt;;    using result_type = R;    using argument_types = std::tuple&lt;As...&gt;;};template&lt;typename F&gt;struct __function_traits;template&lt;typename F&gt;struct __function_traits&lt;std::reference_wrapper&lt;F&gt;&gt; : public __function_traits&lt;F&gt; {};template&lt;typename R, typename ...As&gt;struct __function_traits&lt;R(*)(As...)&gt; : public __function_traits_base&lt;R, As...&gt; {};template&lt;typename R, typename C, typename ...As&gt;struct __function_traits&lt;R(C::*)(As...)&gt; : public __function_traits_base&lt;R, As...&gt; {};template&lt;typename R, typename C, typename ...As&gt;struct __function_traits&lt;R(C::*)(As...) const&gt; : public __function_traits_base&lt;R, As...&gt; {};template&lt;typename F&gt;struct __function_traits : public __function_traits&lt;decltype(&amp;F::operator())&gt; {};}namespace fp {template&lt;typename F&gt;struct function_traits : public __detail::__function_traits&lt;std::decay_t&lt;F&gt;&gt; {};}\n\ncurry的实现采用第一种思路实现。\n首先定义一个可以缓存参数的cacher作为curry的返回值。模板中的TA表示”Tuple of Args”，即保存的参数元组的类型，A和As表示之后还剩下的参数类型。cacher接收一个参数，用其扩展cached_args，将扩展后的cached_args传给一个新的cacher，并返回新cacher。\n其中注意cached_args和f可能不可拷贝，因此用__copy_or_move包装，视情况将其拷贝/移动给新的cacher。\ntemplate&lt;typename F, typename T1, typename T2&gt;class __curry_cacher;template&lt;typename F, typename TA, typename A, typename ...As&gt;class __curry_cacher&lt;F, TA, std::tuple&lt;A, As...&gt;&gt; {    F f;    TA cached_args;public:    __curry_cacher(F f, TA args) : f(std::move(f)), cached_args(std::move(args)) {}    auto operator()(A arg) {        auto new_cached_args = std::tuple_cat(                __copy_or_move(cached_args),                std::tuple&lt;A&gt;(std::forward&lt;A&gt;(arg)));        return __curry_cacher&lt;F,                decltype(new_cached_args),                std::tuple&lt;As...&gt;&gt;(__copy_or_move(f), std::move(new_cached_args));    }}\n\n其中__copy_or_move的实现如下（虽然比较trivial，但还是贴出来吧）：\ntemplate&lt;typename T&gt;auto __copy_or_move(const T &amp;t) -&gt; T {    if constexpr (std::is_copy_constructible_v&lt;T&gt;) {        return t;    } else {        return std::move(const_cast&lt;T &amp;&gt;(t));    }}\n\n当剩余的参数只有一个的时候，调用cacher将直接调用保存的原函数：\ntemplate&lt;typename F, typename TA, typename A&gt;class __curry_cacher&lt;F, TA, std::tuple&lt;A&gt;&gt; {    F f;    TA cached_args;public:    __curry_cacher(F f, TA args) : f(std::move(f)), cached_args(std::move(args)) {}    auto operator()(A arg) {        return std::apply(f, std::tuple_cat(                __copy_or_move(cached_args),                std::tuple&lt;A&gt;(std::forward&lt;A&gt;(arg))));    }};\n\n实现完cacher后，就可以实现curry了。先将参数类型的元组萃取出来，之后返回一个没有缓存参数的cacher。\ntemplate&lt;typename F&gt;auto curry(F f) {    using arg_types = typename function_traits&lt;F&gt;::argument_types;    if constexpr (std::tuple_size_v&lt;arg_types&gt; &lt; 2) {        return f;    } else {        return __detail::__curry_cacher&lt;F, std::tuple&lt;&gt;, arg_types&gt;                (std::move(f), std::tuple&lt;&gt;());    }}\n\npartial的实现也采用第一种思路实现partial。\n先定义一个cacher来缓存参数：\ntemplate&lt;typename F, typename T1, typename T2&gt;class __partial_cacher;template&lt;typename F, typename TA, typename ...As&gt;class __partial_cacher&lt;F, TA, std::tuple&lt;As...&gt;&gt; {    F f;    TA cached_args;public:    __partial_cacher(F f, TA args) : f(std::move(f)), cached_args(std::move(args)) {}    auto operator()(As... args) {        return std::apply(f, std::tuple_cat(                __copy_or_move(cached_args),                std::tuple&lt;As...&gt;(std::forward&lt;As&gt;(args)...)));    }};\n\n之后实现partial。同样是先萃取函数签名，在返回一个缓存着接收到的参数的cacher。注意cacher模板的第三个参数是接下来还要接收的函数参数类型，因此需要用函数签名中的参数类型刨去前面已经接收的参数类型：\ntemplate&lt;typename F, typename ...As&gt;auto partial(F f, As &amp;&amp;...args) {    using arg_types = typename function_traits&lt;F&gt;::argument_types;    static_assert(sizeof...(As) &lt;= std::tuple_size_v&lt;arg_types&gt;, \"Too many arguments\");    if constexpr (sizeof...(As) == 0) {        return f;    } else if constexpr (sizeof...(As) == std::tuple_size_v&lt;arg_types&gt;) {        return f(std::forward&lt;As&gt;(args)...);    } else {        return __detail::__partial_cacher&lt;F, std::tuple&lt;As...&gt;, __detail::__tuple_drop_n_t&lt;sizeof...(As), arg_types&gt;&gt;                (std::move(f), std::tuple&lt;As...&gt;(std::forward&lt;As&gt;(args)...));    }}\n\n其中__tuple_drop_n_t&lt;N, T&gt;用于丢弃元组T的前N个类型，实现如下：\ntemplate&lt;std::size_t I, typename T, typename = void&gt;struct __tuple_drop_n;template&lt;std::size_t I, typename T&gt;using __tuple_drop_n_t = typename __tuple_drop_n&lt;I, T&gt;::type;template&lt;typename ...Ts&gt;struct __tuple_drop_n&lt;0, std::tuple&lt;Ts...&gt;&gt; {    using type = std::tuple&lt;Ts...&gt;;};template&lt;std::size_t I, typename T, typename ...Ts&gt;struct __tuple_drop_n&lt;I, std::tuple&lt;T, Ts...&gt;, std::enable_if_t&lt;(I &gt; 0)&gt;&gt; {    using type = __tuple_drop_n_t&lt;I - 1, std::tuple&lt;Ts...&gt;&gt;;};\n\n\n简单测试curry的测试call-by-valueauto add = [](int a, int b, int c, int d) {        return a + b + c + d;    };    auto c_add = curry(add);    std::cout &lt;&lt; c_add(1)(2)(3)(4) &lt;&lt; std::endl; // 10    auto c_add_1 = c_add(1);    std::cout &lt;&lt; c_add_1(2)(3)(4) &lt;&lt; std::endl; // 10\n\ncall-by-referenceauto genso_concat = [](std::string &amp;s) {        return curry([&amp;](std::string &amp;a, const std::string &amp;b) {            auto tmp = a;            a += \" \" + b + \" \" + s;            s += \" \" + b + \" \" + tmp;        });    };    auto s1 = std::string(\"Reimu\"), s2 = std::string(\"Marisa\");    auto f = genso_concat(s1);    auto ff = f(s2);    ff(\"love\");    std::cout &lt;&lt; s1 &lt;&lt; std::endl; // Reimu love Marisa    std::cout &lt;&lt; s2 &lt;&lt; std::endl; // Marisa love Reimu\n\nclosure?auto greater_than = [](int x) {        return curry([](int a, int b) { return a &lt; b; })(x);    };    auto gt_0 = greater_than(0);    auto gt_1 = greater_than(1);    auto gt_2 = greater_than(2);    auto gt_3 = greater_than(3);    std::cout &lt;&lt; std::boolalpha;    std::cout &lt;&lt; gt_0(-1) &lt;&lt; std::endl; // false    std::cout &lt;&lt; gt_0(0) &lt;&lt; std::endl; // false    std::cout &lt;&lt; gt_0(1) &lt;&lt; std::endl; // true\n\nnon-copyable-functionclass UniF {    std::unique_ptr&lt;int&gt; uip;public:    explicit UniF(int x) : uip(new int{x}) {}    int operator()(int &amp;a, int b) {        return a = *uip += b;    }};{    UniF uf{1};    int x = 0;    auto f = curry(std::move(uf));    auto x_f = std::move(f(x));    std::cout &lt;&lt; x_f(1) &lt;&lt; std::endl; // 2    std::cout &lt;&lt; x_f(1) &lt;&lt; std::endl; // 3    std::cout &lt;&lt; x_f(1) &lt;&lt; std::endl; // 4    std::cout &lt;&lt; x &lt;&lt; std::endl; // 4}{    UniF uf{1};    int x = 0;    auto f = curry(std::ref(uf));    std::cout &lt;&lt; f(x)(1) &lt;&lt; std::endl; // 2    std::cout &lt;&lt; x &lt;&lt; std::endl; // 2    auto x_f = f(x);    std::cout &lt;&lt; x_f(1) &lt;&lt; std::endl; // 3    std::cout &lt;&lt; x_f(1) &lt;&lt; std::endl; // 4    std::cout &lt;&lt; x &lt;&lt; std::endl; // 4}\n\npartial的测试call-by-valueauto gt_0 = partial(std::less&lt;int&gt;{}, 0);    std::cout &lt;&lt; std::boolalpha;    std::cout &lt;&lt; gt_0(-1) &lt;&lt; std::endl; // false    std::cout &lt;&lt; gt_0(0) &lt;&lt; std::endl; // false    std::cout &lt;&lt; gt_0(1) &lt;&lt; std::endl; // true\n\ncall-by-referenceauto pair_assign = [](int &amp;a, int &amp;b, int aa, int bb) -&gt; void { a = aa, b = bb; };    int a = 0, b = 0;    auto assign_a_b = partial(pair_assign, a, b);    assign_a_b(1, 2);    std::cout &lt;&lt; a &lt;&lt; \", \" &lt;&lt; b &lt;&lt; std::endl; // 1, 2\n\nnon-copyable-functionstd::unique_ptr&lt;int&gt; uip{new int{0}};    auto uf = [p = std::move(uip)](int a, int b) {        return *p += a + b;    };    {        auto f = partial(std::ref(uf), 1);        std::cout &lt;&lt; f(1) &lt;&lt; std::endl; // 2        std::cout &lt;&lt; f(1) &lt;&lt; std::endl; // 4        std::cout &lt;&lt; f(1) &lt;&lt; std::endl; // 6    }    {        auto f = partial(std::move(uf), 1);        std::cout &lt;&lt; f(1) &lt;&lt; std::endl; // 8        std::cout &lt;&lt; f(1) &lt;&lt; std::endl; // 10        std::cout &lt;&lt; f(1) &lt;&lt; std::endl; // 12    }\n\n\n使用注意\n传给curry&amp;partial的必须是类型确定的函数，也就是说函数模板和重载的函数（含有默认形参的函数也算）不能直接传入。对于函数模板，需要实例化后传入；对于重载的函数，需要显式转换到确定的类型才能传入。\ncurry&amp;partial默认传入函数的拷贝，如果想传入函数引用可以用std::ref/std::cref进行包装后将引用间接传入。如果传入的函数对象是不可拷贝的，可以选择用std::ref间接传引用或者用std::move转让所有权。\n需要C++17标准支持（主要是constexpr if特性，毕竟多分支模板匹配写起来还是蛮令人不爽的……）。\n\n\n后记自己在PKU-CECA里搞的东西基本和PL或C++没有什么关系（硬要扯上关系的话，TVM的Relay的研究和PL有点关系？或者写CUDA之类的和C++有点关系？），所以这两天搞这种无用的玩意纯属摸鱼行为……不过，虽然无用，但造轮子还是蛮爽的。\n附上代码链接：https://github.com/Light-of-Hers/Cpp-curry-partial-and-other-FP-combinators\n","tags":["Cpp","Programming-Language"]},{"title":"C++模板元编程中的代数数据类型(ADT)及模式匹配等操作：以编译期AVL树为例","url":"/2020/01/21/C++%E6%A8%A1%E6%9D%BF%E5%85%83%E7%BC%96%E7%A8%8B%E4%B8%AD%E7%9A%84%E4%BB%A3%E6%95%B0%E6%95%B0%E6%8D%AE%E7%B1%BB%E5%9E%8B(ADT)%E5%8F%8A%E6%A8%A1%E5%BC%8F%E5%8C%B9%E9%85%8D%E7%AD%89%E6%93%8D%E4%BD%9C%EF%BC%9A%E4%BB%A5%E7%BC%96%E8%AF%91%E6%9C%9FAVL%E6%A0%91%E4%B8%BA%E4%BE%8B/","content":"前言众所周知C++是可以在编译期进行用户可控的图灵完全计算的，其方法主要是利用模板元编程(TMP)，以及在C++11出现并在C++14和C++17中不断增强的constexpr相关的语法（关于这个，clang的源码中有个很有意思的测试样例：a href=”https://github.com/llvm-mirror/clang/blob/master/test/SemaCXX/constexpr-turing.cpp“&gt;用constexpr实现编译期图灵机）。其中constexpr在使用上会更加简洁，而TMP写起来则繁杂些。不过TMP在形式上支持一些比较先进的PL原语，比如模式匹配，这是单纯用constexpr做不到的。\n前几天学习OCaml的时候用OCaml实现了一个函数式AVL树，事后想了想好像用C++的TMP也可以实现个类似的编译期AVL树，试着做了一下，发现将OCaml中的ADT以及基于模式匹配的对于ADT的操作转化到TMP竟然出乎意料地顺滑。于是便写此文章，以编译期AVL树为例，展现一下用TMP实现ADT的简易性。\n关于AVL树的定义与操作，如有需要请自行搜索，本文不提供详细说明。\n\nAVL树定义首先是定义AVL树的ADT。\ntype avl_tree =  | AvlNull  | AvlNode of int * int * avl_tree * avl_treelet avl_height t =  match t with  | AvlNull -&gt; 0  | AvlNode (h, _, _, _) -&gt; h;;let avl_node v l r = AvlNode (max (avl_height l) (avl_height r) + 1, v, l, r)\n\n其中avl_node是AvlNode的构造器，avl_height是avl_tree的树高属性的萃取器。\n转化为C++ TMP代码：\nstruct avl_tree {};struct avl_null : public avl_tree {    static constexpr int height = 0;};template&lt;int V, typename L, typename R&gt;struct avl_node : public avl_tree {    static_assert(std::is_base_of_v&lt;avl_tree, L&gt; &amp;&amp; std::is_base_of_v&lt;avl_tree, R&gt;);    static constexpr int height = std::max(L::height, R::height) + 1;};\n\n其中用继承来表现variant。\n这里和OCaml的实现有点不同，将树高作为类的静态常量保存，不过无伤大雅。\n在avl_node的构造中会对模板参数L和R进行检查，保证其为avl_tree。\n\nAVL树操作元素查询OCaml的代码非常直接：\nlet rec avl_query i t =  match t with  | AvlNode (_, v, l, r) -&gt;    if i &lt; v then avl_query i l else if i &gt; v then avl_query i r else true  | _ -&gt; false;;\n\n可以用模板偏特化来实现模式匹配。其中：\n\n类模板的基础定义可以表示模式匹配中的缺省情况（如下面的static constexpr bool value = false;）。\n对模板的不同形式的偏特化可以表示模式匹配的不同模式。\n\ntemplate&lt;int I, typename T&gt;struct avl_query : public avl_operation&lt;T&gt; {    static constexpr bool value = false;};template&lt;int I, typename T&gt;constexpr bool avl_query_v = avl_query&lt;I, T&gt;::value;template&lt;int V, typename L, typename R, int I&gt;struct avl_query&lt;I, avl_node&lt;V, L, R&gt;&gt; {    static constexpr bool value = I &lt; V ? avl_query_v&lt;I, L&gt; : I &gt; V ? avl_query_v&lt;I, R&gt; : true;};\n\n其中avl_operation主要用于检查模板参数是否为avl_tree：\ntemplate&lt;typename T&gt;struct avl_operation {    static_assert(std::is_base_of_v&lt;avl_tree, T&gt;);};\n\n旋转调整针对AVL树四种需要旋转的模式进行调整：\nlet rec avl_adjust t =  match t with  | AvlNode (_, v1, AvlNode (h2, v2, a, b), c)    when h2 &gt; avl_height c + 1 &amp;&amp; avl_height a &gt;= avl_height b -&gt;    avl_node v2 a (avl_node v1 b c)  | AvlNode (_, v1, a, AvlNode (h2, v2, b, c))    when h2 &gt; avl_height a + 1 &amp;&amp; avl_height c &gt;= avl_height b -&gt;    avl_node v2 (avl_node v1 a b) c  | AvlNode (_, v1, AvlNode (h2, v2, a, AvlNode (h3, v3, b, c)), d)    when h2 &gt; avl_height d + 1 &amp;&amp; h3 &gt; avl_height a -&gt;    avl_node v3 (avl_node v2 a b) (avl_node v1 c d)  | AvlNode (_, v1, a, AvlNode (h2, v2, AvlNode (h3, v3, b, c), d))    when h2 &gt; avl_height a + 1 &amp;&amp; h3 &gt; avl_height d -&gt;    avl_node v3 (avl_node v1 a b) (avl_node v2 c d)  | _ -&gt; t;;\n\nOCaml的代码中用到了模式匹配的when子句，这个可用std::enable_if来模拟：\ntemplate&lt;typename T, typename = void&gt;struct avl_adjust : public avl_operation&lt;T&gt; {    using type = T;};template&lt;typename T&gt;using avl_adjust_t = typename avl_adjust&lt;T&gt;::type;template&lt;int V1, int V2, typename A, typename B, typename C&gt;struct avl_adjust&lt;avl_node&lt;V1, avl_node&lt;V2, A, B&gt;, C&gt;,        std::enable_if_t&lt;(avl_node&lt;V2, A, B&gt;::height &gt; C::height + 1 &amp;&amp;                          A::height &gt;= B::height)&gt;&gt; {    using type = avl_node&lt;V2, A, avl_node&lt;V1, B, C&gt;&gt;;};template&lt;int V1, int V2, typename A, typename B, typename C&gt;struct avl_adjust&lt;avl_node&lt;V1, A, avl_node&lt;V2, B, C&gt;&gt;,        std::enable_if_t&lt;(avl_node&lt;V2, B, C&gt;::height &gt; A::height + 1 &amp;&amp;                          C::height &gt;= B::height)&gt;&gt; {    using type = avl_node&lt;V2, avl_node&lt;V1, A, B&gt;, C&gt;;};template&lt;int V1, int V2, int V3, typename A, typename B, typename C, typename D&gt;struct avl_adjust&lt;avl_node&lt;V1, avl_node&lt;V2, A, avl_node&lt;V3, B, C&gt;&gt;, D&gt;,        std::enable_if_t&lt;(avl_node&lt;V2, A, avl_node&lt;V3, B, C&gt;&gt;::height &gt; D::height + 1 &amp;&amp;                          avl_node&lt;V3, B, C&gt;::height &gt; A::height)&gt;&gt; {    using type = avl_node&lt;V3, avl_node&lt;V2, A, B&gt;, avl_node&lt;V1, C, D&gt;&gt;;};template&lt;int V1, int V2, int V3, typename A, typename B, typename C, typename D&gt;struct avl_adjust&lt;avl_node&lt;V1, A, avl_node&lt;V2, avl_node&lt;V3, B, C&gt;, D&gt;&gt;,        std::enable_if_t&lt;(avl_node&lt;V2, avl_node&lt;V3, B, C&gt;, D&gt;::height &gt; A::height + 1 &amp;&amp;                          avl_node&lt;V3, B, C&gt;::height &gt; D::height)&gt;&gt; {    using type = avl_node&lt;V3, avl_node&lt;V1, A, B&gt;, avl_node&lt;V2, C, D&gt;&gt;;};\n\n该段代码可以很好地展现C++ TMP对模式匹配的支持。\n插入元素OCaml代码：\nlet rec avl_insert i t =  match t with  | AvlNode (_, v, l, r) -&gt;    if i &lt; v    then avl_adjust @@ avl_node v (avl_insert i l) r    else if i &gt; v    then avl_adjust @@ avl_node v l (avl_insert i r)    else t  | _ -&gt; avl_node i AvlNull AvlNull;;\n\n注意多段的条件判断单纯使用C++ TMP不是很好实现，因为std::conditional会对两个分支都求值，而直接用模板匹配来实现这么多个分支又太过繁琐。因此借助了一些constexpr相关语法的帮助，让实现更加简洁：\ntemplate&lt;int I, typename T&gt;struct avl_insert : public avl_operation&lt;T&gt; {    using type = avl_node&lt;I, avl_null, avl_null&gt;;};template&lt;int I, typename T&gt;using avl_insert_t = typename avl_insert&lt;I, T&gt;::type;template&lt;int V, typename L, typename R, int I&gt;struct avl_insert&lt;I, avl_node&lt;V, L, R&gt;&gt; {private:    static auto infer() {        if constexpr (I &lt; V) {            return avl_adjust_t&lt;avl_node&lt;V, avl_insert_t&lt;I, L&gt;, R&gt;&gt;{};        } else if constexpr (I &gt; V) {            return avl_adjust_t&lt;avl_node&lt;V, L, avl_insert_t&lt;I, R&gt;&gt;&gt;{};        } else {            return avl_node&lt;V, L, R&gt;{};        }    }public:    using type = decltype(infer());};\n\n最大值/最小值实现非常简单，主要是为删除元素做铺垫。\nOCaml实现：\nlet rec avl_max t =  match t with  | AvlNode (_, v, l, r) -&gt; max v @@ avl_max r  | _ -&gt; min_int;;let rec avl_min t =  match t with  | AvlNode (_, v, l, r) -&gt; min v @@ avl_min l  | _ -&gt; max_int;;\n\nC++实现：\ntemplate&lt;typename T&gt;struct avl_extreme : public avl_operation&lt;T&gt; {    static constexpr int max_value = std::numeric_limits&lt;int&gt;::min();    static constexpr int min_value = std::numeric_limits&lt;int&gt;::max();};template&lt;typename T&gt;constexpr int avl_max_v = avl_extreme&lt;T&gt;::max_value;template&lt;typename T&gt;constexpr int avl_min_v = avl_extreme&lt;T&gt;::min_value;template&lt;int V, typename L, typename R&gt;struct avl_extreme&lt;avl_node&lt;V, L, R&gt;&gt; {    static constexpr int max_value = std::max(V, avl_max_v&lt;R&gt;);    static constexpr int min_value = std::min(V, avl_min_v&lt;L&gt;);};\n\n删除元素直接上代码吧……\nOCaml代码：\nlet rec avl_remove i t =  match t with  | AvlNode (_, v, l, r) -&gt;    if i &lt; v    then avl_adjust @@ avl_node v (avl_remove i l) r    else if i &gt; v    then avl_adjust @@ avl_node v l (avl_remove i r)    else if l == AvlNull    then r    else if r == AvlNull    then l    else (      let nv = avl_min r in      avl_adjust @@ avl_node nv l (avl_remove nv r))  | _ -&gt; t;;\n\nC++代码：\ntemplate&lt;int I, typename T&gt;struct avl_remove : public avl_operation&lt;T&gt; {    using type = T;};template&lt;int I, typename T&gt;using avl_remove_t = typename avl_remove&lt;I, T&gt;::type;template&lt;int V, typename L, typename R, int I&gt;struct avl_remove&lt;I, avl_node&lt;V, L, R&gt;&gt; {private:    static auto infer() {        if constexpr (I &lt; V) {            return avl_adjust_t&lt;avl_node&lt;V, avl_remove_t&lt;I, L&gt;, R&gt;&gt;{};        } else if constexpr (I &gt; V) {            return avl_adjust_t&lt;avl_node&lt;V, L, avl_remove_t&lt;I, R&gt;&gt;&gt;{};        } else if constexpr (std::is_same_v&lt;L, avl_null&gt;) {            return R{};        } else if constexpr (std::is_same_v&lt;R, avl_null&gt;) {            return L{};        } else {            constexpr int NV = avl_min_v&lt;R&gt;;            return avl_adjust_t&lt;avl_node&lt;NV, L, avl_remove_t&lt;NV, R&gt;&gt;&gt;{};        }    }public:    using type = decltype(infer());};\n\n其中用利用constexpr变量可以实现let ... in ...这样的局部绑定。\n\n简单测试OCaml部分先定义打印AVL树的函数：\nlet rec avl_print ?(depth = 0) t =  match t with  | AvlNode (_, v, l, r) -&gt;    print_string @@ String.make (depth * 2) '-' ^ string_of_int v;    print_newline ();    avl_print l ~depth:(depth + 1);    avl_print r ~depth:(depth + 1)  | _ -&gt; ()\n\n之后构造简单的测试样例：先按顺序插入1~10，之后删除1,3,5。\nlet t =  List.init 10 (fun x -&gt; x + 1) |&gt; List.fold_left (fun t x -&gt; avl_insert x t) AvlNullinavl_print t;print_newline ();avl_remove 1 t |&gt; avl_remove 3 |&gt; avl_remove 5 |&gt; avl_print;\n\n输出结果：\n4--2----1----3--8----6------5------7----9------108--4----2----6------7--9----10\n\nC++部分定义打印函数，以及用于构造连续插入1~n的AVL树的元函数：\ntemplate&lt;typename T&gt;struct avl_printer : public avl_operation&lt;T&gt; {    static void print(int depth = 0) {}};template&lt;int V, typename L, typename R&gt;struct avl_printer&lt;avl_node&lt;V, L, R&gt;&gt; {    static void print(int depth = 0) {        for (int i = 0; i &lt; depth; ++i)            std::cout &lt;&lt; \"--\";        std::cout &lt;&lt; V &lt;&lt; std::endl;        avl_printer&lt;L&gt;::print(depth + 1);        avl_printer&lt;R&gt;::print(depth + 1);    }};template&lt;int I&gt;struct avl_build_range;template&lt;int I&gt;using avl_build_range_t = typename avl_build_range&lt;I&gt;::type;template&lt;&gt;struct avl_build_range&lt;0&gt; {    using type = avl_null;};template&lt;int I&gt;struct avl_build_range {    using type = avl_insert_t&lt;I, avl_build_range_t&lt;I - 1&gt;&gt;;};\n\n之后构造简单测试：插入1~10，之后删除1,3,5：\nint main() {    using t = avl_build_range_t&lt;10&gt;;    avl_printer&lt;t&gt;::print();    std::cout &lt;&lt; std::endl;    avl_printer&lt;avl_remove_t&lt;5, avl_remove_t&lt;3, avl_remove_t&lt;1, t&gt;&gt;&gt;&gt;::print();}\n\n打印结果和OCaml的一样（废话……）：\n4--2----1----3--8----6------5------7----9------108--4----2----6------7--9----10\n\n\n后记本文旨在结合ADT、模式匹配等比较先进的PL概念，提供一些定义C++编译期数据结构的思路和较为简洁的写法。至于编译期AVL树则纯属玩具（毕竟对编译时间的影响还是挺大的，而且一般编译器的模板运算递归深度顶多一两千），看着图一乐就行了。\n","tags":["Cpp","Programming-Language","Data-Structure"]},{"title":"C++泛化的非侵入式访问者接口","url":"/2020/08/06/C++%E6%B3%9B%E5%8C%96%E7%9A%84%E9%9D%9E%E4%BE%B5%E5%85%A5%E5%BC%8F%E8%AE%BF%E9%97%AE%E8%80%85%E6%8E%A5%E5%8F%A3/","content":"前言前阵子看了下TVM的functor相关的源码和@Ubp.a的一篇有关非侵入式访问者接口的文章，有了点想法，试着写了一个较为泛化的非侵入式访问者接口。\n（对相关概念不熟的建议先看一下Ubp.a的文章）\n基本思路思路和Ubp.a的文章的类似：显式地保存一个虚表，在访问者类构造时将目标的子类和对应的派发函数登记到表上，在访问时根据传入的基类指针选择派发的函数：\n\n注：该代码中存在一些问题，std::type_info只实现了相等性的比较，不能直接作为std::map的索引类型，需要再套一个std::type_index。\n泛化的虚表通常来说在RTTI的支持下可以利用std::type_index和typeid来将一个静态类型或一个对象指针的动态类型转化为索引值，再利用std::map或std::unordered_map来检索。\n不过一方面RTTI本身带有不能忽视的开销，另一方面std::map等关联容器的检索开销相对于数组而言还是稍微有点大，因此有时用户可能会自行实现一套运行时类型接口，比如TVM就是如此。\n因此有必要对虚表进行泛化。不难看出，虚表主要需要支持两种操作：\n\nSet(Type t, Function f) -&gt; Void: 将t的派发函数设置为f\nGet(Object o) -&gt; Function: 返回对象o对应的派发函数。\n\n比如使用std::map和std::type_index检索的虚表可以抽象为：\ntemplate&lt;typename Base, typename Func&gt;class default_vtable {public:  template&lt;typename T&gt;  inline void Set(Func f) {    data_[std::type_index(typeid(T))] = f;  }  inline Func Get(Base *base) {    return data_[std::type_index(typeid(*base))];  }private:  std::map&lt;std::type_index, Func&gt; data_;};\n\n而TVM中使用的虚表（tvm::NodeFunctor）可以抽象为：\ntemplate &lt;typename Base, typename Func&gt;class node_vtable {public:    template &lt;typename TNode&gt;    inline void Set(Func f) {        uint32_t tindex = TNode::RuntimeTypeIndex();        if (func_.size() &lt;= tindex) {          func_.resize(tindex + 1, nullptr);        }        CHECK(func_[tindex] == nullptr)             &lt;&lt; \"Dispatch for \" &lt;&lt; TNode::_type_key &lt;&lt; \" is already set\";        func_[tindex] = f;    }    inline Func Get(Base *base) {        return func_[base-&gt;type_index()];    }private:    std::vector&lt;Func&gt; func_;}\n\n泛化的访问者接口侵入式的访问者接口（每个被访问类需要实现一个accept函数）除了侵入式这一个缺点以外，还有一个不太好的地方，就是因为accept函数需要实现为虚函数，因此不能对函数本身直接泛化（通常需要对class进行泛化），这就导致访问者函数不容易泛化，也就是说针对同一种被访问对象，不容易实现visit函数类型不同的访问者。\n非侵入式的接口则可以直接在接口类对visit函数类型进行泛化。\n我写的接口如下：\ntemplate&lt;typename, typename, typename, typename, \t\ttemplate&lt;typename, typename&gt; typename = default_vtable&gt;class GeneralVisitor;template&lt;typename Visitor, typename Base, typename ...Deriveds,        template&lt;typename, typename&gt; typename Vtable, typename R, typename ...Args&gt;class GeneralVisitor&lt;Visitor, Base, std::tuple&lt;Deriveds...&gt;, R(Args...), Vtable&gt; {  using VtableType = Vtable&lt;Base, R(*)(Visitor *, Base *, Args...)&gt;;public:  R Visit(Base *base, Args ...args) {    static VtableType vtable = BuildVtable();    return vtable.Get(base)(static_cast&lt;Visitor *&gt;(this), base, std::forward&lt;Args&gt;(args)...);  }private:  template&lt;typename Derived, typename ...Rest&gt;  static void Register(VtableType &amp;vtable) {    vtable.template Set&lt;Derived&gt;(            [](Visitor *visitor, Base *base, Args ...args) -&gt; R {              return visitor-&gt;ImplVisit(static_cast&lt;Derived *&gt;(base),                                         std::forward&lt;Args&gt;(args)...);            }    );    if constexpr (sizeof...(Rest) &gt; 0) {      Register&lt;Rest...&gt;(vtable);    }  }  static VtableType BuildVtable() {    VtableType vtable;    Register&lt;Deriveds...&gt;(vtable);    return vtable;  }};\n\n其中各个模板参数含义分别为：\n\nVisitor：访问者类\nBase：被访问的基类\nDeriveds：被访问的派生类\nR(Args...)：visit函数的类型\nVtable：虚表类型，默认为前文提到的用std::type_index和std::map实现的default_vtable。\n\n这边出于效率考虑，学习了TVM的一些做法：虚表保存的为函数指针而不是std::function容器（这样的话保存的函数需要多一个参数来传入Visitor*）；将虚表声明为Visit函数内的静态变量，这样一方面可以在Visit第一次调用时才进行虚表的初始化，另一方面对于每个继承同一个模板类的类，只需要保存一个虚表的实例。\n使用示例简单的计算器参见https://github.com/Light-of-Hers/GeneralVisitor\n","tags":["Cpp","Programming-Language"]},{"title":"C++获取函数的参数和返回值类型","url":"/2020/01/11/C++%E8%8E%B7%E5%8F%96%E5%87%BD%E6%95%B0%E7%9A%84%E5%8F%82%E6%95%B0%E5%92%8C%E8%BF%94%E5%9B%9E%E5%80%BC%E7%B1%BB%E5%9E%8B/","content":"C++函数主要分为两类：\n\n一类是继承自C的函数指针（普通函数可以通过std::decay后得到函数指针），其类型的模式可以直接写出：\n\ntemplate&lt;typename R, typename ...As&gt; R(*)(As...)\n\n另一类是可调用对象/函数对象，std::bind、std::function、lambda表达式等返回的都是函数对象。函数对象的类型没有一个固定的模式，但是都重载了operator()，而且其operator()函数的函数指针类型是可以模式化的：\n\ntemplate&lt;typename R, typename C, typename ...As&gt; R(C::*)(As...)\n\ntemplate&lt;typename R, typename C, typename ...As&gt; R(C::*)(As...) const\n\n\n这样就可以用一些TMP技巧来对函数进行分类并用相应的模式萃取出其参数和返回值类型了：\n\n针对std::reference_wrapper&lt;F&gt;，递归对其中包裹的类型F进行萃取。\n用R(*)(...As)模式匹配函数指针进行萃取。\n用R(C::*)(...As)或者R(C::*)(...As) const模式匹配类函数指针进行萃取。\n否则，默认其为函数对象，递归对其重载的operator()函数指针进行萃取。\n\n最后统一一个入口function_traits，先将传入的类型decay后（将函数转化为函数指针，去除引用，去除底层const等），再派发给__function_traits进行具体的匹配。\nnamespace detail {template&lt;typename R, typename ...As&gt;struct __function_traits_base {    using function_type = std::function&lt;R(As...)&gt;;    using result_type = R;    using argument_types = std::tuple&lt;As...&gt;;};template&lt;typename F&gt;struct __function_traits;template&lt;typename F&gt;struct __function_traits&lt;std::reference_wrapper&lt;F&gt;&gt; : public __function_traits&lt;F&gt; {};template&lt;typename R, typename ...As&gt;struct __function_traits&lt;R(*)(As...)&gt; : public __function_traits_base&lt;R, As...&gt; {};template&lt;typename R, typename C, typename ...As&gt;struct __function_traits&lt;R(C::*)(As...)&gt; : public __function_traits_base&lt;R, As...&gt; {};template&lt;typename R, typename C, typename ...As&gt;struct __function_traits&lt;R(C::*)(As...) const&gt; : public __function_traits_base&lt;R, As...&gt; {};template&lt;typename F&gt;struct __function_traits : public __function_traits&lt;decltype(&amp;F::operator())&gt; {};}namespace fp {template&lt;typename F&gt;struct function_traits : public detail::__function_traits&lt;std::decay_t&lt;F&gt;&gt; {};}","tags":["Cpp","Programming-Language"]},{"title":"CUTLASS 3.x CuTe Layout Composition 的一处纰漏","url":"/2024/08/18/CUTLASS%203.x%20CuTe%20Layout%20Composition%20%E7%9A%84%E4%B8%80%E5%A4%84%E7%BA%B0%E6%BC%8F/","content":"前言去年国庆时想写一下 CUTLASS 3.x 相关的博客（当时已经写了一部分 layout algebra 的内容），不过因为一些原因搁置了。在那之后知乎也出现了一些不错的博文来介绍 CUTLASS 3.x（比如 @reed 的系列博文），官方文档在半年前发布 3.4 版本的时候也更新了不少内容（感觉）。最近组里的一些活和这个有关系，就重新复习（预习）了一下官方的文档，过程中发现文档上关于 layout composition 满足左分配律的条件似乎有些纰漏，仔细研究了一下，发现确实只是个无伤大雅的纰漏，不过研究的过程还是有点意思的，就记录一下。\nCuTe Layout先简单介绍一下 CuTe Layout。一个 layout  可以看作两个 int-tuple 的组合 ，其中  和  分别称为  的 shape 和 stride（注：在 CuTe Layout 的实际定义中， 和  也可以是嵌套的 tuple，但在大部分时候可以将它们展平来看待，因此本文仅考虑非嵌套的 tuple）。 也可以表示为 ，其中每个  被称为  的一个 sub-layout。\n一个 layout  可以看作一个限制定义域的整数线性变换，将一个  维整数坐标  () 映射到一维坐标：\n\n每个 layout  都有一个 natural layout ，直观上理解就是一个 shape 和其相同的 contiguous column-major layout：\n\n 也可以接收一个一维坐标  作为参数，将其用  进行逆映射，得到一个  维坐标后，再映射到一个新的一维坐标，可以递归定义为（其中为取模符号）：\n\nLayout Composition由此可以定义 layout 的 composition 操作 ：两个 layout  和  的组合  满足 ，也就是  将多维坐标  映射为一维坐标  后再由  映射为一维坐标 。假设 ，，如果要让  仍然是个 layout（能表示成 shape:stride 的形式），则有如下要求（其中  表示  整除 ）：\n\\tag not allowed in aligned environment \\begin{aligned} &amp;\\exists 1\\le j\\le k\\le n : (\\pi_ {j-1}|w|\\pi_j)\\land (\\pi_ {k-1}|wx|\\pi_ {k})\\tag{1} \\ \\text{where }&amp; \\pi_k=\\prod_ {i=0}^k s_i\\quad (\\text{let }s_0=1) \\end{aligned} \n简单来说就是 stride  (以及整个 layout 所覆盖的范围 ) 在整除这个偏序关系上要介于  的某两个相邻的 shape 前缀积  和  之间。CuTe 实现上是通过 shape_div 和 shape_mod 操作的约束来表现这个限制，我这里将其本质概括了一下。\n关于左分配律满足条件的纰漏接下来就是 CuTe 的文档和实现上存在纰漏的地方了。前文讨论了形如当 ， 时， 的结果仍然是合法的 layout 的条件。而对于一般的情况，也就是 ， 时，官方的文档认为当  是单射函数时，满足左分配律 。这个结论咋一看挺显然的，但是稍微推理一下就发现并不是这么回事。\n对于任意  () ，我们有：\n\n要让 ，就要有：\n\n简单起见，我们这里仅讨论  的情况。设 ，设 ， ，有：\n\n因为 ，所以有：\nMisplaced & 0=d_1(r-r%s_1)-d_2\\lfloor r/s_1\\rfloor=\\begin{cases} 0 &amp; 0\\le r\\le s_1-1\\ d_1s_1-d_2 &amp; s_1\\le r\\le 2s_1-2 \\end{cases} \n也就是说以下条件至少要成立一个：\n\\tag not allowed in aligned environment \\begin{aligned} &amp;\\forall 0\\le c_i &lt; x_i:\\sum_ {i=1}^2(w_ic_i)%s_1 &lt; s_1\\tag{2}\\ &amp;d_1s_1=d_2\\tag{3} \\end{aligned} \n条件可以转化为：\n\n考虑到约束的要求，有：\n\n不难看出条件有可能都不满足，即使按照官方文档的要求  是单射函数。我们可以构造一个简单的例子，令 ，，显然  是个单射函数，但是条件和都不满足。可以编写代码验证一下（这里为方便起见用到了 CuTe 的 python 接口 pycute，可以参考官方文档进行安装）：\nimport pycuteL = pycute.Layout((36, 18), (1, 72))P = pycute.Layout((9, 4), (4, 9))Q = pycute.composition(L, P)print(f\"L = {L}\")print(f\"P = {P}\")print(f\"Q = {Q}\")vis = set()for c in range(P.size()):    p = P(c)    if p in vis:        print(\"P is not injective\")    vis.add(p)    expected, actual = L(p), Q(c)    if expected != actual:        print(f\"(L o P)({c}) = L(P({c})) = {expected} != {actual} = Q({c})\")\n输出结果如下：\nL = (36, 18):(1, 72)P = (9, 4):(4, 9)Q = (9, 4):(4, 9)(L o P)(16) = L(P(16)) = 73 != 37 = Q(16)(L o P)(17) = L(P(17)) = 77 != 41 = Q(17)(L o P)(23) = L(P(23)) = 74 != 38 = Q(23)(L o P)(24) = L(P(24)) = 78 != 42 = Q(24)(L o P)(25) = L(P(25)) = 82 != 46 = Q(25)(L o P)(26) = L(P(26)) = 86 != 50 = Q(26)(L o P)(30) = L(P(30)) = 75 != 39 = Q(30)(L o P)(31) = L(P(31)) = 79 != 43 = Q(31)(L o P)(32) = L(P(32)) = 83 != 47 = Q(32)(L o P)(33) = L(P(33)) = 87 != 51 = Q(33)(L o P)(34) = L(P(34)) = 91 != 55 = Q(34)(L o P)(35) = L(P(35)) = 95 != 59 = Q(35)\n既然官方的实现存在这样的纰漏，那些使用了 CUTLASS 3.x 的算子岂不是可能有 BUG？这点应该不用担心，目前来说大概是没什么问题的，据我观察官方使用到 composition 的场合， 中的  总是满足 （不失一般性，假设  的 sub-layout 按 stride 升序排序，也就是 ），在这个条件下，layout composition 总是满足左分配律的。事实上，日常中使用的 layout 一般也确实满足这个条件，而且 layout complement 操作的合法性检查似乎也会保证这个性质（composition 经常和 complement 结合着使用）。至于为什么这个条件是 layout composition 满足左分配律的一个充分条件，以后有空再写写证明吧……\n","tags":["HPC","CUDA","ML-Compiler","CUTLASS"]},{"title":"MIT 6.828 JOS Lab1 实验报告","url":"/2020/10/05/MIT%206.828%20JOS%20Lab1%20%E5%AE%9E%E9%AA%8C%E6%8A%A5%E5%91%8A/","content":"前言此为本人上本校的操作系统实习(实验班)时所写的实验报告，简单记述了JOS Lab的各个Exercise、Challenge(未覆盖所有Challenge，每个Lab大概做了1~3个Challenge)的基本思路。仅供有需者参考，上有关课程(比如本校的操统实习实验班)的最好不要直接抄。\n附上源代码链接：https://github.com/Light-of-Hers/mit-jos\nExercise 1略\nExercise 2跳转到bootloader前的指令：\n[f000:fff0]    0xffff0:\tljmp   $0xf000,$0xe05b0x0000fff0 in ?? ()(gdb) si[f000:e05b]    0xfe05b:\tcmpl   $0x0,%cs:0x70c80x0000e05b in ?? ()(gdb) si[f000:e062]    0xfe062:\tjne    0xfd4140x0000e062 in ?? ()(gdb) si[f000:e066]    0xfe066:\txor    %dx,%dx0x0000e066 in ?? ()(gdb) si[f000:e068]    0xfe068:\tmov    %dx,%ss0x0000e068 in ?? ()(gdb) si[f000:e06a]    0xfe06a:\tmov    $0x7000,%esp0x0000e06a in ?? ()(gdb) si[f000:e070]    0xfe070:\tmov    $0xf2d4e,%edx0x0000e070 in ?? ()(gdb) si[f000:e076]    0xfe076:\tjmp    0xfff000x0000e076 in ?? ()\n\n在ROM上进行一些初始化工作，如：检查RAM，初始化硬件，初始化段寄存器ss和栈指针esp等。之后跳转到bootloader，即RAM地址0x7c00处（和GDB显示的不一致）\nExercise 3\nQ1: At what point does the processor start executing 32-bit code? What exactly causes the switch from 16- to 32-bit mode?\n\n在执行了ljmp $PROT_MODE_CSEG, $protcseg后，处理器跳转到32位代码。\n在以下代码执行，使能了A20总线后，处理器从16位模式进入32位模式。\nseta20.1:    inb     $0x64,%al               # Wait for not busy    testb   $0x2,%al    jnz     seta20.1    movb    $0xd1,%al               # 0xd1 -&gt; port 0x64    outb    %al,$0x64seta20.2:    inb     $0x64,%al               # Wait for not busy    testb   $0x2,%al    jnz     seta20.2    movb    $0xdf,%al               # 0xdf -&gt; port 0x60    outb    %al,$0x60\n\n\nQ2: What is the last instruction of the boot loader executed, and what is the first instruction of the kernel it just loaded?\n\nbootloader最后执行的语句及其对应的指令为:\n((void (*)(void)) (ELFHDR-&gt;e_entry))();  7d6b:\tff 15 18 00 01 00    \tcall   *0x10018\n\nkernel被加载进来时执行的第一个指令为:\nmovw\t$0x1234,0x472\t\t\t# warm boot\n\n\nQ3: Where is the first instruction of the kernel?\n\n内核执行的第一条指令位于0x10000c\n\nQ4: How does the boot loader decide how many sectors it must read in order to fetch the entire kernel from disk? Where does it find this information?\n\n\n根据elf文件结构体的e_phoff字段确定第一个程序段头（program segment header）的偏移\n根据e_phnum字段确定程序段头的数量\n依次读入各个程序段头：根据其结构体的p_memsz获取对应程序段（program segment）所占的大小，再据此算出该读入多少扇区（sector）\n\nExercise 4略\nExercise 5\nQ: Identify the first instruction that would “break” or otherwise do the wrong thing if you were to get the boot loader’s link address wrong.\n\n会引起错误的第一条指令为\nljmp    $PROT_MODE_CSEG, $protcseg\n\n因为protcseg不是位置无关代码（position indepandent code）。该地址在链接时确定，但是BIOS将bootloader加载到的地址却是固定的（0x7c00）。因此若改变了链接地址，会导致该指令跳转到错误的位置。\n当然，事实上之前的lgdt　gdtdesc指令也会加载错误位置的GDT，但是影响并没有ljmp这样快而直接。\nExercise 6\nQ: Examine the 8 words of memory at 0x00100000 at the point the BIOS enters the boot loader, and then again at the point the boot loader enters the kernel. Why are they different? What is there at the second breakpoint?\n\n在刚进入bootloader时，那些内存位置均为0\n进入kernel时，内存数据如下：\n(gdb) x/8x 0x1000000x100000:\t0x1badb002\t0x00000000\t0xe4524ffe\t0x7205c7660x100010:\t0x34000004\t0x2000b812\t0x220f0011\t0xc0200fd8\n\n这些数据为bootloader所加载的.text段的开头：\n// entry.S.text.align 4.long MULTIBOOT_HEADER_MAGIC.long MULTIBOOT_HEADER_FLAGS.long CHECKSUM.globl\t\t_start_start = RELOC(entry).globl entryentry:\tmovw\t$0x1234,0x472\tmovl\t$(RELOC(entry_pgdir)), %eax\tmovl\t%eax, %cr3\tmovl\t%cr0, %eax    ...\n\n// kernel.asm.globl entryentry:f0100000:\t02 b0 ad 1b 00 00    \tadd    0x1bad(%eax),%dhf0100006:\t00 00                \tadd    %al,(%eax)f0100008:\tfe 4f 52             \tdecb   0x52(%edi)f010000b:\te4                   \t.byte 0xe4f010000c &lt;entry&gt;:f010000c:\t66 c7 05 72 04 00 00 \tmovw   $0x1234,0x472f0100013:\t34 12 f0100015:\tb8 00 20 11 00       \tmov    $0x112000,%eaxf010001a:\t0f 22 d8             \tmov    %eax,%cr3f010001d:\t0f 20 c0             \tmov    %cr0,%eaxf0100020:\t......\n\nExercise 7\nQ: What is the first instruction after the new mapping is established that would fail to work properly if the mapping weren’t in place?\n\n初次出问题的指令：\njmp\t*%eax\n\n此时%eax储存的为0xf010002f，若初始使用的页表没有合理映射，可能会使跳转出问题。\nExercise 8\nWe have omitted a small fragment of code - the code necessary to print octal numbers using patterns of the form “%o”. Find and fill in this code fragment.\n\n修改printfmt.c中的vprintfmt函数：\n// (unsigned) octalcase 'o':    // Replace this with your code.    num = getuint(&amp;ap, lflag);    base = 8;    goto number;\n\n\nQ1: Explain the interface between printf.c and console.c. Specifically, what function does console.c export? How is this function used by printf.c?\n\nconsole.c导出cputchar函数供printf.c中的putch函数使用：\n// printf.cstatic voidputch(int ch, int *cnt){\tcputchar(ch); // from console.c\t*cnt++;}\n\nprintf.c中的putch作为参数传入printfmt.c中的vprintfmt函数\n\nQ2: Explain the following from console.c:\n\n1 if (crt_pos &gt;= CRT_SIZE) {2   int i;3   memmove(crt_buf, crt_buf + CRT_COLS, (CRT_SIZE - CRT_COLS) * sizeof(uint16_t));4   for (i = CRT_SIZE - CRT_COLS; i &lt; CRT_SIZE; i++)5       crt_buf[i] = 0x0700 | ' ';6   crt_pos -= CRT_COLS;7 }\n\n改段代码用于滚屏，也就是当当前输出位置crt_pos大于屏幕容量的时候，不断将屏幕上移（每次上移一行）并更新crt_pos，直到crt_pos位于屏幕内。\n\nQ3: Answer the following questions:\n\nint x = 1, y = 3, z = 4;cprintf(\"x %d, y %x, z %d\\n\", x, y, z);\n\n\nQ3.1: In the call to cprintf(), to what does fmt point? To what does ap point?\n\nfmt指向字符串\"x %d, y %x, z %d\\n\"，也即8(%ebp)位置处的第一个参数。ap指向可变参数列表，也即12(%ebp)位置处的第二个参数\n\nQ3.2: List (in order of execution) each call to cons_putc, va_arg, and vcprintf. For cons_putc, list its argument as well. For va_arg, list what ap points to before and after the call. For vcprintf list the values of its two arguments.\n\nvcprintf(\"x %d, y %x, z %d\\n\", va_list{x, y, z})cons_putc('x')cons_putc(' ')va_arg, ap: va_list{x, y, z} =&gt; va_list{y, z}cons_putc('1')cons_putc(',')cons_putc(' ')cons_putc('y')cons_putc(' ')va_arg, ap: va_list{y, z} =&gt; va_list{z}cons_putc('3')cons_putc(',')cons_putc(' ')cons_putc('z')cons_putc(' ')va_arg, ap: va_list{z} =&gt; va_list{}cons_putc('4')cons_putc('4')cons_putc('\\n')\n\n\nQ4: What is the output? Explain how this output is arrived at in the step-by-step manner of the previous exercise. Here’s an ASCII table that maps bytes to characters.\nThe output depends on that fact that the x86 is little-endian. If the x86 were instead big-endian what would you set i to in order to yield the same output? Would you need to change 57616 to a different value?\n\nunsigned int i = 0x00646c72;cprintf(\"H%x Wo%s\", 57616, &amp;i);\n\n输出为He110 World\n57616的16进制表示为110，而十六进制数72,6c,64在ASCII码中对应的字符分别为r, l, d\n若为大端法，则只需令i = 0x726c6400，无需改动57616\n\nQ5: In the following code, what is going to be printed after ‘y=’? (note: the answer is not a specific value.) Why does this happen?\n\ncprintf(\"x=%d y=%d\", 3);\n\n将会输出12(%ebp)处的值\n\nQ6: Let’s say that GCC changed its calling convention so that it pushed arguments on the stack in declaration order, so that the last argument is pushed last. How would you have to change cprintf or its interface so that it would still be possible to pass it a variable number of arguments?\n\n将其接口改为\ncprintf(..., int n, const char* fmt)\n\n其中n可变参数的个数。\n或者\ncprintf(..., const char* fmt)\n\n其中可变参数倒序输入。\n如果可变参数正序输入但是又没有输入其个数的话，会给后续的处理带来不必要的麻烦（可能需要至少两趟对fmt的遍历）\nExercise 9\nQ: Determine where the kernel initializes its stack, and exactly where in memory its stack is located. How does the kernel reserve space for its stack? And at which “end” of this reserved area is the stack pointer initialized to point to?\n\n初始化栈指针的指令为：\n// entry.Smovl\t$(bootstacktop),%esp\n\n初始的栈所在位置为一个.data段：\n// entry.S.data\t.p2align\tPGSHIFT\t.globl\t\tbootstackbootstack:\t.space\t\tKSTKSIZE\t.globl\t\tbootstacktop   bootstacktop:\n\n如上述代码，采用.space KSTKSIZE为栈静态分配空间\n栈指针初始指向bootstacktop，即该栈空间的地址最高处\nExercise 10\nQ: How many 32-bit words does each recursive nesting level of test_backtrace push on the stack, and what are those words?\n\n递归调用自身时，test_backtrace先将x-1压栈，再将返回地址压栈，再将%ebp压栈，共3个32位数。\nExercise 11-12在commands中插入：\n{\"backtrace\", \"Backtrace the call of functions\", mon_backtrace},\n\n在monitor添加函数：\nintmon_backtrace(int argc, char **argv, struct Trapframe *tf){\t// Your code here.    uint32_t ebp, eip, arg;    struct Eipdebuginfo info;    cprintf(\"Stack backtrace:\\n\");\t// backtrace the ebp chain    for(ebp = read_ebp(); ebp != 0; ebp = *(uint32_t*)(ebp)) {        cprintf(\"  ebp %08x\", ebp);        eip = *((uint32_t*)ebp + 1);        cprintf(\"  eip %08x\", eip);        cprintf(\"  args\");        for(int i=0; i&lt;5; ++i) {            arg = *((uint32_t*)ebp + 2 + i);            cprintf(\" %08x\", arg);        }        cprintf(\"\\n\");\t\t// get eip info        debuginfo_eip(eip, &amp;info);        cprintf(\"         %s:%d: %.*s+%u\\n\",             info.eip_file,             info.eip_line,             info.eip_fn_namelen, info.eip_fn_name,             eip - info.eip_fn_addr);    }    return 0;}\n\n在debuginfo_eip函数中插入：\n// Your code here.stab_binsearch(stabs, &amp;lline, &amp;rline, N_SLINE, addr);if (lline &gt; rline)    return -1;info-&gt;eip_line = stabs[lline].n_desc;\n\nThis completes the lab-1running JOS: (0.7s)   printf: OK   backtrace count: OK   backtrace arguments: OK   backtrace symbols: OK   backtrace lines: OK Score: 50/50\n\nChallenge采用ANSI ESC Sequence嵌入来实现彩色字体的显示，如：\n\"Hello World\" =&gt; \"\\033[&lt;Param1&gt;;&lt;Param2&gt;;...mHello World\\033[0m\"\n\n其中&lt;ParamN&gt;为参数，其中决定颜色的参数为：（参见 http://rrbrandt.dee.ufcg.edu.br/en/docs/ansi/ ）\ncga_putc函数（打印到Qemu的console）暂时不会处理ANSI Escape Sequence，而serial_putc函数（打印到用户Terminal）会处理。这就导致了两者的打印内容的差异。因此要先修改cga_putc以改变VGA的输出行为。\n在VGA的text-mode下，buffer中填充的数据的位域构成如下（参见 https://os.phil-opp.com/vga-text-mode/ ）：\n\n其中color部分数值对应的颜色为：\n\n因此修改console.c的cga_putc函数：\n// Old cga_putcstatic voidcga_putc1(int c){\t// if no attribute given, then use black on white\tif (!(c &amp; ~0xFF))\t\tc |= 0x0700;\tswitch (c &amp; 0xff) {\tcase '\\b':\t\tif (crt_pos &gt; 0) {\t\t\tcrt_pos--;\t\t\tcrt_buf[crt_pos] = (c &amp; ~0xff) | ' ';\t\t}\t\tbreak;\tcase '\\n':\t\tcrt_pos += CRT_COLS;\t\t/* fallthru */\tcase '\\r':\t\tcrt_pos -= (crt_pos % CRT_COLS);\t\tbreak;\tcase '\\t':\t\tcons_putc(' ');\t\tcons_putc(' ');\t\tcons_putc(' ');\t\tcons_putc(' ');\t\tcons_putc(' ');\t\tbreak;\tdefault:\t\tcrt_buf[crt_pos++] = c;\t\t/* write the character */\t\tbreak;\t}\t// What is the purpose of this?\tif (crt_pos &gt;= CRT_SIZE) {\t\tint i;\t\tmemmove(crt_buf, crt_buf + CRT_COLS, (CRT_SIZE - CRT_COLS) * sizeof(uint16_t));\t\tfor (i = CRT_SIZE - CRT_COLS; i &lt; CRT_SIZE; i++)\t\t\tcrt_buf[i] = 0x0700 | ' ';\t\tcrt_pos -= CRT_COLS;\t}\t/* move that little blinky thing */\t/* just move the cursor */\toutb(addr_6845, 14);\toutb(addr_6845 + 1, crt_pos &gt;&gt; 8);\toutb(addr_6845, 15);\toutb(addr_6845 + 1, crt_pos);}static intisdigit(int c){\treturn c &gt;= '0' &amp;&amp; c &lt;= '9';}static int atoi(const char* s){\tint res = 0;\tfor (int i = 0; isdigit(s[i]); ++i)\t\tres = res * 10 + (s[i] - '0');\treturn res;}// Modify the VGA text-mode character attribute 'attr' // based on the parameter contained in the buf.static voidhandle_ansi_esc_param(const char* buf, int len, int* attr){\t// white is light grey\tstatic int ansi2cga[] = {0x0, 0x4, 0x2, 0xe, 0x1, 0x5, 0x3, 0x7};\tint tmp_attr = *attr;\tint n = atoi(buf);\tif (n &gt;= 30 &amp;&amp; n &lt;= 37) {\t\ttmp_attr = (tmp_attr &amp; ~(0x0f)) | ansi2cga[n - 30];\t} else if (n &gt;= 40 &amp;&amp; n &lt;= 47) {\t\ttmp_attr = (tmp_attr &amp; ~(0xf0)) | (ansi2cga[n - 40] &lt;&lt; 4);\t} else if (n == 0) {\t\ttmp_attr = 0x07;\t}\t*attr = tmp_attr;}// The max length of one parameter.// Emmmmmm... no body will input // a number parameter with length of 1023, probably.#define ESC_BUFSZ 1024// If the character is '\\033' (esc), then buffer the input// until get a whole ANSI Esc Seq (and update the attribute) // or get a false input midway.// Otherwise output it normally.// // Use a deterministic finite automata:// // [0]: '\\033'\t=&gt; [1]// \t\tother\t=&gt; [0] + output the character// // [1]: '\\033'\t=&gt; [1]// \t\t'['\t\t=&gt; [2]// \t\tother\t=&gt; [0]// // [2]: digit\t=&gt; [3] + begin record the modification// \t\tother\t=&gt; [0] + discard the modification// // [3]: digit\t=&gt; [3]// \t\t';'\t\t=&gt; [2] + record the modification of attribute// \t\t'm'\t\t=&gt; [0] + update the attribute// \t\tother \t=&gt; [0] + discard the modification// static void cga_putc(int c){\tstatic int state = 0;\tstatic char esc_buf[ESC_BUFSZ];\tstatic int esc_len = 0;\tstatic int attr = 0; // default attribute.\tstatic int esc_attr = 0;\tswitch(state) {\tcase 0: {\t\tif ((char)c == '\\033') {\t\t\tstate = 1;\t\t} else {\t\t\tcga_putc1((attr &lt;&lt; 8) | (c &amp; 0xff));\t\t}\t\tbreak;\t}\tcase 1: {\t\tif ((char)c == '[') {\t\t\tesc_attr = attr;\t\t\tstate = 2;\t\t} else if ((char)c != '\\033') {\t\t\tstate = 0;\t\t}\t\tbreak;\t}\tcase 2: {\t\tif (isdigit(c)) {\t\t\tesc_buf[esc_len++] = (char)c;\t\t\tstate = 3;\t\t} else {\t\t\t// discard modification\t\t\tesc_len = 0;\t\t\tstate = 0;\t\t}\t\tbreak;\t}\tcase 3: {\t\tif (isdigit(c)) {\t\t\tesc_buf[esc_len++] = (char)c;\t\t} else if ((char)c == ';') {\t\t\t// record current modification\t\t\tesc_buf[esc_len++] = 0;\t\t\thandle_ansi_esc_param(esc_buf, esc_len, &amp;esc_attr);\t\t\tesc_len = 0;\t\t\tstate = 2;\t\t} else if ((char)c == 'm') {\t\t\t// update the attribute\t\t\tesc_buf[esc_len++] = 0;\t\t\thandle_ansi_esc_param(esc_buf, esc_len, &amp;esc_attr);\t\t\tesc_len = 0;\t\t\tattr = esc_attr;\t\t\tstate = 0;\t\t} else {\t\t\t// discard modification\t\t\tesc_len = 0;\t\t\tstate = 0;\t\t}\t\tbreak;\t}\t}}\n\n这样VGA就支持ANSI Escape Sequence了。除了只会接受数字参数（最长为1023，虽然并没有这么长的数字参数……），只会处理颜色参数（前景色、背景色）和重置参数之外，其余行为与bash的行为一致，如后出现的参数会覆盖之前出现的与其不相容的参数（例如后出现的前景色会覆盖前出现的前景色）等。\n为了方便设置颜色，在stdio.h中加入颜色设置接口：\n// color enumenum {    COLOR_BLACK = 0,    COLOR_RED,    COLOR_GREEN,    COLOR_YELLOW,    COLOR_BLUE,    COLOR_MAGENTA,    COLOR_CYAN,    COLOR_WHITE,    COLOR_NUM,};// set and reset the foreground colorvoid set_fgcolor(int color);void reset_fgcolor();// set and reset the background colorvoid set_bgcolor(int color);void reset_bgcolor();\n\n在printf.c中实现接口：\nstatic int fgclr = -1;static int bgclr = -1;static const char numbers[] = \"0123456789\";void set_fgcolor(int clr) {\tfgclr = clr;\tcprintf(\"\\033[3%cm\", numbers[clr]);}voidset_bgcolor(int clr){\tbgclr = clr;\tcprintf(\"\\033[4%cm\", numbers[clr]);}void reset_fgcolor(){\tcprintf(\"\\033[0m\");\tif (bgclr != -1)\t\tcprintf(\"\\033[4%cm\", numbers[bgclr]);\tfgclr = -1;}void reset_bgcolor(){\tcprintf(\"\\033[0m\");\tif (fgclr != -1)\t\tcprintf(\"\\033[3%cm\", numbers[fgclr]);\tbgclr = -1;}\n\n在init.c中添加一些有趣的测试：\nvoid rainbow(int stride){\tstatic const char msg[] = \"rainbow!\";\tfor (int i = 0; i &lt; COLOR_NUM; ++i) {\t\tset_fgcolor(i);\t\tset_bgcolor((i + stride) % COLOR_NUM);\t\tcprintf(\"%c\", msg[i % (sizeof(msg) - 1)]);\t}\treset_fgcolor();\treset_bgcolor();\t\tcprintf(\"\\n\");}void test_rainbow(){\tfor(int i = 1; i &lt; COLOR_NUM; ++i)\t\trainbow(i);}\n\n测试效果：\n\nQemu Console：\n\n\nUser Terminal：\n\n\n\nSome problems about stab_binsearch当stabs[m].n_value == addr时，原始代码的处理感觉有些问题：\n// exact match for 'addr', but continue loop to find// *region_right*region_left = m;l = m;addr++;\n\n万一addr+1处的地址也是符合所要求的type时，所得到的匹配范围就会出错。\n因此建议改成：\n// exact match for 'addr', but continue loop to find// *region_right*region_left = m;// l = m;// addr++;l = m + 1;\n\n因为已经有一个恰好匹配了，所以之后的stabs[m].n_value必然比addr大，故而不会修改*region_left，而且找到的*region_right也符合定义。\n还有关于最后的else分句：\n// find rightmost region containing 'addr'for (l = *region_right;    l &gt; *region_left &amp;&amp; stabs[l].n_type != type;    l--)/* do nothing */;*region_left = l;\n\n个人感觉也不是必要的，因为前面的循环（修改后）已经保证*region_left + 1和*region_right之间没有符合type的symbol了。\nSome extension of the console/serial input感觉qemu-console和user-terminal的键盘输入不是很舒服，主要有两点：\n\nuser-terminal的backspace只会回退光标，不会删除字符；而且backspace过多让光标回退到prompt之前……和qemu-console的行为不一致。\n无法左右移动光标以在输入字符串中间进行插入和删除。\n\n因此针对这两点对readline函数进行改进（会涉及到一处对cga_putc函数的修改）\nBackspace\nuser-terminal的backspace只会回退光标，而qemu-console的backspace同时还会删除字符，两者行为不一致。因为我们只是单纯地将输入信息通过串行总线传给user-terminal，对于输入的处理以及显示是由user-terminal内部完成的，因此应将user-terminal的行为视为标准（而且这样仅回退不删除的行为也有利于后续光标移动的实现）：\n\n修改cga_putc（严格来说是cga_putc1，因为之前challenge的修改）中对backspace'\\b'的处理：\n  case '\\b':\t// Change the behavior of backspace to support character insert.\t// Maintain the character in `crt_pos`.\tif (crt_pos &gt; 0) {\t\tcrt_pos--;\t\t// crt_buf[crt_pos] = (c &amp; ~0xff) | ' ';\t}\tbreak;\n\n将（在输入字符串尾部）退格的操作实现为：\n  cputchar('\\b'), cputchar(' '), cputchar('\\b');\n\n\nuser-terminal的backspace甚至会让光标回退到prompt之前。在gdb上截获输入的字符，发现在（我的）user-terminal上输入backspace得到的字符是DEL(0x7f)，比空格' '的ASCII码更大。也就是说在原始版本的readline中，当i == 0时，在user-terminal输入backspace虽然不会进入到处理退格的语句中（判断条件为(c == '\\b' || c == '\\x7f') &amp;&amp; i &gt; 0），但是会进入到正常回显字符的语句中（判断条件为c &gt;= ' ' &amp;&amp; i &lt; BUFLEN - 1），因此将正常回显字符的判断条件改为：\n  c &gt;= ' ' &amp;&amp; c &lt;= '~' &amp;&amp; i &lt; BUFLEN - 1\n\nCursor movement\n首先应知道左右方向键的输入是什么。经查阅资料（ https://stackoverflow.com/questions/22397289/finding-the-values-of-the-arrow-keys-in-python-why-are-they-triples , https://www.ascii-code.com/ ）以及在gdb上截获输入字符，发现user-terminal和qemu-console输入方向键得到的字符不一样：\n\nuser-terminal为一个escape sequence：\nleft arrow: '0x1b','[','D'\nright arrow: '0x1b', '[', 'C'\n\n\nqemu-terminal为一个extended ASCII code：\nleft arrow: 228\nright arrow: 229\n\n\n\n\nqemu-console（kbd_intr）会无视ESC的输入，而user-terminal不会输入extended ASCII code。因此对两种情况分别处理，不会有冲突。\n\n为了不破坏封装性，因此仅对readline.c进行修改，仅以getchar和cputchar函数为与底层交互的接口。采用最直接的单buffer算法，每次插入/删除字符都要进行buffer的拷贝移动并将更新的部分（以及之后的部分）重新flush到display上，单次操作的平均复杂度为O(N)，不过因为本身输入的量很少（buffer的大小只有1024 Byte，平时的终端输入更是不会超过50 Byte），所以使用起来并没有延迟感。代码如下：\n #include &lt;inc/stdio.h&gt;#include &lt;inc/error.h&gt;#include &lt;inc/string.h&gt;  // Handle the extended ASCII code inputed by console inline static void handle_ext_ascii(int c); // Handle the escape sequence inputed by serial (user-terminal) inline static void handle_esc_seq(void); // Move the cursor right inline static void move_right(void); // Move the cursor left inline static void move_left(void); // Flush buffer's [cur, tail) to the displays // and move the cursor back inline static void flush_buf(void); // Insert char to current cursor inline static void insert_char(int c); // Remove current cursor's char inline static void remove_char(void); // Terminate the input inline static void end_input(void); #define BUFLEN 1024 static char buf[BUFLEN]; // Current position of cursor static int cur; // Tail of buffer static int tail; static int echoing; char * readline(const char *prompt) { \tint c; \tif (prompt != NULL) \t\tcprintf(\"%s\", prompt); \tcur = tail = 0; \techoing = iscons(0); \twhile (1) { \t\tc = getchar(); \t\tif (c &lt; 0) { \t\t\tcprintf(\"read error: %e\\n\", c); \t\t\treturn NULL; \t\t} else if ((c == '\\b' || c == '\\x7f') &amp;&amp; cur &gt; 0) { \t\t\tremove_char(); \t\t} else if (c &gt;= ' ' &amp;&amp; c &lt;= '~' &amp;&amp; tail &lt; BUFLEN-1) { \t\t\t// Must have c &lt;= '~', \t\t\t// because DEL(0x7f) is larger than '~' \t\t\t// and it will be inputed when you push \t\t\t// 'backspace' in user-terminal \t\t\tinsert_char(c); \t\t} else if (c == '\\n' || c == '\\r') { \t\t\tend_input(); \t\t\treturn buf; \t\t} else if (c == '\\x1b') { \t\t\thandle_esc_seq(); // only serial will input esc \t\t} else if (c &gt; '\\x7f') { \t\t\thandle_ext_ascii(c); // only console will input extended ascii \t\t} \t} } inline static void  flush_buf(void) { \tfor (int i = cur; i &lt; tail; ++i) \t\tcputchar(buf[i]); \tfor (int i = cur; i &lt; tail; ++i) \t\tcputchar('\\b'); // cursor move back } inline static void  insert_char(int c)  { \tif (cur == tail) { \t\ttail++, buf[cur++] = c; \t\tif (echoing) \t\t\tcputchar(c); \t} else { // general case \t\tmemmove(buf + cur + 1, buf + cur, tail - cur); \t\tbuf[cur] = c, tail++; \t\tif (echoing)  \t\t\tflush_buf(); \t\tmove_right(); \t} } inline static void  remove_char(void) { \tif (cur == tail) { \t\tcur--, tail--; \t\tif (echoing) \t\t\tcputchar('\\b'), cputchar(' '), cputchar('\\b'); \t} else { // general case \t\tmemmove(buf + cur - 1, buf + cur, tail - cur); \t\tbuf[tail - 1] = ' '; \t\tmove_left(); \t\tif (echoing) \t\t\tflush_buf(); \t\ttail--; \t} } inline static void  move_left(void) { \tif (cur &gt; 0) { \t\tif (echoing) \t\t\tcputchar('\\b'); \t\tcur--; \t} } inline static void  move_right(void) { \tif (cur &lt; tail) { \t\tif (echoing) \t\t\tcputchar(buf[cur]); \t\tcur++; \t} } inline static void  end_input(void) { \tif (echoing) { \t\tfor (; cur &lt; tail; cputchar(buf[cur++])) \t\t\t/* move the cursor to the tail */; \t\tcputchar('\\n'); \t} \tcur = tail; \tbuf[tail] = 0; } #define EXT_ASCII_LF 228 #define EXT_ASCII_RT 229 #define EXT_ASCII_UP 226 #define EXT_ASCII_DN 227 inline static void  handle_ext_ascii(int c) { \tswitch(c) { \tcase EXT_ASCII_LF: \t\tmove_left(); \t\treturn; \tcase EXT_ASCII_RT:  \t\tmove_right(); \t\treturn; \t} \tinsert_char(c); } #define ESC_LF 'D' #define ESC_RT 'C' #define ESC_UP 'A' #define ESC_DN 'B' inline static void  handle_esc_seq(void) { \tchar a, b = 0; \ta = getchar(); \tif (a == '[') { \t\tswitch(b = getchar()) { \t\tcase ESC_LF:  \t\t\tmove_left(); \t\t\treturn; \t\tcase ESC_RT: \t\t\tmove_right(); \t\t\treturn;  \t\t} \t} \tinsert_char(a); \tif (b) \t\tinsert_char(b); }\n\n当前的实现存在一定缺陷。主要是user-terminal最多只能让光标backspace到当前行开头。以后有空再改进一下吧。\n","tags":["OS"]},{"title":"MIT 6.828 JOS Lab2 实验报告","url":"/2020/10/05/MIT%206.828%20JOS%20Lab2%20%E5%AE%9E%E9%AA%8C%E6%8A%A5%E5%91%8A/","content":"前言此为本人上本校的操作系统实习(实验班)时所写的实验报告，简单记述了JOS Lab的各个Exercise、Challenge(未覆盖所有Challenge，每个Lab大概做了1~3个Challenge)的基本思路。仅供有需者参考，上有关课程(比如本校的操统实习实验班)的最好不要直接抄。\n附上源代码链接：https://github.com/Light-of-Hers/mit-jos\nExercise 1boot_alloc直接返回nextfree，并将nextfree增加alloc的空间（对齐后）即可。\nresult = nextfree;if (n &gt; 0)     nextfree = (char*)ROUNDUP((uint32_t)nextfree + n, PGSIZE);return result;\n\nmem_init使用boot_alloc申请空间，并初始化为0。\npages = (struct PageInfo *) boot_alloc(npages * sizeof(struct PageInfo));memset(pages, 0, npages * sizeof(struct PageInfo));\n\npage_init先定义两个工具宏，用于设置第_i号页是否为可分配页\n#define MARK_FREE(_i) do {\\    pages[_i].pp_ref = 0;\\    pages[_i].pp_link = page_free_list;\\\tpage_free_list = &amp;pages[_i];\\} while(0)#define MARK_USE(_i) do {\\    pages[_i].pp_ref = 0;\\    pages[_i].pp_link = NULL;\\} while(0)\n\n提前声明一些变量，并进行一些初始化。其中bss_end为kernel的.bss段的尾部，boot_alloc_end为之前使用boot_alloc分配空间的尾部。\nextern char end[];physaddr_t bss_end;physaddr_t boot_alloc_end;size_t i;page_free_list = NULL;bss_end = PADDR(ROUNDUP((char*)end, PGSIZE));boot_alloc_end = PADDR(boot_alloc(0));\n\n第零页不可分配：\nMARK_USE(0);\n\n第一到第npages_basemem页可分配：\nfor (i = 1; i &lt; npages_basemem; ++i)    MARK_FREE(i);\n\n[IOPHYSMEM, EXTPHYSMEM)不可分配：\nfor (i = IOPHYSMEM / PGSIZE; i &lt; EXTPHYSMEM / PGSIZE; ++i)    MARK_USE(i);\n\n[EXTPHYSMEM, boot_alloc_end)不可分配：\nfor (i = EXTPHYSMEM / PGSIZE; i &lt; bss_end / PGSIZE; ++i)    MARK_USE(i);for (i = bss_end / PGSIZE; i &lt; boot_alloc_end / PGSIZE; ++i)    MARK_USE(i);\n\n剩下的可分配：\nfor (i = boot_alloc_end / PGSIZE; i &lt; npages; ++i)    MARK_FREE(i);\n\npage_alloc分配过程比较简单。需要注意的是pp_ref要初始化为0，以及使用page2kva将PageInfo转化为虚拟地址。\nstruct PageInfo *page_alloc(int alloc_flags){\t// Fill this function in    struct PageInfo *pp;    if (!page_free_list)        return NULL;    pp = page_free_list;    page_free_list = pp-&gt;pp_link;    pp-&gt;pp_link = NULL;    pp-&gt;pp_ref = 0; // Not increment reference count    if (alloc_flags &amp; ALLOC_ZERO)        memset(page2kva(pp), 0, PGSIZE);    return pp;}\n\npage_free这个比较简单，没什么要注意的点。\nvoidpage_free(struct PageInfo *pp){\t// Fill this function in\t// Hint: You may want to panic if pp-&gt;pp_ref is nonzero or\t// pp-&gt;pp_link is not NULL.    if(pp-&gt;pp_ref != 0 || pp-&gt;pp_link != NULL)        panic(\"page_free\");    pp-&gt;pp_link = page_free_list;    page_free_list = pp;}\n\nExercise 2Exercise 3\nQ1: Assuming that the following JOS kernel code is correct, what type should variable x have, uintptr_t or physaddr_t?\n\nmystery_t x;char* value = return_a_pointer();*value = 10;x = (mystery_t) value;\n\n因为value为指针类型，是虚拟地址，因此x的类型应为uintptr_t\nExercise 4pagedir_walk严格按照函数的描述实现即可。个人认为比较需要注意的点是，可以将页目录项的所有功能位置位，因为检查主要以页表项的功能位为准，所以页目录项的最好设置得宽松一些。\npte_t *pgdir_walk(pde_t *pgdir, const void *va, int create){\t// Fill this function in    pde_t *pde;    pte_t *pgtab;    struct PageInfo *pp;    pde = &amp;pgdir[PDX(va)];    if (!(*pde &amp; PTE_P)) {        if (!create || !(pp = page_alloc(ALLOC_ZERO)))            return NULL;        *pde = page2pa(pp) | (PTE_P | PTE_U | PTE_W); // it's OK to set all bits in pde.        pp-&gt;pp_ref += 1;    }    pgtab = KADDR(PTE_ADDR(*pde));    return &amp;pgtab[PTX(va)];}\n\nboot_map_region虽然函数描述说va和pa会对齐到页，但还是检查一下比较好。其他方面比较简单。\nstatic voidboot_map_region(pde_t *pgdir, uintptr_t va, size_t size, physaddr_t pa, int perm){\t// Fill this function in    size_t off;    pte_t *pte;\tif ((va &amp; (PGSIZE - 1)) || (pa &amp; (PGSIZE - 1)))\t\tpanic(\"boot_map_region\");        for (off = 0; off &lt; size; off += PGSIZE) {        if (!(pte = pgdir_walk(pgdir, (void*)(va + off), 1)))            panic(\"boot_map_region\");        *pte = (pa + off) | perm | PTE_P;    }}\n\npage_lookup严格按照功能描述实现即可\nstruct PageInfo *page_lookup(pde_t *pgdir, void *va, pte_t **pte_store){\t// Fill this function in    pte_t *pte;    pte = pgdir_walk(pgdir, va, 0);    if (!pte || !(*pte &amp; PTE_P))        return NULL;    if (pte_store)        *pte_store = pte;    return pa2page(PTE_ADDR(*pte));}\n\npage_removepage_decref会负责物理页的释放。而在清空页表项之前，需要禁用TLB。\nvoidpage_remove(pde_t *pgdir, void *va){\t// Fill this function in    pte_t *pte;    struct PageInfo *pp;    if (!(pp = page_lookup(pgdir, va, &amp;pte)))        return;    page_decref(pp);    tlb_invalidate(pgdir, va);    memset(pte, 0, sizeof(pte_t));}\n\npage_insert先将pp_ref递增，然后再尝试移除va处的映射，这样可以避免re-inserted造成的一些错误。值得注意的是，page_remove会调用page_lookup，而page_lookup也会调用pgdir_walk，这就造成了pgdir_walk的重复调用。不过从代码的简洁性和复用性方面考虑，还是这样比较好。\nintpage_insert(pde_t *pgdir, struct PageInfo *pp, void *va, int perm){\t// Fill this function in    pte_t *pte;    if (!(pte = pgdir_walk(pgdir, va, 1)))        return -E_NO_MEM;    pp-&gt;pp_ref++;    page_remove(pgdir, va);    *pte = page2pa(pp) | perm | PTE_P;    return 0;}\n\nExercise 5page_map_region会默认置位页表项的PTE_P，因此将perm设为PTE_U即可。\n关于page自身的映射，会在之后映射整个内核空间时进行。\n//////////////////////////////////////////////////////////////////////// Map 'pages' read-only by the user at linear address UPAGES// Permissions://    - the new image at UPAGES -- kernel R, user R//      (ie. perm = PTE_U | PTE_P)//    - pages itself -- kernel RW, user NONE// Your code goes here:boot_map_region(kern_pgdir, UPAGES, PTSIZE, PADDR(pages), PTE_U);\n\nguard page不进行映射。主要是不清楚要映射到那个那个物理空间，因为理论上guard page甚至连读都不应读。\n//////////////////////////////////////////////////////////////////////// Use the physical memory that 'bootstack' refers to as the kernel// stack.  The kernel stack grows down from virtual address KSTACKTOP.// We consider the entire range from [KSTACKTOP-PTSIZE, KSTACKTOP)// to be the kernel stack, but break this into two pieces://     * [KSTACKTOP-KSTKSIZE, KSTACKTOP) -- backed by physical memory//     * [KSTACKTOP-PTSIZE, KSTACKTOP-KSTKSIZE) -- not backed; so if//       the kernel overflows its stack, it will fault rather than//       overwrite memory.  Known as a \"guard page\".//     Permissions: kernel RW, user NONE// Your code goes here:boot_map_region(    kern_pgdir, KSTACKTOP - KSTKSIZE, KSTKSIZE,     PADDR(bootstacktop) - KSTKSIZE, PTE_W);\n\n这个比较简单。\n//////////////////////////////////////////////////////////////////////// Map all of physical memory at KERNBASE.// Ie.  the VA range [KERNBASE, 2^32) should map to//      the PA range [0, 2^32 - KERNBASE)// We might not have 2^32 - KERNBASE bytes of physical memory, but// we just set up the mapping anyway.// Permissions: kernel RW, user NONE// Your code goes here:boot_map_region(kern_pgdir, KERNBASE, ~(uint32_t)0 - KERNBASE + 1, 0, PTE_W);\n\n\nQ2: What entries (rows) in the page directory have been filled in at this point? What addresses do they map and where do they point? In other words, fill out this table as much as possible:\n\n\nQ3: We have placed the kernel and user environment in the same address space. Why will user programs not be able to read or write the kernel’s memory? What specific mechanisms protect the kernel memory?\n\n因为用户空间和内核空间的页表项中的PTE_U位不同。本质上是x86处理器的MMU通过CS寄存器的特权级结合页表项的PTE_U位来判断当前代码是否有访问特定地址的权限。\n\nQ4: What is the maximum amount of physical memory that this operating system can support? Why?\n\n可利用的最大物理内存大小为128MB（一共32768 = 2^15页）。因为硬件检测出的物理内存就是这么大（可通过qemu的运行参数设置）。\n\nQ5: How much space overhead is there for managing memory, if we actually had the maximum amount of physical memory? How is this overhead broken down?\n\n内存管理部分包括1024个虚拟页表和1个物理页表（不考虑空闲物理页链表头），其中所有虚拟页表所占内存为1024*4KB = 4MB，物理页表所占内存为32768 * 8B = 256KB = 0.25MB （每个表项大小为8B），总内存开销为4.25MB。因为采用了分级页表机制，实际上平时只有很少一部分的虚拟页表会位于内存中，所以总开销一般不足1MB。\n\nQ6: Revisit the page table setup in kern/entry.S and kern/entrypgdir.c. Immediately after we turn on paging, EIP is still a low number (a little over 1MB). At what point do we transition to running at an EIP above KERNBASE? What makes it possible for us to continue executing at a low EIP between when we enable paging and when we begin running at an EIP above KERNBASE? Why is this transition necessary?\n\n在下列指令后EIP进入高地址：\nmov\t$relocated, %eaxjmp\t*%eax\n\n因为entry_pgdir将[0, 4MB)和[KERNBASE, KERNBASE + 4MB)的虚拟地址都映射到了[0, 4MB)的物理地址上，因此刚开启分页模式后，EIP虽然仍位于低地址，但依然可以正常运行。因为开启分页前后，EIP的值没变（严格来说前进了一个指令），但对其的解释却变了，对内存的访问模式从物理访存转换到了虚拟访存，因此为了兼容前后的情况，entry_pgdir的映射必须包含一个[0, 4MB)上的恒等映射（4MB不是必须的，只是因为一个页目录项正好囊括4MB的内存）\n__attribute__((__aligned__(PGSIZE)))pde_t entry_pgdir[NPDENTRIES] = {\t// Map VA's [0, 4MB) to PA's [0, 4MB)\t[0]\t\t= ((uintptr_t)entry_pgtable - KERNBASE) + PTE_P,\t// Map VA's [KERNBASE, KERNBASE+4MB) to PA's [0, 4MB)\t[KERNBASE&gt;&gt;PDXSHIFT]\t\t= ((uintptr_t)entry_pgtable - KERNBASE) + PTE_P + PTE_W};\n\nThis completes the labrunning JOS: (1.8s)   Physical page allocator: OK   Page management: OK   Kernel page directory: OK   Page management 2: OK Score: 70/70\n\nChallenge: JOS kernel monitor extensionshowmap简单地遍历页表即可。\nint mon_showmap(int argc, char **argv, struct Trapframe *tf) {    static const char *msg =     \"Usage: showmappings &lt;start&gt; [&lt;length&gt;]\\n\";    if (argc &lt; 2)        goto help;    uintptr_t vstart, vend;    size_t vlen;    pte_t *pte;    vstart = (uintptr_t)strtol(argv[1], 0, 0);    vlen = argc &gt;= 3 ? (size_t)strtol(argv[2], 0, 0) : 1;    vend = vstart + vlen;    vstart = ROUNDDOWN(vstart, PGSIZE);    vend = ROUNDDOWN(vend, PGSIZE);    for(; vstart &lt;= vend; vstart += PGSIZE) {        pte = pgdir_walk(kern_pgdir, (void*)vstart, 0);        if (pte &amp;&amp; *pte &amp; PTE_P) {            cprintf(\"VA: 0x%08x, PA: 0x%08x, U-bit: %d, W-bit: %d\\n\",            vstart, PTE_ADDR(*pte), !!(*pte &amp; PTE_U), !!(*pte &amp; PTE_W));        } else {            cprintf(\"VA: 0x%08x, PA: No Mapping\\n\", vstart);        }    }    return 0;help:     cprintf(msg);    return 0;}\n\n效果：\n\nsetperm也是简单地遍历即可。\nint mon_setperm(int argc, char **argv, struct Trapframe *tf) {    static const char *msg =     \"Usage: setperm &lt;virtual address&gt; &lt;permission&gt;\\n\";    if (argc != 3)        goto help;        uintptr_t va;    uint16_t perm;    pte_t *pte;    va = (uintptr_t)strtol(argv[1], 0, 0);    perm = (uint16_t)strtol(argv[2], 0, 0);    pte = pgdir_walk(kern_pgdir, (void*)va, 0);    if (pte &amp;&amp; *pte &amp; PTE_P) {        *pte = (*pte &amp; ~0xFFF) | (perm &amp; 0xFFF) | PTE_P;    } else {        cprintf(\"There's no such mapping\\n\");    }    return 0;help:     cprintf(msg);    return 0;    }\n\n效果：\n\ndumpmem处理命令行参数稍微有点繁琐，其他还行。之后可以考虑添加个类似linux getopt的函数。\n关于查看物理地址的问题，因为JOS的默认内存是128MB，而KERNBASE以上的虚拟内存大小为256MB，因此可以直接通过访问对应的KERNBASE以上的虚拟地址来访问对应的物理地址。\n如果自定义Qemu提供的内存大小，导致访问的物理地址大于256MB的话，可以临时映射一个页（比如映射0x0所处的页）到对应的物理地址，来查看其内容。\n默认物理内存不超过32位，不然其中的uint32_t需要改成uint64_t。\nstatic void dump_vm(uint32_t mstart, uint32_t mend){    uint32_t next;    pte_t *pte;    while (mstart &lt; mend) {        if (!(pte = pgdir_walk(kern_pgdir, (void *)mstart, 0))) {            next = MIN((uint32_t)PGADDR(PDX(mstart) + 1, 0, 0), mend);            for (; mstart &lt; next; ++mstart)                cprintf(\"[VA: 0x%08x, PA: No mapping]: None\\n\", mstart);        } else if (!(*pte &amp; PTE_P)) {            next = MIN((uint32_t)PGADDR(PDX(mstart), PTX(mstart) + 1, 0), mend);            for (; mstart &lt; next; ++mstart)                cprintf(\"[VA: 0x%08x, PA: No mapping]: None\\n\", mstart);        } else {            next = MIN((uint32_t)PGADDR(PDX(mstart), PTX(mstart) + 1, 0), mend);            for (; mstart &lt; next; ++mstart)                cprintf(\"[VA: 0x%08x, PA: 0x%08x]: %02x\\n\", mstart,                        PTE_ADDR(*pte) | PGOFF(mstart), *(uint8_t *)mstart);        }    }}static void dump_pm(uint32_t mstart, uint32_t mend){    static const uint32_t map_base = 0;    uint32_t next, base;    while(mstart &lt; mend) {        next = MIN(ROUNDUP(mstart + 1, PGSIZE), mend);        base = ROUNDDOWN(mstart, PGSIZE);        page_insert(kern_pgdir, &amp;pages[base / PGSIZE], (void*)map_base, PTE_P);        for (; mstart &lt; next; ++mstart)            cprintf(\"[PA: 0x%08x]: %02x\\n\", mstart, *((uint8_t*)(mstart - base + map_base)));    }    page_remove(kern_pgdir, (void*)map_base);}int mon_dumpmem(int argc, char **argv, struct Trapframe *tf) {    static const char *msg =    \"Usage: dumpmem [option] &lt;start&gt; &lt;length&gt;\\n\"    \"\\t-p, --physical\\tuse physical address\\n\";    int phys = 0;    if (argc == 4) {        int i;        for (i = 1; i &lt; argc; ++i) {            if (!strcmp(argv[i], \"-p\") || !strcmp(argv[i], \"--physical\")) {                phys = 1;                break;            }        }        if (!phys)            goto help;        for (int j = i; j &lt; argc - 1; ++j)            argv[j] = argv[j + 1];    } else if (argc != 3) {        goto help;    }    uint32_t mstart, mend;    size_t mlen;        mstart = (uint32_t)strtol(argv[1], 0, 0);    mlen = (size_t)strtol(argv[2], 0, 0);    mend = mstart + mlen;    if (phys) {        if (mend &gt; npages * PGSIZE) {            cprintf(\"Target memory out of range\\n\");            return 0;        }        uint32_t next = MIN(mend, ~(uint32_t)0 - KERNBASE + 1);        for (; mstart &lt; next; ++mstart) {            cprintf(\"[PA: 0x%08x]: %02x\\n\", mstart,                    *(uint8_t *)KADDR(mstart));        }        if (mstart &lt; mend)            dump_pm(mstart, mend);    } else {        dump_vm(mstart, mend);    }    return 0;help:     cprintf(msg);    return 0;}\n\n效果：\n\nChallenge: Page Size Extension根据Intel IA-32 Manual Volume 3中的描述，使用4MB的大页，需要若干条件：\n\nCR4的PSE位置位，启动大页扩展。\nPDE的PS位置位，表示该PDE指向一个大页。\n大页指向的物理地址基址为4MB对齐的。\n\n其翻译机制比较简单，具体可见图：\n\n具体实现就比较简单了，首先在装载新的页表前设置CR4的PSE位：\n// Enable page size extensioncr4 = rcr4();cr4 |= CR4_PSE;lcr4(cr4);\n\n然后定义一个新的boot_map_region_huge_page函数，用于在映射KERNBASE以上区域时进行大页映射：\nstatic void boot_map_region_huge_page(pde_t* pgdir, uintptr_t va, size_t size, physaddr_t pa, int perm) {\tsize_t off;\tif (va &amp; (PTSIZE - 1) || pa &amp; (PTSIZE - 1) || size &amp; (PTSIZE - 1))\t\tpanic(\"boot_map_region_huge_page\");\t\tfor (off = 0; off &lt; size; off += PTSIZE) {\t\tpgdir[PDX(va + off)] = (pa + off) | perm | PTE_P | PTE_PS;\t}}\n\nboot_map_region_huge_page(kern_pgdir, KERNBASE, ~(uint32_t)0 - KERNBASE + 1, 0, PTE_W);\n\n还要更改check_va2pa函数（原始的函数不会检查大页），否则通过不了测试：\nstatic physaddr_tcheck_va2pa(pde_t *pgdir, uintptr_t va){\tpte_t *p;\tpgdir = &amp;pgdir[PDX(va)];\tif (!(*pgdir &amp; PTE_P))\t\treturn ~0;\t// recognize huge page\tif (*pgdir &amp; PTE_PS)\t\treturn PTE_ADDR(*pgdir) | (PTX(va) &lt;&lt; PTXSHIFT) | PGOFF(va);\tp = (pte_t*) KADDR(PTE_ADDR(*pgdir));\tif (!(p[PTX(va)] &amp; PTE_P))\t\treturn ~0;\treturn PTE_ADDR(p[PTX(va)]);}\n\n这是启用大页后，使用dumpmem后的结果（在我的dumpmem实现中，访问256MB以内的物理内存时采用的都是访问KERNBASE以上对应的虚拟内存的方法），与之前的dumpmem 0xF0000000 10的结果一致。\n\n","tags":["OS"]},{"title":"MIT 6.828 JOS Lab3 实验报告","url":"/2020/10/05/MIT%206.828%20JOS%20Lab3%20%E5%AE%9E%E9%AA%8C%E6%8A%A5%E5%91%8A/","content":"前言此为本人上本校的操作系统实习(实验班)时所写的实验报告，简单记述了JOS Lab的各个Exercise、Challenge(未覆盖所有Challenge，每个Lab大概做了1~3个Challenge)的基本思路。仅供有需者参考，上有关课程(比如本校的操统实习实验班)的最好不要直接抄。\n附上源代码链接：https://github.com/Light-of-Hers/mit-jos\nExercise 1在kern/pmap.c中加入：\n//////////////////////////////////////////////////////////////////////// Make 'envs' point to an array of size 'NENV' of 'struct Env'.// LAB 3: Your code here.envs = (struct Env *) boot_alloc(NENV * sizeof(struct Env));memset(envs, 0, NENV * sizeof(struct Env));\n\n//////////////////////////////////////////////////////////////////////// Map the 'envs' array read-only by the user at linear address UENVS// (ie. perm = PTE_U | PTE_P).// Permissions://    - the new image at UENVS  -- kernel R, user R//    - envs itself -- kernel RW, user NONE// LAB 3: Your code here.boot_map_region(kern_pgdir, UENVS, PTSIZE, PADDR(envs), PTE_U);\n\nExercise 2env_init按要求初始化各个PCB以及空闲链表。\nvoidenv_init(void){\t// Set up envs array\t// LAB 3: Your code here.    int i;    struct Env *e;    env_free_list = NULL;    for (i = NENV - 1; i &gt;= 0; --i) {        e = &amp;envs[i];        e-&gt;env_id = 0;        e-&gt;env_status = ENV_FREE;        e-&gt;env_link = env_free_list;        env_free_list = e;    }    // Per-CPU part of the initialization    env_init_percpu();}\n\nenv_setup_vm复制内核页目录，并设置自映射。\nstatic intenv_setup_vm(struct Env *e){    struct PageInfo *pp = NULL;        // Allocate a page for the page directory    if (!(pp = page_alloc(ALLOC_ZERO)))        return -E_NO_MEM;        // Now, set e-&gt;env_pgdir and initialize the page directory.        // LAB 3: Your code here.    e-&gt;env_pgdir = page2kva(pp);    pp-&gt;pp_ref += 1;    for (size_t i = PDX(UTOP); i &lt; NPDENTRIES; ++i)        e-&gt;env_pgdir[i] = kern_pgdir[i];    // UVPT maps the env's own page table read-only.    // Permissions: kernel R, user R    e-&gt;env_pgdir[PDX(UVPT)] = PADDR(e-&gt;env_pgdir) | PTE_P | PTE_U;\treturn 0;}\n\nregion_alloc按要求为进程的虚拟页分配对应的物理页即可。\nstatic voidregion_alloc(struct Env *e, void *va, size_t len){    // LAB 3: Your code here.    // (But only if you need it for load_icode.)    uintptr_t vstart, vend;    struct PageInfo *pp;    int err;    vstart = ROUNDDOWN((uintptr_t)va, PGSIZE);    vend = ROUNDUP((uintptr_t)va + len, PGSIZE);    for (; vstart &lt; vend; vstart += PGSIZE) {        if (!(pp = page_alloc(ALLOC_ZERO)))            panic(\"region_alloc(1)\");        if ((err = page_insert(e-&gt;env_pgdir, pp, (void*)vstart, PTE_W | PTE_U)) &lt; 0)            panic(\"region_alloc(2): %e\", err);    }}\n\nload_icode按要求加载即可。有一些需要注意的点：\n\n在加载前，可以先将页目录替换为进程的页目录。在加载完成后，再替换回内核页目录。\n进程trapframe的eip设置为程序入口，这样进程回到用户态后就会从入口处开始执行。\n\nstatic voidload_icode(struct Env *e, uint8_t *binary){    // LAB 3: Your code here.    struct Elf *eh;    struct Proghdr *ph, *ph_end;    eh = (struct Elf *) binary;    if (eh-&gt;e_magic != ELF_MAGIC)        panic(\"load_icode(1)\");    ph = (struct Proghdr *) (binary + eh-&gt;e_phoff);    ph_end = ph + eh-&gt;e_phnum;    lcr3(PADDR(e-&gt;env_pgdir));    for (; ph &lt; ph_end; ++ph) {        if (ph-&gt;p_type != ELF_PROG_LOAD)            continue;        if (ph-&gt;p_filesz &gt; ph-&gt;p_memsz)            panic(\"load_icode(2)\");        region_alloc(e, (void*)ph-&gt;p_va, ph-&gt;p_memsz);        memset((void*)ph-&gt;p_va, 0, ph-&gt;p_memsz);        memcpy((void*)ph-&gt;p_va, binary + ph-&gt;p_offset, ph-&gt;p_filesz);    }    e-&gt;env_tf.tf_eip = eh-&gt;e_entry;        // Now map one page for the program's initial stack    // at virtual address USTACKTOP - PGSIZE.        // LAB 3: Your code here.    region_alloc(e, (void*)(USTACKTOP - PGSIZE), PGSIZE);    lcr3(PADDR(kern_pgdir));}\n\nenv_create分配一个PCB，加载程序，设置进程类型即可。\nvoidenv_create(uint8_t *binary, enum EnvType type){    // LAB 3: Your code here.    struct Env *e;    int err;    if ((err = env_alloc(&amp;e, 0)) &lt; 0)        panic(\"env_create: %e\", err);    load_icode(e, binary);    e-&gt;env_type = ENV_TYPE_USER;}\n\nenv_run按要求设置curenv以及PCB的状态即可。\nvoidenv_run(struct Env *e){    // Step 1: If this is a context switch (a new environment is running):    //\t   1. Set the current environment (if any) back to    //\t      ENV_RUNNABLE if it is ENV_RUNNING (think about    //\t      what other states it can be in),    //\t   2. Set 'curenv' to the new environment,    //\t   3. Set its status to ENV_RUNNING,    //\t   4. Update its 'env_runs' counter,    //\t   5. Use lcr3() to switch to its address space.    // Step 2: Use env_pop_tf() to restore the environment's    //\t   registers and drop into user mode in the    //\t   environment.        // LAB 3: Your code here.        // panic(\"env_run not yet implemented\");    if (curenv &amp;&amp; curenv-&gt;env_status == ENV_RUNNING)        curenv-&gt;env_status = ENV_RUNNABLE;    curenv = e;    curenv-&gt;env_status = ENV_RUNNING;    curenv-&gt;env_runs += 1;    lcr3(PADDR(curenv-&gt;env_pgdir));    env_pop_tf(&amp;curenv-&gt;env_tf);}\n\nExercise 4 &amp; Challenge: Meta-Programmingkern/trapentry.inc新建一个文件kern/trapentry.inc，列出以下各项。TH(n)表示不会产生error-code的第n号中断的trap handler；THE(n)表示会产生error-code的第n号中断的trap handler。\nTH(0)TH(1)TH(2)TH(3)TH(4)TH(5)TH(6)TH(7)THE(8)THE(10)THE(11)THE(12)THE(13)THE(14)TH(16)THE(17)TH(18)TH(19)TH(48)\n\nkern/trapentry.S在kern/trapentry.S中定义TH和THE，引入kern/trapentry.inc，构成各个中断处理例程：\n#define TH(n) \\TRAPHANDLER_NOEC(handler##n, n)#define THE(n) \\TRAPHANDLER(handler##n, n).text/* * Lab 3: Your code here for generating entry points for the different traps. */#include &lt;kern/trapentry.inc&gt;\n\n_alltraps先补齐trapframe所需要的信息，更改段寄存器，接着将ESP压栈作为参数struct Trapframe* tf并调用trap函数。\n/* * Lab 3: Your code here for _alltraps */_alltraps:    pushl %ds     pushl %es     pushal     movw $GD_KD, %ax    movw %ax, %ds     movw %ax, %es    pushl %esp     call trap trap_spin:    jmp trap_spin\n\nkern/trap.c在kern/trap.c中定义TH和THE，引入kern/trapentry.inc，构成中断向量表：\n#define TH(n) extern void handler##n (void);#define THE(n) TH(n)#include &lt;kern/trapentry.inc&gt;#undef THE#undef TH#define TH(n) [n] = handler##n,#define THE(n) TH(n)static void (* handlers[256])(void) = {#include &lt;kern/trapentry.inc&gt;};#undef THE#undef TH\n\ntrap_init考虑到处理的方便，将所有的中断向量都设为中断门，也就是处理过程中屏蔽外部中断。\nvoidtrap_init(void){    extern struct Segdesc gdt[];        // LAB 3: Your code here.    for (int i = 0; i &lt; 32; ++i)         SETGATE(idt[i], 0, GD_KT, handlers[i], 0);    SETGATE(idt[T_BRKPT], 0, GD_KT, handlers[T_BRKPT], 3);    SETGATE(idt[T_SYSCALL], 0, GD_KT, handlers[T_SYSCALL], 3);    // Per-CPU setup     trap_init_percpu();}\n\nQuestions1.\nWhat is the purpose of having an individual handler function for each exception/interrupt? (i.e., if all exceptions/interrupts were delivered to the same handler, what feature that exists in the current implementation could not be provided?)\n\n因为有的中断硬件会多压一个错误码，采用分立的handler目的在于处理这种不一致以提供一致的trapframe。\n2.\nDid you have to do anything to make the user/softint program behave correctly? The grade script expects it to produce a general protection fault (trap 13), but softint’s code says int 14 instruction to invoke the kernel’s page fault handler (which is interrupt vector 14)?\n\n因为14号中断向量的DPL为0，即内核特权级。根据x86 ISA的说明（https://www.felixcloutier.com/x86/intn:into:int3:int1）：\nIF software interrupt (* Generated by INT n, INT3, or INTO; does not apply to INT1 *)        THEN            IF gate DPL &lt; CPL (* PE = 1, DPL &lt; CPL, software interrupt *)                THEN #GP(error_code(vector_number,1,0)); FI;                (* idt operand to error_code set because vector is used *)                (* ext operand to error_code is 0 because INT n, INT3, or INTO*)\n\n在用户态使用int $14，会触发保护异常（Gerenal Protection Fault，伪代码中的GP）。\n如果内核允许用户主动触发缺页异常，将会导致严重的不一致性，内核将难以辨识用户态触发的缺页异常到底因何发生。\nExercise 5简答地识别trapno并派发即可：\nswitch(tf-&gt;tf_trapno) {case T_PGFLT: {    page_fault_handler(tf);    return;}default:    break;}\n\nExercise 6在switch语句中添加一个case即可：\ncase T_BRKPT: {    monitor(tf);    return;}\n\nQuestions3.\nThe break point test case will either generate a break point exception or a general protection fault depending on how you initialized the break point entry in the IDT (i.e., your call to SETGATE from trap_init). Why? How do you need to set it up in order to get the breakpoint exception to work as specified above and what incorrect setup would cause it to trigger a general protection fault?\n\n该test使用int $3指令触发断点异常，因此3号中断向量的DPL必须设为3，即用户特权级。如果没有如此设置，将会触发保护异常。\n4.\nWhat do you think is the point of these mechanisms, particularly in light of what the user/softint test program does?\n\n意义在于防止用户随意地触发异常，但同时又留出一个接口供用户使用系统服务。\nExercise 7syscall中断向量syscall中断向量的建立和初始化之前已有涉及，便不再赘述。\ntrap_dispatch在trap_dispatch中的switch语句添加一个case，通过trapframe获得syscall参数，并设置返回值。\ncase T_SYSCALL: {    // eax, edx, ecx, ebx, edi, esi;    struct PushRegs *r = &amp;tf-&gt;tf_regs;    r-&gt;reg_eax = syscall(        r-&gt;reg_eax,         r-&gt;reg_edx,         r-&gt;reg_ecx,         r-&gt;reg_ebx,         r-&gt;reg_edi,         r-&gt;reg_esi    );    return;}\n\nsyscall补全kern/syscall.c中的syscall函数，注意采用(void)x的形式“使用”一下x变量，防止编译器报错（因为开了-Werror……）：\nint32_tsyscall(uint32_t syscallno, uint32_t a1, uint32_t a2, uint32_t a3, uint32_t a4, uint32_t a5){    // Call the function corresponding to the 'syscallno' parameter.    // Return any appropriate return value.    // LAB 3: Your code here.        // panic(\"syscall not implemented\");    (void)syscallno, (void)a1, (void)a2, (void)a3, (void)a4, (void)a5;\tswitch (syscallno) {    case SYS_cputs: {        sys_cputs((const char *)a1, (size_t)a2);        return 0;    }    case SYS_cgetc: {        return sys_cgetc();    }    case SYS_env_destroy: {        return sys_env_destroy((envid_t)a1);    }    case SYS_getenvid: {        return sys_getenvid();    }    default:        return -E_INVAL;    }}\n\nExercise 8添加如下语句即可：\nthisenv = &amp;envs[ENVX(sys_getenvid())];\n\nExercise 9page_fault_handler在page_fault_handler中添加：\nif ((tf-&gt;tf_cs &amp; 3) == 0)    panic(\"page fault in kernel mode\");\n\nuser_mem_check实现较为简单，注意要将user_mem_check_addr设置为合适的值。\nintuser_mem_check(struct Env *env, const void *va, size_t len, int perm){    // LAB 3: Your code here.    pte_t *pte;    uintptr_t vstart, vend;    vstart = ROUNDDOWN((uintptr_t)va, PGSIZE);    vend = ROUNDUP((uintptr_t)va + len, PGSIZE);        if (vend &gt; ULIM) {        user_mem_check_addr = MAX(ULIM, (uintptr_t)va);        return -E_FAULT;    }    for (; vstart &lt; vend; vstart += PGSIZE) {        pte = pgdir_walk(env-&gt;env_pgdir, (void*)vstart, 0);        if (!pte || (*pte &amp; (perm | PTE_P)) != (perm | PTE_P)) {            user_mem_check_addr = MAX(vstart, (uintptr_t)va);            return -E_FAULT;        }    }    return 0;}\n\nkern/syscall.c当前的syscall只有cons_cputs有涉及到访存，故只需在其中加入内存检查即可：\nuser_mem_assert(curenv, s, len, PTE_U);\n\ndebuginfo_eip加入如下检查语句：\n// Make sure this memory is valid.// Return -1 if it is not.  Hint: Call user_mem_check.// LAB 3: Your code here.if (curenv &amp;&amp;     \tuser_mem_check(curenv, (void*)usd,                        sizeof(struct UserStabData), PTE_U) &lt; 0)    return -1;\n\n// Make sure the STABS and string table memory is valid.// LAB 3: Your code here.if (curenv &amp;&amp; (        user_mem_check(curenv, (void*)stabs,                        (uintptr_t)stab_end - (uintptr_t)stabs, PTE_U) &lt; 0 ||         user_mem_check(curenv, (void*)stabstr,                        (uintptr_t)stabstr_end - (uintptr_t)stabstr, PTE_U) &lt; 0))    return -1;\n\nThis completes this labdivzero: OK (3.4s) softint: OK (1.0s) badsegment: OK (0.9s) Part A score: 30/30faultread: OK (1.7s) faultreadkernel: OK (1.2s) faultwrite: OK (1.8s) faultwritekernel: OK (1.2s) breakpoint: OK (1.7s) testbss: OK (2.1s) hello: OK (2.1s) buggyhello: OK (1.8s) buggyhello2: OK (1.2s) evilhello: OK (1.8s) Part B score: 50/50Score: 80/80\n\nChallenge: Breakpointx86在EFLAGS的TF位置位时，每执行一条指令都会触发一次调试异常（触发后会复位TF）。可以借此实现断点续行。\n首先在trap_dispatch中处理调试异常（和断点异常处理一致）：\ncase T_DEBUG:case T_BRKPT: {    monitor(tf);    return;}\n\n接着在monitor中添加两个命令：step、continue，用于步进和继续执行。简单地检查一下是否是因为用户态的断点/调试异常触发的，接着设置trapframe的EFLAGS的TF位：\nint mon_continue(int argc, char **argv, struct Trapframe *tf) {    if (!(tf &amp;&amp; (tf-&gt;tf_trapno == T_DEBUG || tf-&gt;tf_trapno == T_BRKPT) &amp;&amp;           ((tf-&gt;tf_cs &amp; 3) == 3)))        return 0;    tf-&gt;tf_eflags &amp;= ~FL_TF;    return -1;}int mon_step(int argc, char **argv, struct Trapframe *tf) {    if (!(tf &amp;&amp; (tf-&gt;tf_trapno == T_DEBUG || tf-&gt;tf_trapno == T_BRKPT) &amp;&amp;           ((tf-&gt;tf_cs &amp; 3) == 3)))        return 0;    tf-&gt;tf_eflags |= FL_TF;    return -1;}\n\n测试效果运行breakpoint程序的结果\n[00000000] new env 00001000Incoming TRAP frame at 0xefffffbcIncoming TRAP frame at 0xefffffbcWelcome to the JOS kernel monitor!Type 'help' for a list of commands.TRAP frame at 0xf01c7000  edi  0x00000000  esi  0x00000000  ebp  0xeebfdfc0  oesp 0xefffffdc  ebx  0x00802000  edx  0x0080202c  ecx  0x00000000  eax  0xeec00000  es   0x----0023  ds   0x----0023  trap 0x00000003 Breakpoint  err  0x00000000  eip  0x00800037  cs   0x----001b  flag 0x00000082  esp  0xeebfdfc0  ss   0x----0023K&gt; stepIncoming TRAP frame at 0xefffffbcWelcome to the JOS kernel monitor!Type 'help' for a list of commands.TRAP frame at 0xf01c7000  edi  0x00000000  esi  0x00000000  ebp  0xeebfdff0  oesp 0xefffffdc  ebx  0x00802000  edx  0x0080202c  ecx  0x00000000  eax  0xeec00000  es   0x----0023  ds   0x----0023  trap 0x00000001 Debug  err  0x00000000  eip  0x00800038  cs   0x----001b  flag 0x00000182  esp  0xeebfdfc4  ss   0x----0023K&gt; continueIncoming TRAP frame at 0xefffffbc[00001000] exiting gracefully[00001000] free env 00001000Destroyed the only environment - nothing more to do!Welcome to the JOS kernel monitor!Type 'help' for a list of commands.K&gt; ","tags":["OS"]},{"title":"MIT 6.828 JOS Lab4 实验报告","url":"/2020/10/05/MIT%206.828%20JOS%20Lab4%20%E5%AE%9E%E9%AA%8C%E6%8A%A5%E5%91%8A/","content":"前言此为本人上本校的操作系统实习(实验班)时所写的实验报告，简单记述了JOS Lab的各个Exercise、Challenge(未覆盖所有Challenge，每个Lab大概做了1~3个Challenge)的基本思路。仅供有需者参考，上有关课程(比如本校的操统实习实验班)的最好不要直接抄。\n附上源代码链接：https://github.com/Light-of-Hers/mit-jos\nExercise 1调用boot_map_region即可，注意需要检查范围是否超过MMIOLIM：\nvoid *mmio_map_region(physaddr_t pa, size_t size){    static uintptr_t base = MMIOBASE;    uintptr_t start;        start = base;    size = ROUNDUP(size, PGSIZE);\tif (base + size &gt; MMIOLIM)\t\tpanic(\"overflow MMIOLIM\");    base += size;    boot_map_region(kern_pgdir, start, size, pa, PTE_W | PTE_PCD | PTE_PWT);    return (void*)start;}\n\nExercise 2在page_init里不将MPENTRY_PADDR加入空闲链表即可：\nvoidpage_init(void){#define MARK_FREE(_i) do {\\    size_t __tmp__ = _i;\\    pages[__tmp__].pp_ref = 0;\\    pages[__tmp__].pp_link = page_free_list;\\\tpage_free_list = &amp;pages[__tmp__];\\} while(0)#define MARK_USE(_i) do {\\    size_t __tmp__ = _i;\\    pages[__tmp__].pp_ref = 0;\\    pages[__tmp__].pp_link = NULL;\\} while(0)    extern char end[];    physaddr_t bss_end;    physaddr_t boot_alloc_end;    size_t i;    page_free_list = NULL;    bss_end = PADDR(ROUNDUP((char*)end, PGSIZE));    boot_alloc_end = PADDR(boot_alloc(0));    MARK_USE(0);    // --- 添加的内容 ---    for (i = 1; i &lt; MPENTRY_PADDR / PGSIZE; ++i)        MARK_FREE(i);    MARK_USE(i++);    // -----------------    for (; i &lt; npages_basemem; ++i)        MARK_FREE(i);    for (; i &lt; EXTPHYSMEM / PGSIZE; ++i)        MARK_USE(i);    for (; i &lt; bss_end / PGSIZE; ++i)        MARK_USE(i);    for (; i &lt; boot_alloc_end / PGSIZE; ++i)        MARK_USE(i);    for (; i &lt; npages; ++i)        MARK_FREE(i);#undef MARK_USE#undef MARK_FREE}\n\n\nQ: Compare kern/mpentry.S side by side with boot/boot.S. Bearing in mind that kern/mpentry.S is compiled and linked to run above KERNBASE just like everything else in the kernel, what is the purpose of macro MPBOOTPHYS? Why is it necessary in kern/mpentry.S but not in boot/boot.S? In other words, what could go wrong if it were omitted in kern/mpentry.S? Hint: recall the differences between the link address and the load address that we have discussed in Lab 1.\nA:\n\n计算出符号的物理地址。\n该代码段在编译链接时所重定位的位置不在MPENTRY_PADDR这块。实际运行时将这段代码拷贝到MPENTRY_PADDR再运行AP。因此对于需要绝对寻址的代码，要用MPBOOTPHYS来修改地址。而boot.S就没有这个需求。\n\n\nExercise 3直接用boot_map_region分配就行了：\nstatic voidmem_init_mp(void){    for (size_t i = 0; i &lt; NCPU; ++i) {        boot_map_region(            kern_pgdir,             KSTACKTOP - KSTKSIZE - i * (KSTKSIZE + KSTKGAP),            KSTKSIZE,            PADDR(percpu_kstacks[i]),            PTE_W         );    }}\n\nExercise 4先获取当前的CPU号，再初始化TS的ESP,SS等部分，初始化GDT中的TSS项，最后加载TSS选择子和IDT。\nvoidtrap_init_percpu(void){    struct Taskstate *ts;    size_t i;    i = cpunum();    ts = &amp;cpus[i].cpu_ts;    ts-&gt;ts_esp0 = (uintptr_t)percpu_kstacks[i] + KSTKSIZE;    ts-&gt;ts_ss0 = GD_KD;    ts-&gt;ts_iomb = sizeof(struct Taskstate);    gdt[(GD_TSS0 &gt;&gt; 3) + i] = SEG16(STS_T32A, (uint32_t)ts, sizeof(struct Taskstate) - 1, 0);    gdt[(GD_TSS0 &gt;&gt; 3) + i].sd_s = 0;    ltr(GD_TSS0 + (i &lt;&lt; 3));    lidt(&amp;idt_pd);}\n\nExercise 5在kern/init.c的i386_init中加锁：\n// Lab 4 multitasking initialization functionspic_init();// Acquire the big kernel lock before waking up APs// Your code here:lock_kernel();// Starting non-boot CPUsboot_aps();\n\n在kern/init.c的mp_main中加锁：\n// Now that we have finished some basic setup, call sched_yield()// to start running processes on this CPU.  But make sure that// only one CPU can enter the scheduler at a time!//// Your code here:lock_kernel();sched_yield();\n\n在kern/trap.c的trap中加锁：\nif ((tf-&gt;tf_cs &amp; 3) == 3) {    // Trapped from user mode.    // Acquire the big kernel lock before doing any    // serious kernel work.    // LAB 4: Your code here.    lock_kernel();\n\n在kern/env.c的env_run中解锁：\nunlock_kernel();env_pop_tf(&amp;e-&gt;env_tf);\n\n\nQ: It seems that using the big kernel lock guarantees that only one CPU can run the kernel code at a time. Why do we still need separate kernel stacks for each CPU? Describe a scenario in which using a shared kernel stack will go wrong, even with the protection of the big kernel lock.\nA: 内核锁的获取是在陷入内核之后进行的，这样的话在抢夺内核锁之前，内核栈上至少已经压入了CS和EIP等硬件压入的上下文。如果共享内核栈的话，在多个CPU同时陷入内核时，就会造成内核栈上保存的内容不一致。\n\nExercise 6按要求实现即可，因为有内核锁，所以完全不用考虑竞争的问题(^_^)\nvoidsched_yield(void){    struct Env *idle;        idle = NULL;    if (curenv) {        size_t eidx = ENVX(curenv-&gt;env_id);        uint32_t mask = NENV - 1;        for (size_t i = (eidx + 1) &amp; mask; i != eidx; i = (i + 1) &amp; mask) {            if (envs[i].env_status == ENV_RUNNABLE) {                idle = &amp;envs[i];                break;            }        }        if (!idle &amp;&amp; curenv-&gt;env_status == ENV_RUNNING)            idle = curenv;    } else {        for (size_t i = 0; i &lt; NENV; ++i) {            if (envs[i].env_status == ENV_RUNNABLE) {                idle = &amp;envs[i];                break;            }        }    }    if (idle)        env_run(idle);    // sched_halt never returns    sched_halt();}\n\n对syscall等的修改比较简单，就不列出了\n\nQ: In your implementation of env_run() you should have called lcr3(). Before and after the call to lcr3(), your code makes references (at least it should) to the variable e, the argument to env_run. Upon loading the %cr3 register, the addressing context used by the MMU is instantly changed. But a virtual address (namely e) has meaning relative to a given address context–the address context specifies the physical address to which the virtual address maps. Why can the pointer e be dereferenced both before and after the addressing switch?\nA: 因为所有进程的地址空间在内核部分的映射都是一样的。\n\n\nQ: Whenever the kernel switches from one environment to another, it must ensure the old environment’s registers are saved so they can be restored properly later. Why? Where does this happen?\nA: 因为进程没有自己单独的内核栈，因此寄存器上下文必须保存在PCB之类的结构中，以便之后恢复上下文。在trap.c的trap内保存寄存器上下文：\n// Copy trap frame (which is currently on the stack)// into 'curenv-&gt;env_tf', so that running the environment// will restart at the trap point.curenv-&gt;env_tf = *tf;// The trapframe on the stack should be ignored from here on.tf = &amp;curenv-&gt;env_tf;\n\nExercise 7sys_exofork按要求实现即可：\nstatic envid_tsys_exofork(void){    int r;    struct Env *parent, *child;        parent = curenv;    if (r= env_alloc(&amp;child, parent-&gt;env_id), r &lt; 0)        return r;    child-&gt;env_status = ENV_NOT_RUNNABLE;    child-&gt;env_tf = parent-&gt;env_tf;    child-&gt;env_tf.tf_regs.reg_eax = 0;    return child-&gt;env_id;}\n\nsys_env_set_status需要检查status是合法的，并且envid2env也要检查合法性：\nstatic intsys_env_set_status(envid_t envid, int status){    int r;    struct Env *e;    if (status &lt; 0 || status &gt; ENV_NOT_RUNNABLE)        return -E_INVAL;    if (r = envid2env(envid, &amp;e, 1), r &lt; 0)        return r;    e-&gt;env_status = status;    return 0;}\n\nsys_page_alloc注意需要检查地址的合法性和对齐性，以及perm的合法性：\nstatic intsys_page_alloc(envid_t envid, void *va, int perm){#define CHECK_ALIGIN_UVA(_va) do {\\    uintptr_t __tmp__ = (uintptr_t)(_va);\\    if (__tmp__ &gt;= UTOP || (__tmp__ &amp; (PGSIZE - 1)))\\        return -E_INVAL;\\} while (0)#define CHECK_SYSCALL_PERM(_perm) do {\\    int __tmp__ = _perm;\\    if (!(__tmp__ &amp; PTE_P) || !(__tmp__ &amp; PTE_U) || (__tmp__ &amp; ~PTE_SYSCALL))\\        return -E_INVAL;\\} while (0)    int r;    struct Env *e;    struct PageInfo *pp;    CHECK_ALIGIN_UVA(va);    CHECK_SYSCALL_PERM(perm);    if (r = envid2env(envid, &amp;e, 1), r &lt; 0)        return r;    if (!(pp = page_alloc(ALLOC_ZERO)))        return -E_NO_MEM;    if (r = page_insert(e-&gt;env_pgdir, pp, va, perm), r &lt; 0) {        page_free(pp);        return r;    }    return 0;}\n\nsys_page_map过程较为繁琐，需要进行多个检查：\nstatic intsys_page_map(envid_t srcenvid, void *srcva,\t     envid_t dstenvid, void *dstva, int perm){    int r;    struct Env *srce, *dste;    pte_t *pte;    struct PageInfo *pp;    CHECK_ALIGIN_UVA(srcva);    CHECK_ALIGIN_UVA(dstva);    CHECK_SYSCALL_PERM(perm);    if (r = envid2env(srcenvid, &amp;srce, 1), r &lt; 0)        return r;    if (r = envid2env(dstenvid, &amp;dste, 1), r &lt; 0)        return r;    if (!(pp = page_lookup(srce-&gt;env_pgdir, srcva, &amp;pte)))        return -E_INVAL;    if (!(*pte | PTE_W) &amp;&amp; (perm &amp; PTE_W))        return -E_INVAL;    if (r = page_insert(dste-&gt;env_pgdir, pp, dstva, perm), r &lt; 0)        return r;    return 0;}\n\nsys_page_unmap比较简单，用page_remove即可：\nstatic intsys_page_unmap(envid_t envid, void *va){    int r;    struct Env *e;    CHECK_ALIGIN_UVA(va);    if (r = envid2env(envid, &amp;e, 1), r &lt; 0)        return r;    page_remove(e-&gt;env_pgdir, va);    return 0;}#undef CHECK_SYSCALL_PERM#undef CHECK_ALIGIN_UVA\n\nExercise 8envid2env需要检查进程访问权限，其他按要求实现即可：\nstatic intsys_env_set_pgfault_upcall(envid_t envid, void *func){    int r;    struct Env *e;    if (r = envid2env(envid, &amp;e, 1), r &lt; 0)        return r;    e-&gt;env_pgfault_upcall = func;    return 0;}\n\nExercise 9过程较为繁琐，具体过程见注释：\nvoidpage_fault_handler(struct Trapframe *tf){    uint32_t fault_va;    // Read processor's CR2 register to find the faulting address    fault_va = rcr2();    // Handle kernel-mode page faults.    // LAB 3: Your code here.    if ((tf-&gt;tf_cs &amp; 3) == 0) {        print_trapframe(tf);        panic(\"[%08x] kernel fault va %08x ip %08x\\n\",\t\t    curenv-&gt;env_id, fault_va, tf-&gt;tf_eip);    }    // check upcall    if (!curenv-&gt;env_pgfault_upcall) {        log(\"no upcall\");        goto bad;    }    // check whether upcall and xstack are in user space    user_mem_assert(curenv, (void*)curenv-&gt;env_pgfault_upcall, 0, PTE_U);    user_mem_assert(curenv, (void*)(UXSTACKTOP - 1), 0, PTE_U | PTE_W);    // check xstack overflow    if (fault_va &lt; UXSTACKTOP - PGSIZE &amp;&amp; fault_va &gt;= UXSTACKTOP - 2 * PGSIZE) {        log(\"xstack overflow\");        goto bad;    }    // prepare stack frame    uint32_t esp;    struct UTrapframe* utf;    if (tf-&gt;tf_esp &gt;= UXSTACKTOP - PGSIZE &amp;&amp; tf-&gt;tf_esp &lt;= UXSTACKTOP) {        esp = tf-&gt;tf_esp - (sizeof(struct UTrapframe) + 4);    } else {        esp = UXSTACKTOP - sizeof(struct UTrapframe);    }    // stack overflow    if (esp &lt; UXSTACKTOP - PGSIZE) {        log(\"xstack overflow\");        goto bad;    }        utf = (struct UTrapframe *) esp;    utf-&gt;utf_eflags = tf-&gt;tf_eflags;    utf-&gt;utf_eip = tf-&gt;tf_eip;    utf-&gt;utf_esp = tf-&gt;tf_esp;    utf-&gt;utf_regs = tf-&gt;tf_regs;    utf-&gt;utf_err = tf-&gt;tf_err;    utf-&gt;utf_fault_va = fault_va;    // change esp / eip    tf-&gt;tf_esp = esp;    tf-&gt;tf_eip = (uint32_t)curenv-&gt;env_pgfault_upcall;    return;bad:    // Destroy the environment that caused the fault.    cprintf(\"[%08x] user fault va %08x ip %08x\\n\",        curenv-&gt;env_id, fault_va, tf-&gt;tf_eip);    print_trapframe(tf);    env_destroy(curenv);}\n\nExercise 10首先需要将返回地址压到“将要切换回去的栈”，接着依次恢复寄存器即可。\n.text.globl _pgfault_upcall_pgfault_upcall:    // Call the C page fault handler.    pushl %esp\t\t\t// function argument: pointer to UTF    movl _pgfault_handler, %eax    call *%eax    addl $4, %esp\t\t\t// pop function argument    // LAB 4: Your code here.    movl 48(%esp), %eax    movl 40(%esp), %ebx    subl $4, %eax    movl %ebx, (%eax)    movl %eax, 48(%esp)    // Restore the trap-time registers.  After you do this, you    // can no longer modify any general-purpose registers.    // LAB 4: Your code here.    addl $8, %esp    popal    // Restore eflags from the stack.  After you do this, you can    // no longer use arithmetic operations or anything else that    // modifies eflags.    // LAB 4: Your code here.    addl $4, %esp     popf    // Switch back to the adjusted trap-time stack.    // LAB 4: Your code here.    movl (%esp), %esp    // Return to re-execute the instruction that faulted.    // LAB 4: Your code here.    ret\n\nExercise 11分配一个异常处理栈，再设置upcall函数即可：\nvoidset_pgfault_handler(void (*handler)(struct UTrapframe *utf)){#define PANIC panic(\"set_pgfault_handler: %e\", r)    int r;    if (_pgfault_handler == 0) {        // First time through!        // LAB 4: Your code here.        // panic(\"set_pgfault_handler not implemented\");                if (r = sys_page_alloc(0, (void*)(UXSTACKTOP - PGSIZE), PTE_P | PTE_U | PTE_W), r &lt; 0)            PANIC;        if (r = sys_env_set_pgfault_upcall(0, _pgfault_upcall), r &lt; 0)            PANIC;    }    // Save handler pointer for assembly to call.    _pgfault_handler = handler;    return;#undef PANIC}\n\nExercise 12fork先exofork一个进程，之后父进程将用户空间用duppage拷贝过去，再单独分配一个异常栈，设置upcall，最后再设置子进程的状态：\nenvid_tfork(void){#define PANIC panic(\"fork: %e\", r)    // LAB 4: Your code here.    // panic(\"fork not implemented\");    int r;    envid_t ceid;    set_pgfault_handler(pgfault);    if (ceid = sys_exofork(), ceid == 0) {        thisenv = &amp;envs[ENVX(sys_getenvid())];    } else if (ceid &gt; 0) {        // assume UTOP == UXSTACKTOP        for (size_t pn = 0; pn &lt; UTOP / PGSIZE - 1;) {            uint32_t pde = uvpd[pn / NPDENTRIES];            if (!(pde &amp; PTE_P)) {                pn += NPDENTRIES;            } else {                size_t next = MIN(UTOP / PGSIZE - 1, pn + NPDENTRIES);                for (; pn &lt; next; ++pn) {                    uint32_t pte = uvpt[pn];                    if (pte &amp; PTE_P &amp;&amp; pte &amp; PTE_U)                        if (r = duppage(ceid, pn), r &lt; 0)                            PANIC;                }            }        }        if (r = sys_page_alloc(ceid, (void*)(UXSTACKTOP - PGSIZE),                                 PTE_P | PTE_U | PTE_W), r &lt; 0)            PANIC;        if (r = sys_env_set_pgfault_upcall(ceid, _pgfault_upcall), r &lt; 0)            PANIC;        if (r = sys_env_set_status(ceid, ENV_RUNNABLE), r &lt; 0)            PANIC;    }    return ceid;#undef PANIC}\n\nduppage按要求拷贝页面即可：\nstatic intduppage(envid_t envid, unsigned pn){    // LAB 4: Your code here.    // panic(\"duppage not implemented\");    int r;    void *pg;    pte_t pte;    pg = (void*)(pn * PGSIZE);    pte = uvpt[pn];    assert(pte &amp; PTE_P &amp;&amp; pte &amp; PTE_U);    if (pte &amp; PTE_W || pte &amp; PTE_COW) {        if (r = sys_page_map(0, pg, envid, pg, PTE_P | PTE_U | PTE_COW), r &lt; 0)            return r;        if (r = sys_page_map(0, pg, 0, pg, PTE_P | PTE_U | PTE_COW), r &lt; 0)            return r;    } else {        if (r = sys_page_map(0, pg, envid, pg, PTE_P | PTE_U), r &lt; 0)            return r;    }    return 0;}\n\npgfault过程比较简单，主要是检查出错地址比较繁琐：\nstatic voidpgfault(struct UTrapframe *utf){#define PANIC panic(\"page fault handler: %e\", r)    void *addr = (void *) utf-&gt;utf_fault_va;    uint32_t err = utf-&gt;utf_err;    int r;    // Check that the faulting access was (1) a write, and (2) to a    // copy-on-write page.  If not, panic.    // Hint:    //   Use the read-only page table mappings at uvpt    //   (see &lt;inc/memlayout.h&gt;).    // LAB 4: Your code here.    addr = ROUNDDOWN(addr, PGSIZE);    if (!(            (uvpd[PDX(addr)] &amp; PTE_P) &amp;&amp;             (uvpt[PGNUM(addr)] &amp; PTE_P) &amp;&amp;             (uvpt[PGNUM(addr)] &amp; PTE_U) &amp;&amp;             (uvpt[PGNUM(addr)] &amp; PTE_COW) &amp;&amp;             (err &amp; FEC_WR) &amp;&amp;             1        )) {        panic(            \"[0x%08x] user page fault va 0x%08x ip 0x%08x: \"            \"[%s, %s, %s]\",            sys_getenvid(),            utf-&gt;utf_fault_va,            utf-&gt;utf_eip,            err &amp; 4 ? \"user\" : \"kernel\",            err &amp; 2 ? \"write\" : \"read\",            err &amp; 1 ? \"protection\" : \"not-present\"        );    }    // Allocate a new page, map it at a temporary location (PFTEMP),    // copy the data from the old page to the new page, then move the new    // page to the old page's address.    // Hint:    //   You should make three system calls.    // LAB 4: Your code here.    if (r = sys_page_alloc(0, PFTEMP, PTE_P | PTE_U | PTE_W), r &lt; 0)        PANIC;    memmove(PFTEMP, addr, PGSIZE);    if (r = sys_page_map(0, PFTEMP, 0, addr, PTE_P | PTE_U | PTE_W), r &lt; 0)        PANIC;    if (r = sys_page_unmap(0, PFTEMP), r &lt; 0)        PANIC;    return;#undef PANIC}\n\nExercise 13对我来说只需要在kern/trapentry.inc里添加几项即可：\nTH(32) // TIMERTH(33) // KBDTH(36) // SERIALTH(39) // SPURIOUSTH(46) // IDETH(51) // ERROR\n\n在kern/env.c的env_alloc里加入：\n// Enable interrupts while in user mode.// LAB 4: Your code here.e-&gt;env_tf.tf_eflags |= FL_IF;\n\nExercise 14在trap_dispatch中加入：\nif (tf-&gt;tf_trapno == IRQ_OFFSET + IRQ_TIMER) {    lapic_eoi();    sched_yield();    return;}\n\nExercise 15kern/syscall.c定义了ipc_try_send和ipc_send_page作为辅助函数，其他实现按要求即可：\nstatic int ipc_send_page(struct Env* srce, struct Env* dste){    int r;    void * srcva = srce-&gt;env_ipc_dstva;    void * dstva = dste-&gt;env_ipc_dstva;    unsigned perm = srce-&gt;env_ipc_perm;    if (srcva &lt; (void*)UTOP &amp;&amp; dstva &lt; (void*)UTOP) {        struct PageInfo *pp;        pte_t *pte;        if ((uint32_t)srcva &amp; (PGSIZE - 1))            return -E_INVAL;        if (!(perm &amp; PTE_P) || !(perm &amp; PTE_U) || perm &amp; ~PTE_SYSCALL)            return -E_INVAL;        if (pp = page_lookup(srce-&gt;env_pgdir, srcva, &amp;pte), !pp)            return -E_INVAL;        if (perm &amp; PTE_W &amp;&amp; !(*pte &amp; PTE_W))            return -E_INVAL;        if (r = page_insert(dste-&gt;env_pgdir, pp, dstva, perm), r &lt; 0)            return r;    } else {        dste-&gt;env_ipc_perm = 0;    }    return 0;}static int ipc_try_send(struct Env* dste, uint32_t value, void* srcva, unsigned perm){    int r;    struct Env *cure = curenv;    if (!(dste-&gt;env_ipc_recving &amp;&amp; dste-&gt;env_status == ENV_NOT_RUNNABLE))        return -E_IPC_NOT_RECV;    // map page    cure-&gt;env_ipc_dstva = srcva;    cure-&gt;env_ipc_perm = perm;    if (r = ipc_send_page(cure, dste), r &lt; 0)         return r;    // ok    dste-&gt;env_ipc_recving = 0;    dste-&gt;env_ipc_from = cure-&gt;env_id;    dste-&gt;env_ipc_value = value;    dste-&gt;env_status = ENV_RUNNABLE;    dste-&gt;env_tf.tf_regs.reg_eax = 0;        return 0;}static intsys_ipc_try_send(envid_t envid, uint32_t value, void *srcva, unsigned perm){    // LAB 4: Your code here.    // panic(\"sys_ipc_try_send not implemented\");    int r;    struct Env *dste;    if (r = envid2env(envid, &amp;dste, 0), r &lt; 0)        return r;    return ipc_try_send(dste, value, srcva, perm);}static intsys_ipc_recv(void *dstva){    int r;    struct Env *cure = curenv;    // LAB 4: Your code here.    // panic(\"sys_ipc_recv not implemented\");    if (dstva &lt; (void*)UTOP &amp;&amp; (uint32_t)dstva &amp; (PGSIZE - 1))        return -E_INVAL;    cure-&gt;env_ipc_dstva = dstva;    cure-&gt;env_ipc_recving = 1;    cure-&gt;env_status = ENV_NOT_RUNNABLE;    sched_yield();    return 0;}\n\nlib/ipc.c按要求实现即可：\nint32_tipc_recv(envid_t *from_env_store, void *pg, int *perm_store){    // LAB 4: Your code here.    // panic(\"ipc_recv not implemented\");    int r;    envid_t feid;    int perm;    if (r = sys_ipc_recv(pg ? ROUNDDOWN(pg, PGSIZE) : (void*)UTOP), r &lt; 0) {        feid = 0;        perm = 0;    } else {        feid = thisenv-&gt;env_ipc_from;        perm = thisenv-&gt;env_ipc_perm;    }    if (from_env_store)        *from_env_store = feid;    if (perm_store)        *perm_store = perm;    return r &lt; 0 ? r : thisenv-&gt;env_ipc_value;}voidipc_send(envid_t to_env, uint32_t val, void *pg, int perm){    // LAB 4: Your code here.    // panic(\"ipc_send not implemented\");    int r;    while(r = sys_ipc_try_send(to_env, val, pg ?                                 ROUNDDOWN(pg, PGSIZE) :                                 (void*)UTOP, perm), r == -E_IPC_NOT_RECV)        sys_yield();    if (r &lt; 0)        panic(\"ipc send: %e\", r);}\n\nThis completes this labdumbfork: OK (0.9s) Part A score: 5/5faultread: OK (0.8s) faultwrite: OK (1.2s) faultdie: OK (1.6s) faultregs: OK (2.2s) faultalloc: OK (1.0s) faultallocbad: OK (1.7s) faultnostack: OK (2.2s) faultbadhandler: OK (2.1s) faultevilhandler: OK (1.9s) forktree: OK (1.9s) Part B score: 50/50spin: OK (2.1s) stresssched: OK (2.3s) sendpage: OK (1.8s) pingpong: OK (1.8s) primes: OK (3.2s) Part C score: 25/25Score: 80/80\n\n注：以下结果为开启了CONF_IPC_SLEEP和CONF_MFQ后的测试结果，故这两个相关的challenge的测试结果之后就不再赘述。从中可以看出部分测试的运行时间改进明显（如stresssched）。\ndumbfork: OK (1.3s) Part A score: 5/5faultread: OK (0.9s) faultwrite: OK (1.1s) faultdie: OK (1.7s)faultregs: OK (1.5s) faultalloc: OK (1.4s) faultallocbad: OK (1.4s) faultnostack: OK (1.7s) faultbadhandler: OK (2.0s) faultevilhandler: OK (2.3s) forktree: OK (1.6s) Part B score: 50/50spin: OK (2.9s) stresssched: OK (1.6s) sendpage: OK (1.7s) pingpong: OK (2.1s) primes: OK (3.0s) Part C score: 25/25Score: 80/80\n\nChallenge: Sleep IPC描述实现了一个新的系统调用sys_ipc_send，若目标进程未处于等待状态，会阻塞。接口与sys_ipc_try_send一致。\n原理\n若调用sys_ipc_send时目标进程未处于接收状态，则加入目标进程的IPC阻塞队列，并将自己的状态设为阻塞；否则正常发送。\n若调用sys_ipc_recv时发现自己的IPC阻塞队列非空，则直接取队首的进程接收；否则阻塞。\n\n实现inc/config.h在config文件（Lab2时自己添加的，用于启动或者关闭一些可选功能）中添加选项：\n#define CONF_IPC_SLEEP\n\ninc/elink.h创建了一个新的头文件，定义了嵌于其他结构体中的通用链表节点EmbedLink以及相关的操作函数（参考自Linux的一些数据结构）：\n#include &lt;inc/types.h&gt;typedef struct EmbedLink {    struct EmbedLink *prev, *next;} EmbedLink;static inline void elink_init(EmbedLink *ln) {    ln-&gt;prev = ln-&gt;next = ln;}static inline EmbedLink* elink_remove(EmbedLink *ln) {    ln-&gt;prev-&gt;next = ln-&gt;next;    ln-&gt;next-&gt;prev = ln-&gt;prev;    elink_init(ln);    return ln;}static inline void elink_insert(EmbedLink *pos, EmbedLink *ln) {    ln-&gt;prev = pos, ln-&gt;next = pos-&gt;next;    ln-&gt;prev-&gt;next = ln-&gt;next-&gt;prev = ln;}static inline bool elink_empty(EmbedLink * ln) {    if (ln-&gt;prev == ln) {        assert(ln-&gt;next == ln);        return true;    } else {        return false;    }}static inline void elink_enqueue(EmbedLink *que, EmbedLink *ln) {    elink_insert(que-&gt;prev, ln);}static inline EmbedLink*elink_queue_head(EmbedLink* que){    return que-&gt;next;}static inline EmbedLink* elink_dequeue(EmbedLink* que){    return elink_remove(elink_queue_head(que));}#define offset(_t, _m) ((uint32_t)(&amp;((_t*)0)-&gt;_m))#define master(_x, _t, _m) ((_t*)((void*)(_x) - offset(_t, _m)))\n\ninc/env.h在struct Env中添加两个成员：\nEmbedLink env_ipc_link;         // Embeded link to the blocking queue.EmbedLink env_ipc_queue;        // Blocking queue.\n\nkern/env.c在env_alloc中初始化新增成员：\nelink_init(&amp;e-&gt;env_ipc_link);elink_init(&amp;e-&gt;env_ipc_queue);\n\n在env_free中唤醒阻塞的IPC发送者，并将自己从IPC阻塞队列中取下：\n// wakeup the sleeping senderswhile(!elink_empty(&amp;e-&gt;env_ipc_queue)) {\tstruct Env* sender = master(elink_dequeue(&amp;e-&gt;env_ipc_queue),                                    struct Env, env_ipc_link);\tsender-&gt;env_status = ENV_RUNNABLE;\tsender-&gt;env_tf.tf_regs.reg_eax = -E_BAD_ENV;}elink_remove(&amp;e-&gt;env_ipc_link);\n\nkern/syscall.c添加sys_ipc_send，并修改sys_ipc_recv：\nstatic int sys_ipc_send(envid_t envid, uint32_t value, void *srcva, unsigned perm){    int r;    struct Env* dste;    struct Env* cure = curenv;    if (r = envid2env(envid, &amp;dste, 0), r &lt; 0)        return r;    if (r = ipc_try_send(dste, value, srcva, perm), r != -E_IPC_NOT_RECV)        return r;    cure-&gt;env_ipc_dstva = srcva;    cure-&gt;env_ipc_perm = perm;    cure-&gt;env_ipc_value = value;    cure-&gt;env_status = ENV_NOT_RUNNABLE;    elink_enqueue(&amp;dste-&gt;env_ipc_queue, &amp;cure-&gt;env_ipc_link);    sched_yield();    return 0;}static intsys_ipc_recv(void *dstva){    int r;    struct Env *cure = curenv;  // LAB 4: Your code here.  // panic(\"sys_ipc_recv not implemented\");    if (dstva &lt; (void*)UTOP &amp;&amp; (uint32_t)dstva &amp; (PGSIZE - 1))        return -E_INVAL;    cure-&gt;env_ipc_dstva = dstva;    if (!elink_empty(&amp;cure-&gt;env_ipc_queue)) {        EmbedLink* ln = elink_dequeue(&amp;cure-&gt;env_ipc_queue);        struct Env* sender = master(ln, struct Env, env_ipc_link);        r = ipc_send_page(sender, cure);                    sender-&gt;env_status = ENV_RUNNABLE;        sender-&gt;env_tf.tf_regs.reg_eax = r;        if (r &lt; 0)            goto sleep;        cure-&gt;env_ipc_from = sender-&gt;env_id;        cure-&gt;env_ipc_value = sender-&gt;env_ipc_value;        return 0;    }sleep:    cure-&gt;env_ipc_recving = 1;    cure-&gt;env_status = ENV_NOT_RUNNABLE;    sched_yield();    return 0;}\n\nlib/ipc.h修改ipc_send函数：\nvoidipc_send(envid_t to_env, uint32_t val, void *pg, int perm){  // LAB 4: Your code here.  // panic(\"ipc_send not implemented\");    int r;#ifndef CONF_IPC_SLEEP    while(r = sys_ipc_try_send(to_env, val, pg ?                                ROUNDDOWN(pg, PGSIZE) :                                (void*)UTOP, perm), r == -E_IPC_NOT_RECV)        sys_yield();#else    r = sys_ipc_send(to_env, val, pg ? ROUNDDOWN(pg, PGSIZE) : (void*)UTOP, perm);#endif    if (r &lt; 0)        panic(\"ipc send: %e\", r);}\n\nChallenge: Multilevel Feedback Queue实现了多级反馈队列（MFQ）调度算法。\n原理不再赘述，下面仅说明实现：\n实现inc/config.h新增选项：\n#define CONF_MFQ\n\ninc/env.h在struct Env中添加以下成员，用于记录必要信息（取名比较直白，就不注释说明了）。\n#ifdef CONF_MFQ    EmbedLink env_mfq_link;    uint32_t env_mfq_level;    int env_mfq_left_ticks;#endif\n\nkern/env.h添加以下内容。其中env_ready(e)可用于代替所有的e-&gt;env_status = ENV_RUNNABLE语句，修改的地方不再赘述：\n#ifdef CONF_MFQ #define NMFQ 5#define MFQ_SLICE 2extern EmbedLink* mfqs;void \tenv_mfq_add(struct Env* e);void \tenv_mfq_pop(struct Env* e);#endifvoid \tenv_ready(struct Env* e);\n\nkern/pmap.c在mem_init初始化mfq：\n#ifdef CONF_MFQ\t//////////////////////////////////////////////////////////////////////\t// Make 'mfqs' point to an array of size 'NMFQ' of 'EmbedLink'.\tmfqs = (EmbedLink* ) boot_alloc(NMFQ * sizeof(EmbedLink));\tmemset(mfqs, 0, NMFQ * sizeof(EmbedLink));\tfor (int i = 0 ; i &lt; NMFQ; ++i)\t\telink_init(&amp;mfqs[i]);#endif\n\nkern/env.c实现MFQ相关函数。\n其中env_mfq_add用于将进程加入队列，通常通过env_ready调用。\nenv_mfq_pop将进程从队列中移除。\n#ifdef CONF_MFQEmbedLink* mfqs = NULL;void env_mfq_add(struct Env *e) {\telink_remove(&amp;e-&gt;env_mfq_link);\tif (e-&gt;env_mfq_left_ticks &gt; 0) { // time slice left         // add to queue's head\t\telink_insert(&amp;mfqs[e-&gt;env_mfq_level], &amp;e-&gt;env_mfq_link);\t\t} else { // no time slice left\t\tuint32_t lv = MIN(e-&gt;env_mfq_level + 1, NMFQ - 1);\t\te-&gt;env_mfq_level = lv;\t\te-&gt;env_mfq_left_ticks = (1 &lt;&lt; lv) * MFQ_SLICE;\t\telink_enqueue(&amp;mfqs[lv], &amp;e-&gt;env_mfq_link);\t}}void env_mfq_pop(struct Env* e){\telink_remove(&amp;e-&gt;env_mfq_link);}#endifvoid env_ready(struct Env* e){\te-&gt;env_status = ENV_RUNNABLE;#ifdef CONF_MFQ\tenv_mfq_add(e);#endif}\n\n在env_alloc中初始化相关成员：\n#ifdef CONF_MFQ\te-&gt;env_mfq_level = 0;\te-&gt;env_mfq_left_ticks = MFQ_SLICE;\telink_enqueue(&amp;mfqs[0], &amp;e-&gt;env_mfq_link);#endif\n\n在env_free中处理相关成员：\n#ifdef CONF_MFQ\te-&gt;env_mfq_level = 0;\te-&gt;env_mfq_left_ticks = 0;\tenv_mfq_pop(e);#endif\n\n修改env_run，将当前要运行的进程从队列中移除。注意，只要进程不处于就绪态就要从MFQ中移除，包括IPC发送、接收时的阻塞，这些方面的修改就不再赘述了。\nvoidenv_run(struct Env *e){    struct Env* olde = curenv;    if (olde &amp;&amp; olde-&gt;env_status == ENV_RUNNING)        env_ready(olde);    curenv = e;    e-&gt;env_status = ENV_RUNNING;    e-&gt;env_runs += 1;#ifdef CONF_MFQ    env_mfq_pop(e);#endif    if (olde != e) // 只有进程切换才进行，尽可能避免TLB失效        lcr3(PADDR(e-&gt;env_pgdir));    unlock_kernel();    env_pop_tf(&amp;e-&gt;env_tf);}\n\nkern/sched.c修改sched_yield函数，实现MFQ调度算法：\n#ifndef CONF_MFQ// RR scheduler#else void sched_yield(void){    struct Env* idle = NULL;    for (int i = 0; i &lt; NMFQ; ++i) {        if (!elink_empty(&amp;mfqs[i])) {            idle = master(elink_queue_head(&amp;mfqs[i]), struct Env, env_mfq_link);            // assert(idle-&gt;env_status == ENV_RUNNABLE);            if (idle-&gt;env_status != ENV_RUNNABLE) {                log_int(idle-&gt;env_status);                panic(\"only runnable env can be in mfq\");\t            }            break;        }    }    if (idle) {        env_run(idle);    } else if (curenv &amp;&amp; curenv-&gt;env_status == ENV_RUNNING) {        env_run(curenv);    }    sched_halt();}#endif\n\nkern/trap.c在trap_dispatch中修改对时钟中断的处理：\n    if (tf-&gt;tf_trapno == IRQ_OFFSET + IRQ_TIMER) {#ifndef CONF_MFQ        lapic_eoi();        sched_yield();        return;#else        struct Env* cure = curenv;        lapic_eoi();        if (cure &amp;&amp; cure-&gt;env_mfq_left_ticks-- == 1) {            sched_yield();        }        return;#endif    }\n\nChallenge: Process snapshot and rollback描述实现了两个系统调用sys_snapshot和sys_rollback。\n接口如下：\nenvid_t\tsys_env_snapshot(uint32_t *dmail_store);int sys_env_rollback(envid_t spst, uint32_t dmail);\n\nsys_env_snapshot：\n\n参数dmail_store：用于存储来自“未来”的信息。\n返回envid：作为snapshot的标识。\n出错返回负数。\n\nsys_env_rollback：\n\n参数spst：回滚的目标snapshot。\n参数dmail：传递给“过去”的信息。\n通常不返回，出错则返回负数。\n\n以下为一个使用示例：\n#include &lt;inc/lib.h&gt;int min = 0;void umain(int argc, char** argv){    uint32_t dmail = 0;    int sec = 0;    envid_t spst = sys_env_snapshot(&amp;dmail);    if (dmail == EMPTY_DMAIL) {        sys_env_rollback(spst, 0);    } else if (dmail &lt; 10) {        cprintf(\"recv dmail %d at time(%d:%d)\\n\", dmail, min++, sec++);        sys_env_rollback(spst, ++dmail);    }}\n\n输出：\n[00000000] new env 00001000[00001000] new env 00001001recv dmail 0 at time(0:0)recv dmail 1 at time(0:0)recv dmail 2 at time(0:0)recv dmail 3 at time(0:0)recv dmail 4 at time(0:0)recv dmail 5 at time(0:0)recv dmail 6 at time(0:0)recv dmail 7 at time(0:0)recv dmail 8 at time(0:0)recv dmail 9 at time(0:0)[00001000] exiting gracefully[00001000] free env 00001000[00001000] free env 00001001No runnable environments in the system!\n\n原理基本原理和fork类似，不过核心部分均在内核而不是用户态实现（主要是出于效率方面的考虑）：\n\nsnapshot的时候分配一个新的快照进程，加入当前进程的快照列表中（每个进程可以持有多个快照，按时间排列）；用类似fork的方式复制当前进程的页到快照进程。\nrollback的时候，先将快照列表中目标快照之后的快照释放（符合直觉，而且可以防止不断回滚不断重复做快照让PCB耗尽）。之后用目标快照恢复当前进程的寄存器、内存等信息。\n\n实现inc/env.h新增一个EnvType：ENV_TYPE_SPST，用于表示作为快照的进程\n// Special environment typesenum EnvType {    ENV_TYPE_USER = 0,    ENV_TYPE_SPST,  // snapshot};\n\n在struct Env中新增以下成员：\n    EmbedLink env_spst_link;    // Embeded link to the snapshot list    envid_t env_spst_owner_id;  // snapshot's owner env's id    envid_t env_spst_id;        // rollbacked snapshot's id    uint32_t env_spst_dmail;    // DeLorean-Mail（这一切都是命运石之门的选择!）#define EMPTY_DMAIL ~0U\n\nkern/syscall.c实现sys_env_snapshot和sys_env_rollback：\nstatic envid_tsys_env_snapshot(void){#define CHECK(x) do {if (r = (x), r &lt; 0) return r;} while(0)    int r;    struct Env* cure = curenv;    struct Env* e;        CHECK(env_alloc(&amp;e, cure-&gt;env_id));    e-&gt;env_tf = cure-&gt;env_tf;    e-&gt;env_status = ENV_NOT_RUNNABLE;    e-&gt;env_type = ENV_TYPE_SPST;    e-&gt;env_spst_owner_id = cure-&gt;env_id;    elink_enqueue(&amp;cure-&gt;env_spst_link, &amp;e-&gt;env_spst_link);#ifdef CONF_MFQ    env_mfq_pop(e);#endif    for (uint32_t pdeno = 0; pdeno &lt; PDX(UTOP); ++pdeno) {        if ((cure-&gt;env_pgdir[pdeno] &amp; PTE_P) == 0)            continue;        pte_t* pt = (pte_t*)KADDR(PTE_ADDR(cure-&gt;env_pgdir[pdeno]));        for (uint32_t pteno = 0; pteno &lt; NPDENTRIES; ++pteno) {            if (pt[pteno] &amp; PTE_P) {                pte_t pte = pt[pteno];                struct PageInfo* pp = pa2page(PTE_ADDR(pte));                void* va = PGADDR(pdeno, pteno, 0);                assert(pte &amp; PTE_U);                if (pte &amp; PTE_W || pte &amp; PTE_COW) {                    CHECK(page_insert(e-&gt;env_pgdir, pp, va, PTE_P | PTE_U | PTE_COW));                    CHECK(page_insert(cure-&gt;env_pgdir, pp, va, PTE_P | PTE_U | PTE_COW));                } else {                    CHECK(page_insert(e-&gt;env_pgdir, pp, va, PTE_P | PTE_U));                }            }        }    }    struct PageInfo* pp = page_lookup(cure-&gt;env_pgdir, (void*)(UXSTACKTOP - PGSIZE), 0);    CHECK(page_insert(e-&gt;env_pgdir, pp, (void*)(UXSTACKTOP - PGSIZE), PTE_P | PTE_U | PTE_W));    CHECK(page_insert(cure-&gt;env_pgdir, pp, (void*)(UXSTACKTOP - PGSIZE), PTE_P | PTE_U | PTE_W));    cure-&gt;env_spst_dmail = EMPTY_DMAIL;    return e-&gt;env_id;#undef CHECK}\n\nstatic int sys_env_rollback(envid_t eid, uint32_t dmail){#define CHECK(x) do {if (r = (x), r &lt; 0) return r;} while(0)    int r;    struct Env* cure = curenv;    struct Env* e;    envid_t ceid;    CHECK(envid2env(eid, &amp;e, 1));    if (e-&gt;env_type != ENV_TYPE_SPST || e-&gt;env_spst_owner_id != cure-&gt;env_id)        return -E_INVAL;    // 将该快照之后记录的快照全部删除    for(EmbedLink* ln = &amp;e-&gt;env_spst_link; ln-&gt;next != &amp;cure-&gt;env_spst_link; ) {        struct Env* tmpe = master(elink_remove(ln-&gt;next), struct Env, env_spst_link);        env_free(tmpe);    }    // 将快照进程的页映射到当前进程，并将当前进程多余的页删去    for (uint32_t pdeno = 0; pdeno &lt; PDX(UTOP); ++pdeno) {        if (e-&gt;env_pgdir[pdeno] &amp; PTE_P) {            pte_t *pt = (pte_t *)KADDR(PTE_ADDR(e-&gt;env_pgdir[pdeno]));            pte_t *pt2 = (cure-&gt;env_pgdir[pdeno] &amp; PTE_P)                             ? (pte_t *)KADDR(PTE_ADDR(cure-&gt;env_pgdir[pdeno]))                             : NULL;            for (uint32_t pteno = 0; pteno &lt; NPDENTRIES; ++pteno) {                if (pt[pteno] &amp; PTE_P) {                    pte_t pte = pt[pteno];                    CHECK(page_insert(cure-&gt;env_pgdir, pa2page(PTE_ADDR(pte)),                                PGADDR(pdeno, pteno, 0), pte &amp; PTE_SYSCALL));                } else if (pt2 &amp;&amp; pt2[pteno] &amp; PTE_P) {                    page_remove(cure-&gt;env_pgdir, PGADDR(pdeno, pteno, 0));                }            }        } else if (cure-&gt;env_pgdir[pdeno] &amp; PTE_P) {            pte_t *pt = (pte_t*)KADDR(PTE_ADDR(cure-&gt;env_pgdir[pdeno]));            for (uint32_t pteno = 0; pteno &lt; NPDENTRIES; ++pteno) {                if (pt[pteno] &amp; PTE_P)                    page_remove(cure-&gt;env_pgdir, PGADDR(pdeno, pteno, 0));            }        }    }    cure-&gt;env_tf = e-&gt;env_tf;    cure-&gt;env_spst_dmail = dmail;    return e-&gt;env_id;#undef CHECK}\n\nlib/fork.c实现sys_env_snapshot用户态的接口。之所以在lib/fork.c而不是lib/syscall.c里实现是为了设置page fault handler为pgfault。\nstatic inline int32_tsyscall(int num, int check, uint32_t a1, uint32_t a2, uint32_t a3, uint32_t a4, uint32_t a5){\tint32_t ret;\tasm volatile(\"int %1\\n\"\t\t     : \"=a\" (ret)\t\t     : \"i\" (T_SYSCALL),\t\t       \"a\" (num),\t\t       \"d\" (a1),\t\t       \"c\" (a2),\t\t       \"b\" (a3),\t\t       \"D\" (a4),\t\t       \"S\" (a5)\t\t     : \"cc\", \"memory\");\tif(check &amp;&amp; ret &gt; 0)\t\tpanic(\"syscall %d returned %d (&gt; 0)\", num, ret);\treturn ret;}envid_tsys_env_snapshot(uint32_t *dmail_store){ #define PANIC panic(\"sys_env_snapshot: %e\", r)    int r;    set_pgfault_handler(pgfault);    if (r = syscall(SYS_env_snapshot, 0, 0, 0, 0, 0, 0), r &lt; 0)        PANIC;    if (dmail_store)        *dmail_store = thisenv-&gt;env_spst_dmail;    return r;#undef PANIC   }\n\nlib/syscall.c实现sys_env_rollback的用户态接口：\nint sys_env_rollback(envid_t eid, uint32_t dmail){\tif (dmail == EMPTY_DMAIL)\t\treturn -E_INVAL;\tint r = syscall(SYS_env_rollback, 1, (uint32_t)eid, dmail, 0, 0, 0);\tif (r == 0)\t\tpanic(\"rollback should never return\");\treturn r;}\n\nCompatible to Page Size Extension在本Lab的多处理器环境下若要兼容Lab2一个Challenge中的大页扩展，需要在kern/init.c的mp_main函数内，加载页表之前设置好CR4寄存器的值：\nvoidmp_main(void){#ifdef CONF_HUGE_PAGE\t// Enable page size extension\tuint32_t cr4;\tcr4 = rcr4();\tcr4 |= CR4_PSE;\tlcr4(cr4);#endif\t// We are in high EIP now, safe to switch to kern_pgdir \tlcr3(PADDR(kern_pgdir));\t// ......}","tags":["OS"]},{"title":"MIT 6.828 JOS Lab5 实验报告","url":"/2020/10/05/MIT%206.828%20JOS%20Lab5%20%E5%AE%9E%E9%AA%8C%E6%8A%A5%E5%91%8A/","content":"前言此为本人上本校的操作系统实习(实验班)时所写的实验报告，简单记述了JOS Lab的各个Exercise、Challenge(未覆盖所有Challenge，每个Lab大概做了1~3个Challenge)的基本思路。仅供有需者参考，上有关课程(比如本校的操统实习实验班)的最好不要直接抄。\n附上源代码链接：https://github.com/Light-of-Hers/mit-jos\nExercise 1在env_create函数中加入如下语句即可：\nif (type == ENV_TYPE_FS)     e-&gt;env_tf.tf_eflags |= FL_IOPL_MASK;\n\n\nQ: Do you have to do anything else to ensure that this I/O privilege setting is saved and restored properly when you subsequently switch from one environment to another? Why?\nA: 不需要，因为IO权限保存在EFLAGS中，而上下文切换时会保存/恢复EFLAGS\n\nExercise 2bc_pgfault按要求完成即可。关于为什么先读取磁盘块再判断是否空闲，个人认为是因为读取的磁盘块可能是本身就是bitmap的一部分。\n// Allocate a page in the disk map region, read the contents// of the block from the disk into that page.// Hint: first round addr to page boundary. fs/ide.c has code to read// the disk.//// LAB 5: you code here:addr = ROUNDDOWN(addr, BLKSIZE);if (r = sys_page_alloc(0, addr, PTE_P | PTE_U | PTE_W), r &lt; 0)    panic(\"in bc_pgfault, sys_page_alloc: %e\", r);if (r = ide_read(blockno * BLKSECTS, addr, BLKSECTS), r &lt; 0)    panic(\"in bc_pgfault, ide_read: %e\", r);// Clear the dirty bit for the disk block page since we just read the// block from diskif ((r = sys_page_map(0, addr, 0, addr, uvpt[PGNUM(addr)] &amp; PTE_SYSCALL)) &lt; 0)    panic(\"in bc_pgfault, sys_page_map: %e\", r);// Check that the block we read was allocated. (exercise for// the reader: why do we do this *after* reading the block// in?)// perhaps it's the bitmap block, therefore reading the block before checking the bitmapif (bitmap &amp;&amp; block_is_free(blockno))    panic(\"reading free block %08x\\n\", blockno);\n\nflush_block按要求完成即可：\nvoidflush_block(void *addr){    uint32_t blockno = ((uint32_t)addr - DISKMAP) / BLKSIZE;    if (addr &lt; (void*)DISKMAP || addr &gt;= (void*)(DISKMAP + DISKSIZE))        panic(\"flush_block of bad va %08x\", addr);    // LAB 5: Your code here.    // panic(\"flush_block not implemented\");    int r;    addr = ROUNDDOWN(addr, BLKSIZE);    if (!va_is_mapped(addr) || !va_is_dirty(addr))        return;    if (r = ide_write(blockno * BLKSECTS, addr, BLKSECTS), r &lt; 0)        panic(\"in flush_block, ide_write: %e\", r);    if (r = sys_page_map(0, addr, 0, addr, uvpt[PGNUM(addr)] &amp; PTE_SYSCALL), r &lt; 0)        panic(\"in flush_block, sys_page_map: %e\", r);}\n\nExercise 3按顺序搜索空闲块即可：\nintalloc_block(void){    // The bitmap consists of one or more blocks.  A single bitmap block    // contains the in-use bits for BLKBITSIZE blocks.  There are    // super-&gt;s_nblocks blocks in the disk altogether.    // LAB 5: Your code here.    // panic(\"alloc_block not implemented\");    int blockno;    if (!super)        panic(\"no super block\");    for (blockno = 0; blockno &lt; super-&gt;s_nblocks; ++blockno)        if (block_is_free(blockno))            break;    if (blockno == super-&gt;s_nblocks)        return -E_NO_DISK;    bitmap[blockno / 32] &amp;= ~(1 &lt;&lt; (blockno % 32));    flush_block(bitmap);    return blockno;}\n\nExercise 4file_block_walk先寻找直接块，再寻找间接块，必要时分配一个间接块：\nstatic intfile_block_walk(struct File *f, uint32_t filebno, uint32_t **ppdiskbno, bool alloc){    // LAB 5: Your code here.    // panic(\"file_block_walk not implemented\");    if (filebno &lt; NDIRECT) {        *ppdiskbno = &amp;f-&gt;f_direct[filebno];        return 0;    }    filebno -= NDIRECT;    if (filebno &lt; NINDIRECT) {        if (f-&gt;f_indirect == 0) {            if (!alloc)                return -E_NOT_FOUND;            int blockno = alloc_block();            if (blockno &lt; 0)                return blockno;            f-&gt;f_indirect = (uint32_t)blockno;            memset(diskaddr(f-&gt;f_indirect), 0, BLKSIZE);        }        uint32_t *ind_blk = (uint32_t*)diskaddr(f-&gt;f_indirect);        *ppdiskbno = &amp;ind_blk[filebno];        return 0;    }    return -E_INVAL;}\n\nfile_get_block利用file_block_walk寻找对应的slot，得到对应的块号（必要时分配一个块），之后返回磁盘块对应的内存地址即可：\nintfile_get_block(struct File *f, uint32_t filebno, char **blk){    // LAB 5: Your code here.    // panic(\"file_get_block not implemented\");    int r;    uint32_t *diskbno;        if (r = file_block_walk(f, filebno, &amp;diskbno, 1), r &lt; 0)        return r;    if (*diskbno == 0) {        if (r = alloc_block(), r &lt; 0)            return r;        *diskbno = (uint32_t)r;    }    *blk = (char*)diskaddr(*diskbno);    return 0;}\n\nExercise 5模仿serve_set_size，利用file_read实现即可。注意最后要更新文件的offset。\nintserve_read(envid_t envid, union Fsipc *ipc){    struct Fsreq_read *req = &amp;ipc-&gt;read;    struct Fsret_read *ret = &amp;ipc-&gt;readRet;    if (debug)        cprintf(\"serve_read %08x %08x %08x\\n\", envid, req-&gt;req_fileid, req-&gt;req_n);    // Lab 5: Your code here:    int r;    struct OpenFile *o;    if (r = openfile_lookup(envid, req-&gt;req_fileid, &amp;o), r &lt; 0)        return r;    if (r = file_read(o-&gt;o_file, ret-&gt;ret_buf, req-&gt;req_n, o-&gt;o_fd-&gt;fd_offset), r &lt; 0)        return r;    o-&gt;o_fd-&gt;fd_offset += r;    return r;}\n\nExercise 6serve_write和serve_read实现类似：\nintserve_write(envid_t envid, struct Fsreq_write *req){    if (debug)        cprintf(\"serve_write %08x %08x %08x\\n\", envid, req-&gt;req_fileid, req-&gt;req_n);    // LAB 5: Your code here.    // panic(\"serve_write not implemented\");    int r;    struct OpenFile *o;    if (r = openfile_lookup(envid, req-&gt;req_fileid, &amp;o), r &lt; 0)        return r;    if (r = file_write(o-&gt;o_file, req-&gt;req_buf, req-&gt;req_n, o-&gt;o_fd-&gt;fd_offset), r &lt; 0)        return r;    o-&gt;o_fd-&gt;fd_offset += r;    return r;}\n\ndevfile_write模仿devfile_read实现即可：\nstatic ssize_tdevfile_write(struct Fd *fd, const void *buf, size_t n){    // Make an FSREQ_WRITE request to the file system server.  Be    // careful: fsipcbuf.write.req_buf is only so large, but    // remember that write is always allowed to write *fewer*    // bytes than requested.    // LAB 5: Your code here    // panic(\"devfile_write not implemented\");    int r;    assert(n &lt;= sizeof(fsipcbuf.write.req_buf));    fsipcbuf.write.req_fileid = fd-&gt;fd_file.id;    fsipcbuf.write.req_n = n;    memmove(fsipcbuf.write.req_buf, buf, n);    if (r = fsipc(FSREQ_WRITE, NULL), r &lt; 0)        return r;    assert(r &lt;= n);    return r;}\n\nExercise 7按要求设置一些必要的控制/状态寄存器即可：\nstatic intsys_env_set_trapframe(envid_t envid, struct Trapframe *tf){    // LAB 5: Your code here.    // Remember to check whether the user has supplied us with a good    // address!    // panic(\"sys_env_set_trapframe not implemented\");    int r;    struct Env *e;    if (r = envid2env(envid, &amp;e, 1), r &lt; 0)        return r;    e-&gt;env_tf = *tf;    tf = &amp;e-&gt;env_tf;    tf-&gt;tf_eflags |= FL_IF;    tf-&gt;tf_eflags &amp;= ~FL_IOPL_MASK;    tf-&gt;tf_cs |= GD_UT | 3;    tf-&gt;tf_ds |= GD_UD | 3;    tf-&gt;tf_es |= GD_UD | 3;    tf-&gt;tf_ss |= GD_UD | 3;    return 0;}\n\nExercise 8duppage按要求修改映射即可。注意我将COW的优先级视作比SHARE更高，也就是如果一个页是COW的，则将其视作COW处理而不管其是否为SHARE。\nstatic intduppage(envid_t envid, unsigned pn){    // LAB 4: Your code here.    // panic(\"duppage not implemented\");    int r;    void *pg;    pte_t pte;    pg = (void*)(pn * PGSIZE);    pte = uvpt[pn];    assert(pte &amp; PTE_P &amp;&amp; pte &amp; PTE_U);    if ((pte &amp; PTE_W &amp;&amp; !(pte &amp; PTE_SHARE)) || pte &amp; PTE_COW) {        if (r = sys_page_map(0, pg, envid, pg, (pte &amp; PTE_SYSCALL &amp; ~PTE_W) | PTE_COW), r &lt; 0)            return r;        if (r = sys_page_map(0, pg, 0, pg, (pte &amp; PTE_SYSCALL &amp; ~PTE_W) | PTE_COW), r &lt; 0)            return r;    } else {        if (r = sys_page_map(0, pg, envid, pg, pte &amp; PTE_SYSCALL), r &lt; 0)            return r;    }    return 0;}\n\ncopy_shared_pages只映射标记为SHARE的页面即可：\nstatic intcopy_shared_pages(envid_t child){    // LAB 5: Your code here.    int r;    uintptr_t addr;    for (addr = 0; addr &lt; UTOP;) {        if (!(uvpd[PDX(addr)] &amp; PTE_P)) {            addr = (uintptr_t)PGADDR(PDX(addr) + 1, PTX(addr), PGOFF(addr));        } else {            uintptr_t next =                 MIN((uintptr_t)PGADDR(PDX(addr) + 1, PTX(addr), PGOFF(addr)), UTOP);            for (; addr &lt; next; addr += PGSIZE) {                pte_t pte = uvpt[PGNUM(addr)];                if (pte &amp; PTE_P &amp;&amp; pte &amp; PTE_U &amp;&amp; pte &amp; PTE_SHARE)                    if (r = sys_page_map(0, (void*)addr,                                             child, (void*)addr, pte &amp; PTE_SYSCALL), r &lt; 0)                        return r;            }        }    }    return 0;}\n\nExercise 9在trap_dispatch中添加两个处理即可：\n// Handle keyboard and serial interrupts.// LAB 5: Your code here.if (tf-&gt;tf_trapno == IRQ_OFFSET + IRQ_KBD) {    kbd_intr();    lapic_eoi();    return;}if (tf-&gt;tf_trapno == IRQ_OFFSET + IRQ_SERIAL) {    serial_intr();    lapic_eoi();    return;}\n\nExercise 10模仿对输出重定向的处理即可：\nif (fd = open(t, O_RDONLY), fd &lt; 0) {    cprintf(\"open %s for read: %e\", t, fd);    exit();}if (fd != 0) {    dup(fd, 0);    close(fd);}\n\nThis completes this labinternal FS tests [fs/test.c]: OK (1.4s)   fs i/o: OK   check_bc: OK   check_super: OK   check_bitmap: OK   alloc_block: OK   file_open: OK   file_get_block: OK   file_flush/file_truncate/file rewrite: OK testfile: OK (1.3s)   serve_open/file_stat/file_close: OK   file_read: OK   file_write: OK   file_read after file_write: OK   open: OK   large file: OK spawn via spawnhello: OK (0.7s) Protection I/O space: OK (1.6s) PTE_SHARE [testpteshare]: OK (2.3s) PTE_SHARE [testfdsharing]: OK (1.1s) start the shell [icode]: Timeout! OK (31.4s) testshell: OK (1.9s) primespipe: OK (6.8s) Score: 150/150\n\nChallenge: Disk Buffer Cache目的限制在物理内存中缓存的磁盘块的个数\n原理\n用特定结构维护当前缓存着的磁盘块信息。\n维护一个计数器：\n每次对文件磁盘块访问时（调用file_get_block时），计数器加一。\n当计数器达到一定量时，清空计数器，扫描所有已缓存块，将其Access位清零。\n\n\n当缓存块数超出上限时：\n扫描缓存块，释放所有Access位为0的块。\n若找不到Access位为0的块，则释放最早缓存的一个块。\n\n\n一些系统保留的磁盘块（super块，bitmap块等）不考虑在内，也就是说这些保留块会永远驻留在内存中。\n\n实现在fs/bc.c中实现。实现代码如下，具体说明见注释。\n#define NCACHE 1024#define NVISIT (NCACHE / 4)typedef struct BufferCache {\tstruct BufferCache *bufc_free_link;\tEmbedLink bufc_used_link;\tvoid *bufc_addr;} BufferCache;static BufferCache bcaches[NCACHE];static BufferCache *bufc_free;static EmbedLink bufc_used;static int ncache = 0;static int nvisit = 0;static void bufc_init(void);static int bufc_alloc(void *addr);int bufc_visit(void);static int bufc_evict(void);static int bufc_remove(BufferCache *bc);static bool is_reserved(void *addr);// 是否为保留块？static bool is_reserved(void *addr){\treturn addr &lt; diskaddr(2);}// 每次page fault引入磁盘块后都会调用该函数static intbufc_alloc(void *addr){\tint r;\t// 忽略保留块\tif (is_reserved(addr))\t\treturn 0;\t// 缓存块数达到上限，驱逐一些块\tif (ncache == NCACHE) {\t\tif (r = bufc_evict(), r &lt; 0)\t\t\treturn r;\t}\t// 为addr分配一个块\tassert(bufc_free);\tncache++;\tBufferCache *bc = bufc_free;\tbufc_free = bufc_free-&gt;bufc_free_link;\telink_enqueue(&amp;bufc_used, &amp;bc-&gt;bufc_used_link);\tbc-&gt;bufc_addr = addr;\treturn 0;}// 初始化相关数据结构static voidbufc_init(void){\tbufc_free = NULL;\tfor (int i = 0; i &lt; NCACHE; ++i) {\t\telink_init(&amp;bcaches[i].bufc_used_link);\t\tbcaches[i].bufc_free_link = bufc_free, bufc_free = bcaches + i;\t\tbcaches[i].bufc_addr = 0;\t}\telink_init(&amp;bufc_used);}// 增加计数器。若达上限则扫描缓存块，将其Access位清零// 注意清零之前需要flush一下，因为sys_page_map不能保留Dirty位intbufc_visit(void) {\tint r;\tif (++nvisit &lt; NVISIT)\t\treturn 0;\tnvisit = 0;\tfor (EmbedLink *ln = bufc_used.next; ln != &amp;bufc_used; ln = ln-&gt;next) {\t\tBufferCache *bc = master(ln, BufferCache, bufc_used_link);\t\tvoid *addr = bc-&gt;bufc_addr;\t\tif (uvpt[PGNUM(addr)] &amp; PTE_A) {\t\t\tflush_block(addr);\t\t\tif (r = sys_page_map(0, addr, 0, addr, uvpt[PGNUM(addr)] &amp; PTE_SYSCALL), r &lt; 0)\t\t\t\treturn r;\t\t}\t}\treturn 0;}// 将缓存块的内容释放static int bufc_remove(BufferCache *bc) {\tint r;\tflush_block(bc-&gt;bufc_addr);\tif (r = sys_page_unmap(0, bc-&gt;bufc_addr), r &lt; 0)\t\treturn r;\tncache--;\telink_remove(&amp;bc-&gt;bufc_used_link);\tbc-&gt;bufc_free_link = bufc_free;\tbufc_free = bc;\tbc-&gt;bufc_addr = 0;\treturn 0;}// 驱逐一些缓存块static int bufc_evict(void) {\tint r;\tEmbedLink *ln;\t// 驱逐所有Access位为0的块\tfor (ln = bufc_used.next; ln != &amp;bufc_used;) {\t\tBufferCache *bc = master(ln, BufferCache, bufc_used_link);\t\tvoid *addr = bc-&gt;bufc_addr;\t\tln = ln-&gt;next;\t\tif (!(uvpt[PGNUM(addr)] &amp; PTE_A)) {\t\t\tif (r = bufc_remove(bc), r &lt; 0)\t\t\t\treturn r;\t\t}\t}\t// 如果失败，则驱逐最早进入缓存的块\tif (ncache == NCACHE) {\t\tln = bufc_used.next;\t\tassert(ln != &amp;bufc_used);\t\tBufferCache *bc = master(ln, BufferCache, bufc_used_link);\t\tif (r = bufc_remove(bc), r &lt; 0)\t\t\treturn r;\t}\treturn 0;}\n\n顺便在free_block时也将其映射的页释放：\n// Mark a block free in the bitmapvoidfree_block(uint32_t blockno){\tint r;\t// Blockno zero is the null pointer of block numbers.\tif (blockno == 0)\t\tpanic(\"attempt to free zero block\");\tbitmap[blockno/32] |= 1&lt;&lt;(blockno%32);\t// 释放缓存\tif (r = sys_page_unmap(0, diskaddr(blockno)), r &lt; 0)\t\tpanic(\"free_block: %e\", r);}\n\n测试将NCACHE设为16（基本上可以保证肯定会有驱逐现象）后的测试结果，\ninternal FS tests [fs/test.c]: OK (1.4s)   fs i/o: OK   check_bc: OK   check_super: OK   check_bitmap: OK   alloc_block: OK   file_open: OK   file_get_block: OK   file_flush/file_truncate/file rewrite: OK testfile: OK (1.1s)   serve_open/file_stat/file_close: OK   file_read: OK   file_write: OK   file_read after file_write: OK   open: OK   large file: OK spawn via spawnhello: OK (1.7s)     (Old jos.out.spawn failure log removed)Protection I/O space: OK (1.0s) PTE_SHARE [testpteshare]: OK (1.8s)     (Old jos.out.pte_share failure log removed)PTE_SHARE [testfdsharing]: OK (2.2s) start the shell [icode]: Timeout! OK (31.8s) testshell: OK (1.9s) primespipe: OK (5.5s) Score: 150/150","tags":["OS"]},{"title":"MIT 6.828 JOS Lab6 实验报告","url":"/2020/10/05/MIT%206.828%20JOS%20Lab6%20%E5%AE%9E%E9%AA%8C%E6%8A%A5%E5%91%8A/","content":"前言此为本人上本校的操作系统实习(实验班)时所写的实验报告，简单记述了JOS Lab的各个Exercise、Challenge(未覆盖所有Challenge，每个Lab大概做了1~3个Challenge)的基本思路。仅供有需者参考，上有关课程(比如本校的操统实习实验班)的最好不要直接抄。\n附上源代码链接：https://github.com/Light-of-Hers/mit-jos\nExercise 1在时钟中断处调用time_tick：\n    if (tf-&gt;tf_trapno == IRQ_OFFSET + IRQ_TIMER) {        time_tick();        lapic_eoi();#ifndef CONF_MFQ        sched_yield();        return;#else        struct Env* cure = curenv;        if (cure &amp;&amp; cure-&gt;env_mfq_left_ticks-- == 1) {            sched_yield();        }        return;#endif    }\n\n系统调用处直接调用time_msec即可：\n// Return the current time.static intsys_time_msec(void){    // LAB 6: Your code here.    // panic(\"sys_time_msec not implemented\");    return time_msec();}\n\nExercise 3在e1000.h和e1000.c中实现一个pci-attach的函数：\nintpci_e1000_attach(struct pci_func *pcif) {    pci_func_enable(pcif);    return 1;}\n\n查询手册得到E1000的VENDOR-ID和DEV-ID：\n#define E1000_VEND     0x8086  // Vendor ID for Intel #define E1000_DEV      0x100E  // Device ID for the e1000 Qemu, Bochs, and VirtualBox emmulated NICs\n\n在pci_attach_vendor中添加：\nstruct pci_driver pci_attach_vendor[] = {    { E1000_VEND, E1000_DEV, &amp;pci_e1000_attach },    { 0, 0, 0 },};\n\nExercise 4在e1000.c中定义一个MMIO指针：\nstatic volatile uint32_t *e1000;\n\n在pci_e1000_attach中初始化MMIO指针：\nintpci_e1000_attach(struct pci_func *pcif) {    pci_func_enable(pcif);    e1000 = mmio_map_region(pcif-&gt;reg_base[0], pcif-&gt;reg_size[0]);    return 1;}\n\nExercise 5根据手册定义传输描述符的结构：\nstruct e1000_tx_desc {    uint64_t addr;    uint16_t length;    uint8_t cso;    uint8_t cmd;    uint8_t status;    uint8_t css;    uint16_t special;};\n\n设置一些基本常量，定义描述符表和传输缓冲区：\n#define E1000_NTXDESC 32#define E1000_MAXPACK 1518__attribute__((__aligned__(sizeof(struct e1000_tx_desc))))static volatile struct e1000_tx_desc tx_descs[E1000_NTXDESC];static volatile uint8_t tx_buf[E1000_NTXDESC][E1000_MAXPACK];\n\n查手册得到一些寄存器的位置，以及一些寄存器（TCTL/TIPG）内部必要字段的位置或偏移，定义并实现tx_init函数：\n\n初始化传输描述符表（主要是设置STA.DD位，相当于标记该缓冲区为空）。\n按手册要求初始化TDBAL（因为是32位系统，不用初始化TDBAH）,TDLEN,TDH,TDT寄存器。\n结合手册和实验要求初始化TCTL,TIPG寄存器。\n\n#define REG_TDBAL    0x03800  /* TX Descriptor Base Address Low - RW */#define REG_TDBAH    0x03804  /* TX Descriptor Base Address High - RW */#define REG_TDLEN    0x03808  /* TX Descriptor Length - RW */#define REG_TDH      0x03810  /* TX Descriptor Head - RW */#define REG_TDT      0x03818  /* TX Descripotr Tail - RW */#define REG_TCTL     0x00400  /* TX Control - RW */#define REG_TIPG     0x00410  /* TX Inter-packet gap -RW */#define TCTL_EN_BIT         (1 &lt;&lt; 1)#define TCTL_PSP_BIT        (1 &lt;&lt; 3)#define TCTL_CT_SHIFT       4#define TCTL_COLD_SHIFT     12#define TIPG_IPGT_SHIFT     0#define TIPG_IPGR1_SHIFT    10#define TIPG_IPGR2_SHIFT    20#define TX_CMD_EOP_BIT     (1 &lt;&lt; 0)#define TX_CMD_IFCS_BIT    (1 &lt;&lt; 1)#define TX_CMD_RS_BIT      (1 &lt;&lt; 3)#define TX_STA_DD_BIT      (1 &lt;&lt; 0)static volatile uint32_t *reg_tdh, *reg_tdt;static void tx_init() {    // tx descs init    for (int i = 0; i &lt; E1000_NTXDESC; ++i) {        tx_descs[i].status |= TX_STA_DD_BIT;    }    // setting TDBAL, TDLEN    e1000[REG_TDBAL &gt;&gt; 2] = (uint32_t)PADDR((void*)tx_descs);    e1000[REG_TDLEN &gt;&gt; 2] = sizeof(tx_descs);    // TDH = TDT = 0    reg_tdh = &amp;e1000[REG_TDH &gt;&gt; 2];    reg_tdt = &amp;e1000[REG_TDT &gt;&gt; 2];    *reg_tdh = 0;    *reg_tdt = 0;    // TCTL setting    e1000[REG_TCTL &gt;&gt; 2] = 0        | TCTL_EN_BIT         | TCTL_PSP_BIT         | (0x10 &lt;&lt; TCTL_CT_SHIFT)         | (0x40 &lt;&lt; TCTL_COLD_SHIFT)        ;    // IPG setting    e1000[REG_TIPG &gt;&gt; 2] = 0        | (10 &lt;&lt; TIPG_IPGT_SHIFT)         | (8 &lt;&lt; TIPG_IPGR1_SHIFT)         | (6 &lt;&lt; TIPG_IPGR2_SHIFT)        ;}\n\n在pci_e1000_attach中添加tx_init：\nintpci_e1000_attach(struct pci_func *pcif) {    pci_func_enable(pcif);    e1000 = mmio_map_region(pcif-&gt;reg_base[0], pcif-&gt;reg_size[0]);    tx_init();    return 1;}\n\nExercise 6添加并实现e1000_transmit函数。按手册要求实现即可。有几点需要注意：\n\n判断一个缓冲区是否空闲不能依靠TDH寄存器，而需要利用描述符中的STA.DD位来判断。发包时也要设置CMD.RS位。\n传输的地址要用物理地址。\n因为我设置单个缓冲区大小足够装下一个以太网包，所以每次发包都要设置CMD.EOP位标记这是包的最后一段。\nCMD.IFCS位用于插入FCS校验码，可以增强链路层的检错能力，本次实验中不设置也没什么关系（反正接收时并不会处理……）。\n\nint e1000_transmit(const char *buf, size_t len) {    assert(len &lt;= E1000_MAXPACK);        uint32_t tmp_reg_tdt = *reg_tdt;    // queue if full    if (!(tx_descs[tmp_reg_tdt].status &amp; TX_STA_DD_BIT))        return -1;    // copy memory    memmove((void*)tx_buf[tmp_reg_tdt], buf, len);    // setting desc    tx_descs[tmp_reg_tdt].cmd = 0         | TX_CMD_RS_BIT         | TX_CMD_EOP_BIT         | TX_CMD_IFCS_BIT        ;    tx_descs[tmp_reg_tdt].status = 0;    tx_descs[tmp_reg_tdt].addr = (uint64_t)PADDR((void*)tx_buf[tmp_reg_tdt]);    tx_descs[tmp_reg_tdt].length = len;    // update TDT    *reg_tdt = (tmp_reg_tdt + 1) % E1000_NTXDESC;    return 0;}\n\nExercise 7设置一个系统调用sys_dl_transmit（数据链路层传输）简单包装e1000_transmit：\nstatic int sys_dl_transmit(const char* buf, size_t len) {    user_mem_assert(curenv, buf, len, PTE_U);    return e1000_transmit(buf, len);    }\n\nExercise 8按要求实现即可，注意只接受来自ns_envid的传输请求：\nvoidoutput(envid_t ns_envid){    binaryname = \"ns_output\";    // LAB 6: Your code here:    // \t- read a packet from the network server    //\t- send the packet to the device driver    int r;    int feid;    while(1) {        if (r = ipc_recv(&amp;feid, &amp;nsipcbuf, NULL), r &lt; 0)            panic(\"in output, ipc_recv: %e\", r);        if (r != NSREQ_OUTPUT || feid != ns_envid)            continue;        while (r = sys_dl_transmit(nsipcbuf.pkt.jp_data, nsipcbuf.pkt.jp_len), r &lt; 0)            /* spinning */;    }}\n\n\nQ: How did you structure your transmit implementation? In particular, what do you do if the transmit ring is full?\nA: 传输缓冲区满的话直接忙等（因为是外部设备，而且是发送消息，一般只会阻塞很短的时间，因此忙等就够了），直到传输成功。\n\nExercise 10根据手册定义接收描述符的结构：\nstruct e1000_rx_desc {    uint64_t addr;    uint16_t length;    uint16_t checksum;    uint8_t status;    uint8_t errors;    uint16_t special;};\n\n设置一些基本常量，定义描述符表和接收缓冲区：\n#define E1000_NRXDESC 128#define QEMU_MAC_ADDR  0x563412005452__attribute__((__aligned__(sizeof(struct e1000_rx_desc))))static volatile struct e1000_rx_desc rx_descs[E1000_NRXDESC];static volatile uint8_t rx_buf[E1000_NRXDESC][E1000_MAXPACK];\n\n查手册得到一些寄存器的位置，以及一些寄存器内部必要字段的位置或偏移，并实现rx_init函数（具体过程不再赘述）：\n#define REG_RAL      0x05400#define REG_RAH      0x05404#define REG_RDBAL    0x02800  /* RX Descriptor Base Address Low - RW */#define REG_RDBAH    0x02804  /* RX Descriptor Base Address High - RW */#define REG_RDLEN    0x02808  /* RX Descriptor Length - RW */#define REG_RDH      0x02810  /* RX Descriptor Head - RW */#define REG_RDT      0x02818  /* RX Descriptor Tail - RW */#define REG_RCTL     0x00100  /* RX Control - RW */#define REG_MTA      0x05200  /* Multicast Table Array - RW Array */#define RAH_AV_BIT              (1 &lt;&lt; 31)#define RCTL_EN_BIT             (1 &lt;&lt; 1)#define RCTL_LBM_SHIFT          6#define RCTL_RDMTS_SHIFT        8#define RCTL_BAM_BIT            (1 &lt;&lt; 15)#define RCTL_BSIZE_SHIFT        16#define RCTL_SECRC_BIT          (1 &lt;&lt; 26)#define RX_STA_DD_BIT      (1 &lt;&lt; 0)#define RX_STA_EOP_BIT     (1 &lt;&lt; 1)static volatile uint32_t *reg_rdh, *reg_rdt;static void rx_init() {    // init rx descs    for (int i = 0; i &lt; E1000_NRXDESC; ++i) {        rx_descs[i].addr = (uint32_t)PADDR((void*)rx_buf[i]);        rx_descs[i].length = E1000_MAXPACK;        rx_descs[i].status = 0;    }    // setting RAH:RAL    e1000[REG_RAL &gt;&gt; 2] = QEMU_MAC_ADDR &amp; 0xFFFFFFFF;    e1000[REG_RAH &gt;&gt; 2] = QEMU_MAC_ADDR &gt;&gt; 32 | RAH_AV_BIT;    // setting MTA: Multicast Table Array    memset((void*)(e1000 + REG_MTA), 0, 128 * sizeof(uint32_t));    // setting RDBAL, RDLEN    e1000[REG_RDBAL &gt;&gt; 2] = (uint32_t)PADDR((void*)rx_descs);    e1000[REG_RDLEN &gt;&gt; 2] = sizeof(rx_descs);    // setting RDH, RHT    reg_rdh = &amp;e1000[REG_RDH &gt;&gt; 2];    reg_rdt = &amp;e1000[REG_RDT &gt;&gt; 2];    *reg_rdh = 0;    *reg_rdt = E1000_NRXDESC - 1;    // setting RCTL    e1000[REG_RCTL &gt;&gt; 2] =　0        | RCTL_EN_BIT        | (0 &lt;&lt; RCTL_LBM_SHIFT)        | (3 &lt;&lt; RCTL_RDMTS_SHIFT)        | RCTL_BAM_BIT        | (0 &lt;&lt; RCTL_BSIZE_SHIFT)        | RCTL_SECRC_BIT        ;}\n\n将rx_init加入pci_e1000_attach中：\nintpci_e1000_attach(struct pci_func *pcif) {    pci_func_enable(pcif);    e1000 = mmio_map_region(pcif-&gt;reg_base[0], pcif-&gt;reg_size[0]);    tx_init();    rx_init();    return 1;}\n\nExercise 11添加并实现e1000_receive函数。注意该实现的缓冲区负载上限为缓冲区大小减一（因为RDT好像不能指向缓冲区外部，但网卡判断缓冲区满的条件又是RDH == RDT。不太懂该怎么完全利用缓冲区……）：\ninte1000_receive(char *buf, size_t len){    uint32_t tmp_reg_rdt = (*reg_rdt + 1) % E1000_NRXDESC;    // queue is empty    if (!(rx_descs[tmp_reg_rdt].status &amp; RX_STA_DD_BIT))        return -1;    // one buffer, one packet    assert(rx_descs[tmp_reg_rdt].status &amp; RX_STA_EOP_BIT);    assert(KADDR(rx_descs[tmp_reg_rdt].addr) == rx_buf[tmp_reg_rdt]);    // memory copy    len = MIN(len, rx_descs[tmp_reg_rdt].length);    memmove(buf, KADDR(rx_descs[tmp_reg_rdt].addr), len);    // set desc    rx_descs[tmp_reg_rdt].status = 0;    rx_descs[tmp_reg_rdt].addr = (uint32_t)PADDR((void*)rx_buf[tmp_reg_rdt]);    rx_descs[tmp_reg_rdt].length = E1000_MAXPACK;    // update register    *reg_rdt = tmp_reg_rdt;    return (int)len;}\n\n实现一个系统调用sys_dl_receive，简单包装一下e1000_receive：\nstatic int sys_dl_receive(char *buf, size_t len) {    user_mem_assert(curenv, buf, len, PTE_U | PTE_W);    return e1000_receive(buf, len);}\n\nExercise 12按要求实现即可。注意每次接收包时都重新分配一个物理页，防止服务请求方来不及读取数据就被覆写了。\nvoidinput(envid_t ns_envid){\tbinaryname = \"ns_input\";\t// LAB 6: Your code here:\t// \t- read a packet from the device driver\t//\t- send it to the network server\t// Hint: When you IPC a page to the network server, it will be\t// reading from it for a while, so don't immediately receive\t// another packet in to the same physical page.\tint r;\twhile(1) {\t\tif (r = sys_page_alloc(0, &amp;nsipcbuf, PTE_P | PTE_U | PTE_W), r &lt; 0)\t\t\tpanic(\"in input, sys_page_alloc: %e\", r);\t\twhile (r = sys_dl_receive(nsipcbuf.pkt.jp_data, PGSIZE - sizeof(int)), r &lt; 0)\t\t\tsys_yield();\t\tnsipcbuf.pkt.jp_len = r;\t\tipc_send(ns_envid, NSREQ_INPUT, &amp;nsipcbuf, PTE_P | PTE_U);\t\tif (r = sys_page_unmap(0, &amp;nsipcbuf), r &lt; 0)\t\t\tpanic(\"in input, sys_page_unmap: %e\", r);\t}}\n\n\nQ: How did you structure your receive implementation? In particular, what do you do if the receive queue is empty and a user environment requests the next incoming packet?\nA: 缓冲区空的时候只是简单地出让CPU，期待下次调度时缓冲区中有数据（这时最好使用轮转调度）。通常情况下这样做足够了，对于一些实时性要求比较高的网络应用来说可能性能上不太好。更好的做法是采用中断来提醒收包。\n\nExercise 13send_file实现比较简单。注意返回前要及时关闭fd。\nstatic intsend_file(struct http_request *req){\tint r;\toff_t file_size = -1;\tint fd;\t// open the requested url for reading\t// if the file does not exist, send a 404 error using send_error\t// if the file is a directory, send a 404 error using send_error\t// set file_size to the size of the file\t// LAB 6: Your code here.\t// panic(\"send_file not implemented\");\tif (fd = open(req-&gt;url, O_RDONLY), fd &lt; 0) {\t\tsend_error(req, 404);\t\treturn fd;\t}\tstruct Stat st;\tif (r = stat(req-&gt;url, &amp;st), r &lt; 0 || st.st_isdir) {\t\tr = send_error(req, 404);\t\tgoto end;\t}\tfile_size = st.st_size;\tif ((r = send_header(req, 200)) &lt; 0)\t\tgoto end;\tif ((r = send_size(req, file_size)) &lt; 0)\t\tgoto end;\tif ((r = send_content_type(req)) &lt; 0)\t\tgoto end;\tif ((r = send_header_fin(req)) &lt; 0)\t\tgoto end;\tr = send_data(req, fd);end:\tclose(fd);\treturn r;}\n\nsend_data实现比较简单。注意向网络写数据时可能需要连续写多次才能将缓冲区数据写完。\nstatic intsend_data(struct http_request *req, int fd){\t// LAB 6: Your code here.\t// panic(\"send_data not implemented\");\tint r;\tint rd, wt, tot;\tchar buf[256];\ttot = 0;\twhile (rd = read(fd, buf, sizeof(buf)), rd &gt; 0) {\t\tfor (wt = 0; wt &lt; rd; ) {\t\t\tif (r = write(req-&gt;sock, buf + wt, rd - wt), r &lt; 0)\t\t\t\treturn r;\t\t\twt += r;\t\t}\t\ttot += rd;\t}\treturn rd &lt; 0 ? rd : tot;}\n\n\nQ: What does the web page served by JOS’s web server say?\nA: This file came from JOS. Cheesy web page!\n\n\nQ: How long approximately did it take you to do this lab?\nA:\n\nThis complete this labtesttime: OK (7.9s) pci attach: OK (0.8s) testoutput [5 packets]: OK (2.0s) testoutput [100 packets]: OK (2.2s) Part A score: 35/35testinput [5 packets]: OK (1.9s) testinput [100 packets]: OK (1.2s) tcp echo server [echosrv]: OK (1.6s) web server [httpd]:   http://localhost:26002/: OK (2.2s)   http://localhost:26002/index.html: OK (0.9s)   http://localhost:26002/random_file.txt: OK (1.7s) Part B score: 70/70Score: 105/105\n\nChallenge: Get MAC Address from EEPROM原理查阅手册可知，可以通过EERD寄存器来访问EEPROM：\n\nSoftware can use the EEPROM Read register (EERD) to cause the Ethernet controller to read a word from the EEPROM that the software can then use. To do this, software writes the address to read the Read Address (EERD.ADDR) field and then simultaneously writes a 1b to the Start Read bit (EERD.START). The Ethernet controller then reads the word from the EEPROM, sets the Read Done bit (EERD.DONE), and puts the data in the Read Data field (EERD.DATA). Software can poll the EEPROM Read register until it sees the EERD.DONE bit set, then use the data from the EERD.DATA field. Any words read this way are not written to hardware’s internal registers.\n\n而MAC地址可以通过访问EEPROM的前三个16位字来获得。\n实现查完手册，实现起来就很简单了：\n#define REG_EERD     0x00014#define EERD_START_BIT      (1 &lt;&lt; 0)#define EERD_DONE_BIT       (1 &lt;&lt; 4)#define EERD_ADDR_SHIFT     8#define EERD_DATA_SHIFT     16uint64_te1000_read_mac_addr(void){    uint32_t eerd = 0;    uint16_t data = 0;    uint64_t mac_addr = 0;    for (int i = 0; i &lt; 3; ++i) {        e1000[REG_EERD &gt;&gt; 2] = 0            | (i &lt;&lt; EERD_ADDR_SHIFT)            | EERD_START_BIT            ;        while(eerd = e1000[REG_EERD &gt;&gt; 2], !(eerd &amp; EERD_DONE_BIT))            /* waiting */;        data = eerd &gt;&gt; EERD_DATA_SHIFT;        mac_addr |= (uint64_t)data &lt;&lt; (i * 16);    }    return mac_addr;}\n\n初始化RAH:RAL时可以直接用上：\n// setting RAH:RALuint64_t mac_addr = e1000_read_mac_addr();e1000[REG_RAL &gt;&gt; 2] = mac_addr &amp; 0xFFFFFFFF;e1000[REG_RAH &gt;&gt; 2] = (mac_addr &gt;&gt; 32) | RAH_AV_BIT;\n\n添加系统调用sys_dl_read_mac_addr简单包装：\nstatic int sys_dl_read_mac_addr(uint8_t *mac){    user_mem_assert(curenv, mac, 6, PTE_U | PTE_W);    uint64_t mac_addr = e1000_read_mac_addr();    for (int i = 0; i &lt; 6; ++i)        mac[i] = (uint8_t)(mac_addr &gt;&gt; (8 * i));    return 0;}\n\n修改/net/lwip/jos/jif/jif.c中的low_level_init函数：\nstatic voidlow_level_init(struct netif *netif){    int r;    netif-&gt;hwaddr_len = 6;    netif-&gt;mtu = 1500;    netif-&gt;flags = NETIF_FLAG_BROADCAST;    sys_dl_read_mac_addr(netif-&gt;hwaddr);    // MAC address is hardcoded to eliminate a system call    // netif-&gt;hwaddr[0] = 0x52;    // netif-&gt;hwaddr[1] = 0x54;    // netif-&gt;hwaddr[2] = 0x00;    // netif-&gt;hwaddr[3] = 0x12;    // netif-&gt;hwaddr[4] = 0x34;    // netif-&gt;hwaddr[5] = 0x56;}","tags":["OS"]},{"title":"Mirage A Multi-Level Superoptimizer for Tensor Programs 简记","url":"/2024/10/17/Mirage%20A%20Multi-Level%20Superoptimizer%20for%20Tensor%20Programs%20%E7%AE%80%E8%AE%B0/","content":"\n论文: https://arxiv.org/abs/2405.05751 \n代码: https://github.com/mirage-project/mirage\n\nMirage 是 CMU 贾志豪组搞的一个 ML Compiler，输入是一个计算图子图（子图中的算子来自一个预定义的算子集合），输出是优化后的 cuda 程序，所作的优化在效果上等价于一系列优化的结合，包括但不限于图变换 (graph rewrite) 和算子融合 (operator fusion)。\nMirage 和之前的算子级别或图级别的 ML Compiler 的不同之处在于，之前的 ML Compiler 的优化方法大多是 deductive program synthesis (一般称为 term rewrite)，也就是 graph rewrite、loop rewrite/schedule 之类的方法，从原程序出发，通过一系列等价变换 (rewrite-rules, schedule-primitives, …)，得到新的程序；而 Mirage 用的是 inductive program synthesis (一般称为 program synthesis……)，根据语法 (算子集合) 直接去构造程序，通过一些方法 (通常是 SMT Solver) 来验证所构造的程序和原程序的等价性。ASPLOS’22 的 Rake (paper, code) 和 ASPLOS’24 的 Hydride (paper, code) 也用了 program synthesis 的方法来优化向量化的 Halide 程序在 x86 CPU, ARM CPU 和 Hexagon DSP/NPU 上的性能。\nMu-GraphMirage 的核心是一个 multi-level 的计算图表示，称为 mu-graph。mu-graph 包含三个层级，kernel-graph、block-graph 和 thread-graph，分别对应 cuda 程序执行的三个层级。\n\nkernel-graph 的张量位于全局内存，算子包含两种，一种是预定义算子 (pre-defined operator)，另一种是合成算子 (graph-defined operator)。其中预定义算子会直接对应 vendor-library 的 kernel，例如 matmul 对应 cublas 里的 gemm，而合成算子则会包含一个 block-graph。\nblock-graph 的张量位于共享内存，算子包含预定义算子和合成算子。其中预定算子会对应 CUTLASS 或者 ThunderKittens 等 CUDA 组件库中封装好的共享内存上的一些操作（例如矩阵乘等），而合成算子会包含一个 thread-graph。block-graph 主要包含下面的属性来表示程序并行切分的信息：\nimap: grid-dims/spatial-dims 到 input tensor dims 的映射。\nomap: grid-dims/spatial-dims 到 output tensor dims 的映射。\nfmap: for-loop-dims/temporal-dims 到 input iterator dims / output accumulator dims 的映射。\n\n\nthread-graph 的张量位于寄存器，算子只包含预定义算子，对应封装好的寄存器上的一些操作。下图展示了原程序为 GQA 计算所得到的一个 mu-graph：\n\nSynthesisprogram synthesis 的主要流程如下图所示：Mirage 在 synthesis 过程中，维护一个 prefix kernel-graph（有算子数量限制），每次枚举一个算子加入(枚举 matmul, exp, add, …, 合成算子)，枚举到了合成算子，会递归进行 block-graph 的 synthesis (会枚举不同的 grid-dims 和 for-loop-dims)，以此类推。Mirage 会将 mu-graph 转换为 canonical form 来过滤重复的 mu-graph。\nPruning &amp; Verificationprogram synthesis 的问题主要在于速度比较慢，慢的原因主要有两点，一是枚举过程中有些前缀程序可能之后永远都无法扩展到和原程序等价，搜索这些就是浪费时间，二是最终验证合成的程序和原程序的等价性一般需要用到 SMT Solver，这个太慢了，特别是针对规模较大的 tensor program。针对此，Mirage 也提出了两个优化，一个是基于 abstract expression 的剪枝，一个是基于 finite field random test 的等价性验证。\nMirage 会将搜索过程中的 prefix graph 的算子的表达式简化为 abstract expression，主要是简化了 matmul 和 reduction 等计算的表示：借助公理集合  和 ，使用 SMT 检查当前的 prefix graph 的 abstraction expression 和目标程序的 abstract-expression 的某个 sub-expression 是否等价，将不满足的裁剪掉：。\n为了验证合成的 mu-graph 和原 mu-graph 的等价性，Mirage 在 finite filed  上随机采样输入进行测试，在通过的测试样例数量达到一定程度时，可以在理论上保证两者不等价的概率足够小。具体细节还是看论文吧……\n至于根据 mu-graph 生成实际的 cuda 程序，Mirage 也做了不少的优化，在文档里有详细的描述，之后可能会再写个博客分析一下。\nDisscussion我个人还是挺喜欢 Mirage 这个工作的，它通过 inductive program synthesis 巧妙地将 kernel-level 和 block-level (以及 thread-level) 的优化空间进行了融合统一，效果也确实挺不错的（我之前其实也有考虑将这几个层级进行统一优化，不过一直拘泥于 deductive synthesis 的思路，很难搞出实际可用的解决方案）。不过 Mirage 还是有几个个人感觉比较局限或者说需要改进的点：\n\n优化时间：论文的 Section 7.4 有提到，在 block-graph 的算子数量达到 7 的时候（这个是搜索出论文 Figure 4 的优化后的 GQA 的必要数量），搜索时间基本就要破一个小时了（当然这个在一众 Tuning-based ML Compiler 里其实算比较快的了……）。\n对动态形状的支持：目前 Mirage 应该是只支持静态形状输入，个人希望搜索出的 mu-graph 可以直接扩展到支持动态形状输入（保持 block-graph 的 shape 不变）。\n支持的程序：目前 Mirage 的 finite field random test 要求的 mu-graph 一条路径上至多只有一个 exp，不然难以推导出论文中的 Theorem 3.\n算子扩展：目前 Mirage 支持的算子类型比较有限（连 max 都没有，所以 Mirage 写的 Attention 都是没有使用 numerical stable softmax 的版本，基本不会在生产环境中使用），而且扩展起来挺麻烦的，添加一个新算子需要实现其对应的 abstraction expression（可能还需要添加新的公理到  和  中）以及在 finite field 上的操作，基本上只能由开发者进行扩展（而且有些算子还真不一定好加进来，比如 max ……）。我觉得这个是最大的问题。\n\n","tags":["CUDA","ML-Compiler","Programming-Language","Program-Synthesis"]},{"title":"Stable-Diffusion + ControlNet 的 UNet 网络结构剖析","url":"/2023/09/28/Stable-Diffusion%20+%20ControlNet%20%E7%9A%84%20UNet%20%E7%BD%91%E7%BB%9C%E7%BB%93%E6%9E%84%E5%89%96%E6%9E%90/","content":"上图是 Stable-Diffusion (简称 SD) + 单个 ControlNet (简称 CN) 的 UNet 部分的整体结构 （SD1.5 或者 SD2.0 的结构，SDXL 的阶段数和各阶段层数会有些不同，不过大致上差不多）。其中 “$” 代表沿着 channel 维的 concat 操作。\n假设用户指定生成一个 H x W 的图片，则 SD-UNet 的输入和输出一般是 H/8 x W/8 的 latent image。经过多轮 UNet 推理采样后，输出的 latent image 会经过一个 VAE Decoder 来生成最终的 H x W 大小的图片。如果是图生图，则用户输入的 H x W 的 image 会先经过一个 CLIP Encoder 来编码为 H/8 x W/8 的 latent image。\n图中 DownSample, UpSample, Conv3x3(stride=2), Interpolate 方框内的 h1,w1-&gt;h2,w2 表示输入到输出的 image-size 的变化，部分 ResBlock, Conv3x3 方框内的 c1-&gt;c2 表示输入到输出的 channel-size 的变化。\nSD-UNet 中第一个 Conv3x3 会将输入的 channel-size 由 4 升为 320，之后的下采样阶段会进行三次 DownSample，上采样阶段会进行三次 UpSample。每个 DownSample 会将 image height/width 减半，随后会跟着一个 ResBlock 来将 channel-size 加倍（除了第三个 DownSample 后的 ResBlock）；UpSample 会将 image height/width 加倍，随后会跟着一个 ResBlock 来将 channel-size 减半（除了第一个 UpSample 后的 ResBlock）。\n下采样阶段的每个 SpatialTransformer (SpTxformer) 和 DownSample 的输出会驻留在内存，和之后上采样阶段对应层级的 SpatialTransformer 或者 UpSample 的输出 concat 在一起，作为之后的 ResBlock 的输入，表现为图中的 12 个 skip-connection。\nSD + n 个 CN 相当于把 SD 下采样阶段的网络复制 n 份（当然 SD 和各个 CN 的权重是不同的，输入的 latent-image 也不同），将 SD 和各个 CN 下采样阶段的同一层级的 SpatialTransformer 或 DownSample 的输出相加之后驻留在内存，之后和上采样阶段对应的 SpatialTransformer/UpSample 的输出 concat 在一起作为之后 ResBlock 的输出。\nSD-UNet 中比较重要的两个模块是 ResBlock 和 SpatialTransformer。ResBlock 除了接收 latent-image 外，还会接收 time-step embedding 作为输入，两者通过 Conv3x3/Linear 映射后相加，再过一个 Conv3x3 和 residual addition，随后输出。\n\nSpatialTransformer 接收 latent-image 和 context embedding（也就是用户输入的 prompt 编码后的 embedding）。SpatialTransformer 主要由 Self-Attention, Cross-Attention 和 Feed-Forward-Network / MLP 这三部分组成，其中 Cross-Attention 用于融合 latent-image 和 context/prompt。\n\n","tags":["Machine-Learning","Diffusion"]},{"title":"Stream-K 和 Lean-Attention","url":"/2024/08/24/Stream-K%20%E5%92%8C%20Lean-Attention/","content":"这两天看了一下 Stream-K 和 Lean-Attention，简单总结一下。\nStream-KStream-K 是英伟达提出的一个 HPC 算法，主要是为了解决 GPU 上优化 GEMM 所使用的传统的 Data-Parallel 以及 Split-K 算法所面对的 SM 利用率不稳定的问题。当然这个算法也可以用于优化其他的同时存在 spatial-loop 以及 reduce-loop 的算子。上图展示了这几个算法之间的直观思路。对于 GEMM 来说的话，每行代表一个 MN-tile (output-tile) 的计算，每行的每个白色方格代表一个 MNK-tile， 符号代表 MNK-tile 计算结果之间的累加归约操作。\n(a) 表示的是传统的 Data-Parallel 算法，只沿着不存在数据依赖的 MN 维度进行并行化，将各个 MN-tile 顺次分配给 GPU 上的 SM 进行计算，所有 SM 每计算一个 MN-tile 的过程被称为一个 Wave，不难看出在 Wave-1 的时候，SM-1、SM-2、SM-3 是完全闲置的，计算资源被浪费了，整个 GEMM 计算过程的 SM 利用率(Util)只有 62.5%。\n(b) 表示的是在 (a) 的基础上加上 Split-K 算法，也就是在先对 MN 维度进行并行切分的基础上，再对 K 维度也进行并行。因为 MNK-tile 之间的累加操作(不考虑浮点误差的话)是满足结合律的，所以可以进行并行归约。和 (a) 相比，其 SM 利用率提高到了 83.3%。不过代价是计算同一个 MN-tile 的不同 SM 之间需要进行同步来累加各自计算的部分和(partial sum)，并且同步归约的次数和整个 MNK 的规模成正比。\n(c) 表示的是 Stream-K 算法，该算法将直接将 MNK 三个维度融合了之后统一考虑并行切分，将各个 MNK-tile 均分给各个 SM。该算法达到了 93.75% 的 SM 利用率，并且和 Split-K 相比，其同步归约的次数也更少，理论上不超过 GPU 的 SM 个数。\n利用率分析定量分析一下各个算法的 SM 利用率。假设各个 spatial-loop 经过切分后总的 tile 个数为 ，各个 reduce-loop 经过切分后总的 tile 个数为 ，SM 的总个数为 。\n先定义一个辅助函数：\n\n则 Data-Parallel 的 SM 利用率为：\n\nData-Parallel + Split-K 的利用率为（假设 Split-K 的切分个数为 ，）：\n\nStream-K 的利用率为：\n\n 的图像大概长这样：当  的时候，，也就是当 、、 大于 9 的时候上述三个算法的 SM 利用率分别可以稳定大于 90%。\n不难看出当  时 Split-K 和 Stream-K 的 SM 利用率相同，不过同步开销还是不一样的。Split-K 的同步归约次数为 ，而 Stream-K 的同步归约次数至多为 。\nLean-Attention前文说过，Split-K 和 Stream-K 对于其他的同时存在 spatial-loop 和 reduce-loop 的算子来说也是适用的，比如 Flash-Attention-2。Flash-Decoding 就是 Split-K 在 Flash-Attention-2 上的应用，而最近挂在 arxiv 上的 Lean-Attention 则是 Stream-K 在 Flash-Attention-2 上的应用。Lean-Attention 原理较为简单，和 Flash-Decoding 一样利用了 online-softmax 满足结合律的特性，只是把优化用的 Split-K 换成了 Stream-K。\n","tags":["HPC","CUDA","ML-Compiler"]},{"title":"Y-combinator in Racket supporting variant arguments","url":"/2020/02/05/Y-combinator%20in%20Racket%20supporting%20variant%20arguments/","content":"Y-combinator:\n(define Y  (lambda (g)    (let ((d (lambda (f)               (lambda args                 (apply (g (f f)) args)))))      (d d))))\n\nAn example:\n(let ((fact (Y (lambda (fact)                 (lambda (n)                   (if (zero? n)                       1                       (* n (fact (- n 1)))))))))  (fact 10))\n\nAnother example:\n(let ((gcd (Y (lambda (gcd)                (lambda (a b)                  (if (zero? b)                      a                      (gcd b (remainder a b))))))))  (gcd 12 8))","tags":["Programming-Language","Lisp"]},{"title":"Y组合子（不动点组合子）的简单推导","url":"/2020/02/17/Y%E7%BB%84%E5%90%88%E5%AD%90%EF%BC%88%E4%B8%8D%E5%8A%A8%E7%82%B9%E7%BB%84%E5%90%88%E5%AD%90%EF%BC%89%E7%9A%84%E7%AE%80%E5%8D%95%E6%8E%A8%E5%AF%BC/","content":"对于一个函数  （其中  中可能含有对  的引用）\n设  ，则对于之前定义的  ，应该有  （或者写成  ），也就是说  是  的不动点。\n不动点组合子可以写成  （ 其中 表示满足方程  的  ），也就是输入一个函数  ，返回满足方程  的  。\n而 可以写成lambda演算的形式：  （其中  表示将中所有  的自由出现替换为  ）。\n因此不动点组合子可以写成 。\n注意该写法适用于call-by-name，而不适用于call-by-value。通常call-by-value将一般的  形式的方程转换成lambda演算时需要添加其他的原语（比如unfold）来延迟对  的代换。不过因为不动点组合子一般只用于函数，因此可以通过函数封装来延迟代换，也就是可以写成：  ，或者：  。\n在scheme中，Y组合子可以写成：\n(define Y  (lambda (g)    (let ((d (lambda (f)               (lambda args                 (apply (g (f f)) args)))))      (d d))))\n注意scheme中的函数一般是非柯里化的，所以用apply来处理变长参数。\n","tags":["Programming-Language","Lisp"]},{"title":"为什么没有自动生成任意算子fusion kernel的工作？（回答）","url":"/2024/09/11/%E4%B8%BA%E4%BB%80%E4%B9%88%E6%B2%A1%E6%9C%89%E8%87%AA%E5%8A%A8%E7%94%9F%E6%88%90%E4%BB%BB%E6%84%8F%E7%AE%97%E5%AD%90fusion%20kernel%E7%9A%84%E5%B7%A5%E4%BD%9C%EF%BC%9F%EF%BC%88%E5%9B%9E%E7%AD%94%EF%BC%89/","content":"其实挺多相关工作的。fusion 这个东西扯起来历史还是挺久远的，本身也算编译器领域的一个经典课题，从上世纪开始就有不少 loop fusion 相关的研究，特别是在 polyhedral model 基础之上进行的 loop fusion，离现在比较近的工作有 PPoPP’14 的 Revisiting loop fusion in the polyhedral framework ，赵捷大佬的一个有关 polyhedral 的知乎回答也有 loop fusion 相关的内容。loop fusion 的收益来源主要就是减少中间数据的搬移，kernel fusion 在此基础上还减少了一些 kernel launch 的开销（不过实际场景中减少 kernel launch 带来的收益很多时候可以忽略）。\nfusion 在学术界的发展基本上可以分为 4 个阶段（阶段之间一般有所重叠，没有明确的界限）。第一阶段，loop fusion 作为编译器后端 loop 优化相关的研究的一部分得到初步发展。第二阶段，image processing pipeline 中各种连续的 stencil 操作带来了新的 fusion 空间，因为 stencil 操作引入了滑窗依赖，因此如何进行任务划分来平衡 访存、通信/同步、重复计算 等要素是挺值得研究的，PolyMage 和 Halide 算是这个阶段的一部分代表性工作，甚至还有做六边形 tiling 的工作 。\n\n第三阶段，就是深度学习加速器和编译器兴起的阶段，那时候有不少加速器设计相关的工作关注 CNN 相邻层的 fusion（和前文说的 stencil pipeline 一样因为有滑窗依赖所以有不少可以研究的点），比如 MICRO’16 的 Fused-Layer ，还有我们组师兄的 DAC’17 的一篇工作 ，近几年也有 HPCA’23 的 DeFiNES 和 ISOSceles 这样的工作。在深度学习编译器这边，做的主要是整个计算图范围内的访存密集型算子之间的自动融合，典型的工作如 DNNFusion、AStitch 、Apollo 。\n第四阶段，主要就是 transformer 架构逐渐流行的时候，multi-head attention 计算在形状上的特殊性，导致其中的两个矩阵乘在实质上成为了访存密集型算子，有着超大的融合优化收益。MLSys’22 的 BOLT、思泽师兄的 HPCA’23 的 Chimera 都对相邻矩阵乘的融合优化做了探索，不过要说这方面最出名的工作还当属 22 年的 Flash-Attention 和 23 年的 Flash-Attention-2（其实 BOLT 和 Chimera 之类的工作在切分调度上和 FA-2 是一样的，只是没发掘 online-softmax 的用法，因此不能直接用在生产环境中的 attention 上）。然后题主所说的整图范围内的任意算子的 kernel fusion，个人感觉比较接近的是 OSDI’23 的 Welder（今年 OSDI 的 @LeiWang1999 的 Ladder 也可以算）还有今年 ASPLOS 的几篇工作：Souffle、Korch、PyTorch-2。特别是 PyTorch-2，应该算是目前图层面融合优化做得最好的工业级 ML Compiler，虽然它好像不会做连续矩阵的融合。不过连续矩阵乘的融合收益还是要看具体场景，虽然能减少中间矩阵的搬移，但也会影响并行度以及对旁侧矩阵的复用，最好是中间矩阵足够大、旁侧矩阵足够小才有比较好的收益，主流场景中好像基本只有各类 attention、cnn 的前几层、一些小型 mlp 比较符合这个要求，针对此类少数情况一般手写个算子就差不多得了，特别是现在用 triton 写还很方便……\n还有一类 kernel fusion 被称为 horizontal fusion，将不存在依赖任务同时运行在一个 kernel 内增加资源利用率，典型的工作如 CGO’20 的 HFuse ，OSDI’20 的 Rammer ，MLSys’21 的 IOS ，最近的 UW 的 Baris Kasikci 组开源的 NanoFlow 也用到了类似的技术，其创新点在于将大模型的推理沿 batch 切开，将不同 request 的推理错开，人为制造适合进行 horizontal fusion 的异构 task。\n","tags":["ML-Compiler"]},{"title":"作死向：修改TVM的底层数据结构","url":"/2020/06/28/%E4%BD%9C%E6%AD%BB%E5%90%91%EF%BC%9A%E4%BF%AE%E6%94%B9TVM%E7%9A%84%E5%BA%95%E5%B1%82%E6%95%B0%E6%8D%AE%E7%BB%93%E6%9E%84/","content":"前言最近给某个新设备写TVM后端时，出于一些原因需要修改TVM底层的DLDataType的lanes的类型，将其从uint16_t改为int32_t（或者uint32_t），以支持较大长度的vectorization schedule。刚开始以为很简单，但改着改着发现很多地方都以一种非引用的方式牵涉到DLDataType，没改全的话运行时会出现莫名其妙的错误，结果这样不断调试不断修改，花了一天多时间才搞定。为纪念吾辈之努力（全部木大じゃない），谨以此文记录之。\n作死过程简单的修改首先把3rdparty/dlpack/include/dlpack/dlpack.h的DLDataType::lanes改为int32_t（顺便把code和bits也都改成uint16_t，这样可以构成一个64-bits的packed-struct，方便跨域的传输）。\ntypedef struct {  /*!   * \\brief Type code of base types.   * We keep it uint8_t instead of DLDataTypeCode for minimal memory   * footprint, but the value should be one of DLDataTypeCode enum values.   * */  uint16_t code; // MARK  /*!   * \\brief Number of bits, common choices are 8, 16, 32.   */  uint16_t bits; // MARK  /*! \\brief Number of lanes in the type, used for vector types. */  int32_t lanes; // MARK} DLDataType;\n\n然后编译一下，有几个涉及类型转换地方的会报错，修改之：\n\ninclude/tvm/runtime/data_type.h:75:\n  DataType(int code, int bits, int lanes) {    data_.code = static_cast&lt;uint16_t&gt;(code); // MARK    data_.bits = static_cast&lt;uint16_t&gt;(bits); // MARK    data_.lanes = static_cast&lt;int32_t&gt;(lanes); // MARK    if (code == kBFloat) {        CHECK_EQ(bits, 16);    }}\n\ninclude/tvm/runtime/serializer.h:41,46:\n  inline static void Write(Stream* strm, const DLDataType&amp; dtype) {  Handler&lt;uint16_t&gt;::Write(strm, dtype.code); // MARK  Handler&lt;uint16_t&gt;::Write(strm, dtype.bits); // MARK  Handler&lt;int32_t&gt;::Write(strm, dtype.lanes); // MARK}inline static bool Read(Stream* strm, DLDataType* dtype) {    if (!Handler&lt;uint16_t&gt;::Read(strm, &amp;(dtype-&gt;code))) return false; // MARK    if (!Handler&lt;uint16_t&gt;::Read(strm, &amp;(dtype-&gt;bits))) return false; // MARK    if (!Handler&lt;int32_t&gt;::Read(strm, &amp;(dtype-&gt;lanes))) return false; // MARK    return true;}\n\nCython相关之后编译就没问题了，但是运行时会出问题，原因在于python和C++的交互部分（主要是Cython代码）。在python部分用grep搜索一下DLDataType和DataType，发现以下几处需要修改的部分：\n\npython/tvm/_ffi/_cython/base.pxi:47:\n  ctypedef struct DLDataType:    uint16_t code # MARK    uint16_t bits # MARK    int32_t lanes # MARK\n\npython/tvm/_ffi/runtime_ctypes.py:64:\n  _fields_ = [(\"type_code\", ctypes.c_uint16), # MARK            (\"bits\", ctypes.c_uint16), # MARK            (\"lanes\", ctypes.c_int32)] # MARK\n\nLLVM生成的Host端代码之后可以正常地进行代码生成了（tvm.build），但一旦部署运行就会出问题，比如运行下面的代码：\nA = te.placeholder((101,), dtype=\"float32\", name=\"A\")B = te.compute((101,), lambda i: A[i] + 1, name=\"B\")s = te.create_schedule([B.op])fun = tvm.build(s, [A, B])ctx = tvm.cpu(0)a_np = np.random.uniform(size=(101,)).astype(A.dtype)a = tvm.nd.array(a_np, ctx)b = tvm.nd.array(np.zeros((101,), dtype=B.dtype), ctx)fun(a, b)\n\n会报错：\nTVMError: Check failed: ret == 0 (-1 vs. 0) : Assert fail: (((tvm_struct_get(arg0, 0, 5) == (uint8)2) &amp;&amp; (tvm_struct_get(arg0, 0, 6) == (uint8)32)) &amp;&amp; (tvm_struct_get(arg0, 0, 7) == (uint16)1)), arg0.dtype is expected to be float32\n\n尴尬的是从traceback上来看该错误是一个Foreign-Function-Call造成的，仅靠调试很难进行溯源。\n用grep搜索dtype is expected to be，发现了错误的可能来源：src/tir/transforms/arg_binder.cc:170，修改之：\ntype_err_msg &lt;&lt; arg_name &lt;&lt; \".dtype is expected to be \" &lt;&lt; dtype;PrimExpr cond = (TVMArrayGet(DataType::UInt(16), handle, intrinsic::kArrTypeCode) ==                     IntImm(DataType::UInt(16), dtype.code()) &amp;&amp; // MARK                 TVMArrayGet(DataType::UInt(16), handle, intrinsic::kArrTypeBits) ==                     IntImm(DataType::UInt(16), dtype.bits()) &amp;&amp; // MARK                 TVMArrayGet(DataType::Int(32), handle, intrinsic::kArrTypeLanes) ==                     IntImm(DataType::Int(32), dtype.lanes())); // MARK\n\n但是这样修改一下，甚至连tvm.build都运行不了了，在LLVM/CPU代码生成（Host端代码生成）时会出问题。这里困惑了我很久，之后我把arg_binder.cc的修改取消后，查看了一下生成的LLVM IR才发现问题：\n; ModuleID = 'TVMMod'source_filename = \"TVMMod\"target datalayout = \"e-m:e-i64:64-f80:128-n8:16:32:64-S128\"target triple = \"x86_64-pc-linux-gnu\"%0 = type { i8*, %1, i32, %2, i64*, i64*, i64 }%1 = type { i32, i32 }%2 = type { i8, i8, i16 } # MARK\n\n原来TVM生成Host端代码时还会自己再构造一遍DLTensor、DLContext、DLDataType等底层结构（对应代码的%0、%1、%2）。\n这样一来就很好找了，直接用grep搜索StructType::create，很快就发现了错误来源：src/target/llvm/codegen_cpu.c:47，修改之：\n// TVM runtime typest_tvm_shape_index_ = llvm::Type::getIntNTy(*ctx, DataType::ShapeIndex().bits());t_tvm_context_ = llvm::StructType::create({t_int_, t_int_});t_tvm_type_ = llvm::StructType::create({t_int16_, t_int16_, t_int32_}); // MARKt_tvm_func_handle_ = t_void_p_;t_tvm_array_ = llvm::StructType::create({t_void_p_, t_tvm_context_, t_int_, t_tvm_type_,                                         t_tvm_shape_index_-&gt;getPointerTo(),                                         t_tvm_shape_index_-&gt;getPointerTo(), t_int64_});t_tvm_value_ = llvm::StructType::create({t_float64_});t_tvm_parallel_group_env_ = llvm::StructType::create({t_int32_-&gt;getPointerTo(), t_int32_});ftype_tvm_parallel_lambda_ = llvm::FunctionType::get(    t_int_, {t_int_, t_tvm_parallel_group_env_-&gt;getPointerTo(), t_void_p_}, false);md_tbaa_ctx_ptr_ = md_builder_-&gt;createTBAAScalarTypeNode(\"ctx_ptr\", md_tbaa_root_);\n\n改完之后就可以正常进行代码生成以及运行了。\nRPC数据传输过了一段时间，用autotvm的时候又出了问题，根据报错信息溯源，问题似乎出在tvm的RPC模块，想必是跟DLDataType的数据读写有关。在RPC部分（src/runtime/rpc/）搜索DLDataType和kTVMDataType，很快就发现了问题源头，在src/runtime/rpc/rpc_protocol:225,344：\ncase kTVMDataType: {    channel-&gt;Write(value.v_type);    // padding    int32_t padding = 0;    channel-&gt;template Write&lt;int32_t&gt;(padding); // MARK    break;}\n\ncase kTVMDataType: {    channel-&gt;Read(&amp;(value.v_type));    int32_t padding = 0;    channel-&gt;template Read&lt;int32_t&gt;(&amp;padding); // MARK    break;}\n\n这里tvm传输TVMValue需要凑齐8字节，而它“知道”DLDataType的大小为4字节（又是一处擅自假设DLDataType的结构与大小的代码），所以再额外读/写了4字节的padding。这里我们直接吧padding部分删掉就行了（因为之前把DLDataType改成了一个8字节的packed-struct）。\n总结修改DLDataType的lanes的类型至少需要修改以下几处：\n\n3rdparty/dlpack/include/dlpack/dlpack.h:106\ninclude/tvm/runtime/data_type.h:75\ninclude/tvm/runtime/serializer.h:41,46\npython/tvm/_ffi/_cython/base.pxi:47\npython/tvm/_ffi/runtime_ctypes.py:64\nsrc/tir/transforms/arg_binder.cc:170\n以下几处也可以酌情修改：\nsrc/runtime/stackvm/stackvm.cc:532\nsrc/tir/transforms/lower_tvm_builtin.cc:194\n\n\n\n\nsrc/target/llvm/codegen_cpu.c:47\nsrc/runtime/rpc/rpc_protocol:225,344\n\n修改其他的底层类型所涉及到的地方也与之类似。\n不得不说这应该算TVM设计不合理的地方（或者说设计时根本就没考虑到修改底层类型这种事）。个人认为，除了DLDataType定义的地方（以及python和cython部分的代码），其他地方应该直接引用DLDataType进行编码（比如利用decltype来获取field的类型，据此进行派发）。\n","tags":["ML-Compiler","TVM"]},{"title":"在TVM中添加新设备Codegen","url":"/2020/02/20/%E5%9C%A8TVM%E4%B8%AD%E6%B7%BB%E5%8A%A0%E6%96%B0%E8%AE%BE%E5%A4%87Codegen/","content":"前言最近想试着往TVM(v0.7)中加入针对某一新的底层设备的Codegen，本以为是个比较容易的事，但源代码看着看着发现TVM中Codegen和其他部分的耦合比预想中的更紧，故写下这篇短文记录一下添加新的Codegen需要涉及的部分。\nCodegen所针对的IR可以针对两种IR进行Codegen：\n\nRelay IR（之后简写为Relay）\nTensor Level IR（之后简写为TIR）\n\n后者TIR是Relay出现之前TVM使用的IR，相对更加底层（在PL特性的丰富性上）。placeholder等Tensor Expression（之后简写为TE）在C++端都是被转化为TIR（如TE的OperationNode继承自TIR的FunctionBaseNode）。\n在Relay出现之前，各种后端的Codegen都是针对TIR进行的。Relay出现之后，可能出于复用性等方面的考虑，Relay的通常的Codegen都是先转化为TIR再进行的，如tvm.relay.build_module.build的调用路径为：\n\ntvm.relay.build_module.build　in python/tvm/relay/build_module.py\ntvm.relay.build_module.BuildModule.build in …\ntvm::relay::backend::RelayBuildModule::Build in src/relay/backend/build_module.cc\ntvm::relay::backend::RelayBuildModule::BuildRelay in …\ntvm::build in src/driver/driver_api.cc\ntvm::build（前一个build的重载）　in …\ntvm::codegen::Build in src/target/codegen.cc，在这里会用tvm::runtime::Registry::Get根据传入的target参数动态派发给具体函数，如target为\"cuda\"时会派发给注册为codegen.build_cuda的tvm::codegen::BuildCUDA(in src/target/opt/build_cuda_on.cc)。\n\n本文主要介绍针对TIR生成代码所涉及的部分。关于针对Relay做Codegen可以参考官方文档（虽然有点简略）。\n接下来将以一个非常简单（代码量不足70行）的后端模块”hello”的构造来展示针对TIR的代码生成。该模块的使用如下：\nimport tvmA = tvm.placeholder((10, 10))B = tvm.compute((10, 10), lambda i, j: A[i, j])s = tvm.create_schedule(B.op)f = tvm.build(s, [A, B], \"hello\")print(f.get_source())\n\n输出：\n// hello tvm backend!void default_function( void* args,  void* arg_type_ids, int32_t num_args,  void* out_ret_value,  void* out_ret_tcode) {  // ......  float* placeholder = (float*)(((DLTensor*)arg0)[0].data);  // ......  float* compute = (float*)(((DLTensor*)arg1)[0].data);  // ......  for (int32_t i = 0; i &lt; 10; ++i) {    for (int32_t j = 0; j &lt; 10; ++j) {      compute[((i * 10) + j)] = placeholder[((i * 10) + j)];    }  }}\n\n新建模块文件新增的模块的python代码一般写在python/tvm/contrib/，C++代码一般写在src/runtime/contrib/。我们这里在src/runtime/contrib/下添加文件夹hello/，hello/内添加hello_module.cc。\n因为作为示例的hello模块非常简单，因此只用单文件就够了。一般来讲要视情况组织为多个编译单元，具体可参见src/runtime/contrib/中其他模块的组织方式。\nhello模块直接利用tvm.build等前端接口进行构建，如果还需要处理一些前端逻辑或是提供其他的前端接口，则可在python/tvm/contrib/中添加对应的文件。\n实现后端模块tvm.build和tvm.build_module.build返回的都是tvm::runtime::Module，而tvm::runtime::Module是tvm::runtime::ModuleNode的运行时引用，因此我们需要先新定义一个ModuleNode的子类。\nModuleNode有以下虚方法：\n\ntype_key：返回标识该模块的字符串，例如CUDAModuleNode的type_key返回\"cuda\"。\nGetFunction：返回用于运行该模块的PackedFunc（关于PackedFunc的介绍参见官方文档），例如CUDAModuleNode的GetFunction返回的PackedFunc利用CUDA Runtime API来加载运行保存在CUDAModuleNode中的PTX代码。\nSaveToFile：将模块保存进文件。\nSaveToBinary：将模块输出到二进制流。\nGetSource：返回模块保存的源代码，例如CUDAModuleNode的GetSource返回其保存的CUDA C代码。\n\n其中type_key和GetFunction为纯虚函数，每个ModuleNode的非抽象子类必须实现，否则实例化处会出现编译期错误。而另外三个虚方法如果子类没有覆写，则在被调用时会抛出运行时错误。\n以hello模块的HelloModuleNode为例，该类实现了type_key、GetFunction、GetSource。该类构造时接收代码字符串，GetSource返回代码，GetFunction返回的PackedFunc输出代码：\nclass HelloModuleNode : public ModuleNode {public:  explicit HelloModuleNode(std::string code) : code_(std::move(code)) {}  const char *type_key() const final {    return \"hello\";  }  PackedFunc GetFunction(      const std::string &amp;name,      const ObjectPtr&lt;Object&gt; &amp;sptr_to_self) final {    auto code = code_;    return PackedFunc([code](TVMArgs args, TVMRetValue *ret) {      std::cout &lt;&lt; code &lt;&lt; std::endl;    });  }  std::string GetSource(const std::string &amp;format) final {    return code_;  }private:  std::string code_;};\n\n实现翻译单元因为前端传递过来的是TIR，因此还需要有一个翻译单元来将传递过来的TIR进行转换，以合适的形式传递给后端模块。\n一般来说这个单元做的事就是代码生成，如CodeGenCUDA就将传入的TIR翻译为CUDA C代码传递给CUDAModuleNode。\n作为示例的hello模块也加一个非常简单的代码生成单元CodeGenHello，该类继承自CodeGenC，所做的仅仅是在CodeGenC输出的前置声明语句中添加一个注释// hello tvm backend!：\nclass CodeGenHello : public CodeGenC {public:  std::string Finish()  {    decl_stream &lt;&lt; \"// hello tvm backend!\" &lt;&lt; std::endl;    return CodeGenC::Finish();  }};\n\n注册接口函数tvm.build和tvm.build_module.build最后一步的派发都发生在tvm::codegen::Build：\nstd::string build_f_name = \"codegen.build_\" + mode;  // the build function.  const PackedFunc* bf = runtime::Registry::Get(build_f_name);  CHECK(bf != nullptr)      &lt;&lt; \"Target \" &lt;&lt; target &lt;&lt; \" is not enabled\";  runtime::Module m = transformed_funcs.empty() ?                      (*bf)(funcs, target) :                      (*bf)(transformed_funcs, target);  return m;\n\n由其代码可见，如果想利用tvm.build等已有的前端接口构建模块，则需将一个函数签名为(tvm::Array&lt;tvm::tir::LoweredFunc&gt;, const std::string &amp;) -&gt; tvm::runtime::Module的后端接口函数注册为\"codegen.build_${target}\"。\n如下为hello模块的后端接口函数及其注册：\nModule BulidHello(Array&lt;tir::LoweredFunc&gt; funcs, const std::string &amp;target) {  codegen::CodeGenHello cg;  for (auto &amp;f : funcs)    cg.AddFunction(f);  return Module(make_object&lt;HelloModuleNode&gt;(cg.Finish()));}TVM_REGISTER_GLOBAL(\"codegen.build_hello\").set_body_typed(BulidHello);\n\n当然也可以注册其他类型的后端接口，不过这样可能需要自己添加其他函数来处理前端的输入（Relay、Tensor-Expression等），将前端输入转化为后端接口适配的类型。\n添加设备类型因为tvm.build的执行过程会提前进行一些和设备相关的检查（好像会检查这些的代码最终都会流向tvm::codegen::Build，而后者本身就会检查设备后端接口的存在性，所以这种强行增加模块耦合性的行为是为什么呢……），因此需要手动在源码中为我们的hello模块“放行”：\n在python/tvm/_ffi/runtime_ctypes.py中的TVMContext.STR2MASK中添加一项：\nSTR2MASK = {        'llvm': 1,        'stackvm': 1,        'cpu': 1,        'c': 1,        'hello': 1, # here        'gpu': 2,        'cuda': 2,        # ......        'micro_dev': 13,    }\n\n在src/target/target.cc中的tvm::CreateTarget里添加一项判断：\nif (target_name == \"c\" &amp;&amp; t-&gt;device_name == \"micro_dev\") {    t-&gt;device_type = kDLMicroDev;  } else if (target_name == \"c\" || target_name == \"llvm\") {    t-&gt;keys_array.push_back(tir::StringImmNode::make(\"cpu\"));  } else if (target_name == \"cuda\" || target_name == \"nvptx\") {    t-&gt;device_type = kDLGPU;    t-&gt;keys_array.push_back(tir::StringImmNode::make(\"cuda\"));    t-&gt;keys_array.push_back(tir::StringImmNode::make(\"gpu\"));    t-&gt;max_num_threads = 1024;    t-&gt;thread_warp_size = 32;  // ......  } else if (target_name == \"hybrid\") {    t-&gt;device_type = kDLCPU;  } else if (target_name == \"hello\") { // here    t-&gt;device_type = kDLCPU;  } else {    LOG(ERROR) &lt;&lt; \"Unknown target name \" &lt;&lt; target_name;    return target::stackvm();  }\n\n改写cmake文件最后一步就是将我们新增的模块集成到原本的项目构建系统中。\n首先在cmake/modules/contrib/中添加Hello.cmake文件，将我们的源文件加入编译列表。\nlist(APPEND RUNTIME_SRCS src/runtime/contrib/hello/hello_module.cc)list(APPEND COMPILER_SRCS src/runtime/contrib/hello/hello_module.cc)message(STATUS \"Build with Hello support\")\n\n在CMakeList.txt中添加一项：\ninclude(cmake/modules/contrib/Hello.cmake)\n\n至此大功告成。\n总结\n可以针对Relay和TIR两种IR进行代码生成。推荐针对TIR生成代码，这样可以复用大量的前端/后端代码。\n\n对TIR生成代码主要需要以下步骤：\n\n实现后端模块，用于运行代码。\n\n实现翻译单元，用于代码生成。\n\n注册接口函数，给TVM其他部分调用。\n\n适当修改其他部分的代码。\n\n改写cmake文件。\n\n\n附上hello_module.cc的内容：\n#include &lt;string&gt;#include &lt;tvm/runtime/module.h&gt;#include &lt;tvm/tir/lowered_func.h&gt;#include &lt;tvm/node/container.h&gt;#include &lt;tvm/runtime/registry.h&gt;#include \"../../../target/source/codegen_c.h\"#include &lt;iostream&gt;namespace tvm {namespace codegen {class CodeGenHello : public CodeGenC {public:  std::string Finish() {    decl_stream &lt;&lt; \"// hello tvm backend!\" &lt;&lt; std::endl;    return CodeGenC::Finish();  }};}namespace runtime {class HelloModuleNode : public ModuleNode {public:  explicit HelloModuleNode(std::string code) : code_(std::move(code)) {}  const char *type_key() const final {    return \"hello\";  }  PackedFunc GetFunction(      const std::string &amp;name,      const ObjectPtr&lt;Object&gt; &amp;sptr_to_self) final {    auto code = code_;    return PackedFunc([code](TVMArgs args, TVMRetValue *ret) {      std::cout &lt;&lt; code &lt;&lt; std::endl;    });  }  std::string GetSource(const std::string &amp;format) final {    return code_;  }private:  std::string code_;};Module BulidHello(Array&lt;tir::LoweredFunc&gt; funcs, const std::string &amp;target) {  codegen::CodeGenHello cg;  for (auto &amp;f : funcs)    cg.AddFunction(f);  return Module(make_object&lt;HelloModuleNode&gt;(cg.Finish()));}TVM_REGISTER_GLOBAL(\"codegen.build_hello\").set_body_typed(BulidHello);}}","tags":["ML-Compiler","TVM"]},{"title":"用魔法打败魔法：C++模板元编程实现的scheme元循环求值器","url":"/2020/06/28/%E7%94%A8%E9%AD%94%E6%B3%95%E6%89%93%E8%B4%A5%E9%AD%94%E6%B3%95%EF%BC%9AC++%E6%A8%A1%E6%9D%BF%E5%85%83%E7%BC%96%E7%A8%8B%E5%AE%9E%E7%8E%B0%E7%9A%84scheme%E5%85%83%E5%BE%AA%E7%8E%AF%E6%B1%82%E5%80%BC%E5%99%A8/","content":"前言寒假时沉迷C++模板元编程，写了个简单的Scheme元循环求值器。可以用类似Scheme的语法写出这样的C++模板代码：\n_&lt;lambda, _&lt;V(pred), V(lst)&gt;,    _&lt;letrec, _&lt;_&lt;V(iter), _&lt;lambda, _&lt;V(lst)&gt;,                            _&lt;cond,                                _&lt;_&lt;is_null, lst&gt;, B(false)&gt;,                                _&lt;_&lt;pred, _&lt;car, lst&gt;&gt;, B(true)&gt;,                                _&lt;elsee, _&lt;iter, _&lt;cdr, lst&gt;&gt;&gt;&gt;&gt;&gt;&gt;,        _&lt;iter, lst&gt;&gt;&gt;\n\n等价的Scheme代码是这样的：\n(lambda (pred lst)  (letrec ((iter (lambda (lst)                   (cond                    ((null? lst) #f)                    ((pred (car lst)) #t)                    (else (iter (cdr lst)))))))    (iter lst)))\n\n可以在运行时输出表达式的值：\n/* mutual recursive 1 * (letrec *   ( *     (even? (lambda (n) *       (if (eqv? n zero) *         #t *         (odd? (sub1 n))))) *     (one 1) *     (odd? (lambda (n) *       (if (eqv? n zero) *         #f *         (even? (sub1 n))))) *     (sub1 (lambda (n) (- n one))) *     (zero (sub1 one))) *   (even? 12)) */using expr = eval&lt;    _&lt;letrec,      _&lt;          _&lt;V(is_even), _&lt;lambda, _&lt;V(n)&gt;,                          _&lt;iff, _&lt;is_eq, n, V(zero)&gt;,                            B(true),                            _&lt;V(is_odd), _&lt;V(sub1), n&gt;&gt;&gt;&gt;&gt;,          _&lt;V(one), N(1) &gt;,          _&lt;V(is_odd), _&lt;lambda, _&lt;V(n)&gt;,                         _&lt;iff, _&lt;is_eq, n, V(zero)&gt;,                           B(false),                           _&lt;is_even, _&lt;V(sub1), n&gt;&gt;&gt;&gt;&gt;,          _&lt;V(sub1), _&lt;lambda, _&lt;V(n)&gt;, _&lt;sub, n, one&gt;&gt;&gt;,          _&lt;V(zero), _&lt;sub1, one&gt;&gt;&gt;,      _&lt;is_even, N(12)&gt;&gt;&gt;;runtime&lt;expr&gt;::output(std::cout) &lt;&lt; std::endl; // #t\n\n还有一些简单的例子：\n/* mutual recursive 2 * (letrec *   ((fs (cons *          (lambda (n) *            (if (eqv? n 0) *                #t *                ((cdr fs) (- n 1)))) *          (lambda (n) *            (if (eqv? n 0) *                #f *                ((car fs) (- n 1))))))) *   ((car fs) 12)) */using expr = eval&lt;    _&lt;letrec,        _&lt;_&lt;V(fs), _&lt;cons,            _&lt;lambda, _&lt;V(n)&gt;,                _&lt;iff, _&lt;is_eq, n, N(0) &gt;,                    B(true),                    _&lt;_&lt;cdr, fs&gt;, _&lt;sub, n, N(1)&gt;&gt;&gt;&gt;,            _&lt;lambda, _&lt;V(n)&gt;,                _&lt;iff, _&lt;is_eq, n, N(0) &gt;,                    B(false),                    _&lt;_&lt;car, fs&gt;, _&lt;sub, n, N(1)&gt;&gt;&gt;&gt;&gt;&gt;&gt;,        _&lt;_&lt;car, fs&gt;, N(12)&gt;&gt;&gt;;runtime&lt;expr&gt;::output(std::cout) &lt;&lt; std::endl; // #t\n\n/* dot * (let *   ( *     (head (lambda (head . tail) head)) *   (head 1 2 #f)) */using expr = eval&lt;    _&lt;let,        _&lt;            _&lt;V(head), _&lt;lambda, _&lt;V(head), dot, V(tail)&gt;, head&gt;&gt;&gt;,        _&lt;head, N(1), N(2), B(false)&gt;&gt;&gt;;runtime&lt;expr&gt;::output(std::cout) &lt;&lt; std::endl; // 1\n\n// (flat-map list (list 1 2) (list 3 4))using expr = eval&lt;    _&lt;flat_map, list, _&lt;list, N(1), N(2) &gt;, _&lt;list, N(3), N(4)&gt;&gt;&gt;; // interleaveruntime&lt;expr&gt;::output(std::cout) &lt;&lt; std::endl; // (1 3 2 4)\n\n当然求值的结果也可以在编译期使用，只是懒得实现了（毕竟本质玩具……而且C++编译期计算用constexpr函数就足够了）。\n代码以及详细的介绍位于https://github.com/Light-of-Hers/CCTV\n写完后就忘了这茬事了……\n这学期修了胡振江老师的PL课，突然想起了自己写的这个玩具，便写下此文记录一下。\n语法元素\n用变参模板来表示scheme中的列表(list)。\n用普通类来表示不携带其他信息的token，比如关键词(keyword)、标识符(identifier)等。\n用模板类来表示携带额外信息的token，比如字面量(literal)：number、boolean等。\n用模板类来表示denotable value，比如pair、closure等。\n\n其中list和token是用户可见的，为了方便用户的书写：\n\nkeyword提前声明好，这样用户可以直接写lambda来表示scheme中的lambda。\n部分keyword和C++的keyword冲突，做了一些修改，如用iff表示if。\n\n\n表示list的模板名取为_，这样用户就可以用_&lt;a, b, c&gt;来表示scheme中的(a b c)。\n用一个macro来声明代表identifier的普通类：#define V(x) struct x，这样用户可以用V(abc)来表示标识符abc了。而且同一个标识符只要用该宏生成一次（同名类只需声明一次），之后的使用可以不再套个宏了。\n用宏N(n)来表示number字面量n，用B(b)来表示boolean字面量b。\n\n考虑到keyword、identifier、denotable value等都用类来表示，故使用继承结构来进行区分：\n\nlang\nkeyword\nlambda, iff, …\n\n\nvalue\npair_value\npair\n\n\natom_value\nnull_atom\nnull\n\n\nnumber_atom\nnumber\n\n\nboolean_atom\nboolean\n\n\nprocedure_atom\nclosure\nprimitive\n\n\n\n\n\n\n\n\n\n所有没有继承自lang的类都视为identifier。\n表达式求值C++的模板可以进行pattern match，因此求值函数大部分时候写起来还是蛮轻松的，就不多说了。\n不过因为C++模板运算是pure functional的，就导致letrec的实现稍微费了点心思。\nr6rs和racket的letrec的是借助side effect（let/let*和set!的语法糖）实现的，而用C++模板实现side effect不太现实（让我用state passing style来实现side effect的话还不如要side effect……）。\nfix-point组合子倒是很好的解决方案，不过当时我还没有这方面知识……因此想了个稍显古怪但还挺不错的解决方案：\n\n将environment-frame分类为normal-frame和recurse-frame（前者表示lambda和let等普通的绑定生成的frame，后者表示letrec生成的frame）：\n每个frame都有一个前驱frame的引用，一个identifier以及其绑定的value。\n一个recurse-frame还有一个标记来表示前驱frame是否和该frame由同一个letrec的bindings生成。\n\n\n求值letrec的bindings时，按照let*的规则进行，只是生成的frame为recurse-frame。\n对environment进行lookup时，若匹配到一个recurse-frame\n\n（其所在letrec所生成frame中的最下游frame为），且其绑定的value为包含一个closure ，绑定的environment为，则：\n\n若\n\n的前驱frame 为所绑定的frame的祖先，即，则返回一个新的closure ，只有绑定的environment与不同，为- 。\n\n否则，直接返回\n\n\n。\n\n\n\n后记谨以此纪念寒假的摸鱼时光。\n","tags":["Cpp","Programming-Language","Lisp","Compiler"]},{"title":"目前是否有挑战 Transformer 的新型架构？（回答）","url":"/2024/01/26/%E7%9B%AE%E5%89%8D%E6%98%AF%E5%90%A6%E6%9C%89%E6%8C%91%E6%88%98%20Transformer%20%E7%9A%84%E6%96%B0%E5%9E%8B%E6%9E%B6%E6%9E%84%EF%BC%9F%EF%BC%88%E5%9B%9E%E7%AD%94%EF%BC%89/","content":"Linear RNN 和 Linear Attention。直观理解的话，前者消除 RNN 状态之间的部分非线性依赖，让其在训练时可以展开用 conv (FFT 加速) 或者 parallel scan 高效并行；后者则消除 Attention 计算的部分非线性依赖（主要是 softmax），让其在推理时可以像 RNN 一样高效。\n目前特别火的 Mamba (paper, code) 可以归类到 Linear RNN，RWKV (paper, code, homepage) 和 RetNet (paper, code) 可以归类到 Linear Attention。其中 Mamba 和 RWKV-6 重新引入了非线性的 data-dependent gating 来提升模型效果，此外还有 GateLoop (paper, code)、HGRN (paepr, code)、Zoology/Based (paper, code, blog)、GLA (paper, code) 等工作也做了类似的优化。\n顺便推荐一下 @sonta @Yu Zhang 等大佬的 flash-linear-attention 这个项目，给诸多 state-of-the-art 的 Linear Attention 工作提供了高效的 triton 代码实现。\n","tags":["Machine-Learning"]}]